{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ky4iZ0H8DK-n"
      },
      "source": [
        "# Dealing with label noise in image classification\n",
        "\n",
        "[Diego Ortego](https://sites.google.com/view/diegoortego/), [Insight Centre for Data Analytics](https://www.insight-centre.org/)\n",
        "\n",
        "[Dublin City University](https://www.dcu.ie/)\n",
        "\n",
        "---\n",
        "\n",
        "This lab will illustrate the memorization of uniform random label noise when training CNNs for image classification. The lab will further introduce a combination of bootstrapping loss correction and mixup data augmentation to prevent memorization. Here, we will use the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html) (50K images with 32x32 resolution) and will introduce label noise synthetically."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "555SCjNjDiQM"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "Anywhere you see a **???** in the code below, fill in in with the correct code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "274053W7C8EW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32b095fd-3195-4996-eac8-f4b04eadce74"
      },
      "source": [
        "import sys\n",
        "print(sys.version)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.9.16 (main, Dec  7 2022, 01:11:51) \n",
            "[GCC 9.4.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sK7Wqe-GD3BM"
      },
      "source": [
        "# Import packages\n",
        "Find the PyTorch docs at https://pytorch.org/docs/stable/index.html\n",
        "\n",
        "Tutorials: https://pytorch.org/tutorials/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8TdKha5hoCs"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.utils.data as data\n",
        "from torch import optim\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets.utils import download_file_from_google_drive\n",
        "\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import os\n",
        "import time\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9SofYqPEJWd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b08fcea1-5d52-43cc-add6-567d9ebdf926"
      },
      "source": [
        "print('PyTorch version:', torch.__version__)\n",
        "torch.cuda.get_device_properties(0).total_memory"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.0.0+cu118\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15835398144"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpYOltAGD2WM"
      },
      "source": [
        "# Hyperparameters + Enable GPU acceleration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efceks_N6SVB"
      },
      "source": [
        "class configuration:\n",
        "  def __init__(self):\n",
        "    self.experiment_name = \"LabelNoise_lab\"\n",
        "    self.num_classes = 10\n",
        "    self.lr = 0.1 #learning rate\n",
        "    self.M = [40, 70]\n",
        "    self.batch_size = 100 #Training batch size\n",
        "    self.test_batch_size = 100 #Test batch size\n",
        "    self.epoch = 80\n",
        "    self.epochBoot = 45 # Epoch to start bootstrapping loss correction\n",
        "    self.train_root = \"./data\"\n",
        "    self.download = False\n",
        "    self.Mixup_Alpha = 1\n",
        "    self.seed = 271828\n",
        "    self.noise_ratio = 0.6 ## Noise level. Default, 60%."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDimpcstRzel"
      },
      "source": [
        "## Create arguments object\n",
        "args = configuration()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EHQdIHSDv_k"
      },
      "source": [
        "# Make sure to enable GPU acceleration!\n",
        "device = 'cuda'\n",
        "\n",
        "# Set random seed for reproducability\n",
        "torch.backends.cudnn.deterministic = True  # fix the GPU to deterministic mode\n",
        "torch.manual_seed(args.seed)  # CPU seed\n",
        "torch.cuda.manual_seed_all(args.seed)  # GPU seed\n",
        "random.seed(args.seed)  # python seed for image transformation\n",
        "np.random.seed(args.seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMy4gpCKaFnp"
      },
      "source": [
        "# Define network architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuWPxqa-Eu1C"
      },
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    \n",
        "    def __init__(self, num_classes=10):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "\n",
        "        self.activation = nn.LeakyReLU(0.1)\n",
        "        self.conv1a = nn.Conv2d(3, 128, 3, padding=1)\n",
        "        self.bn1a = nn.BatchNorm2d(128)\n",
        "        self.conv1b = nn.Conv2d(128, 128, 3, padding=1)\n",
        "        self.bn1b = nn.BatchNorm2d(128)\n",
        "        self.mp1 = nn.MaxPool2d(2, stride=2, padding=0)\n",
        "        \n",
        "        self.conv2a = nn.Conv2d(128, 256, 3, padding=1)\n",
        "        self.bn2a = nn.BatchNorm2d(256)\n",
        "        self.conv2b = nn.Conv2d(256, 256, 3, padding=1)\n",
        "        self.bn2b = nn.BatchNorm2d(256)\n",
        "        self.mp2 = nn.MaxPool2d(2, stride=2, padding=0)\n",
        "        \n",
        "        self.conv3a = nn.Conv2d(256, 512, 3, padding=0)\n",
        "        self.bn3a = nn.BatchNorm2d(512)\n",
        "        self.conv3b = nn.Conv2d(512, 128, 1, padding=0)\n",
        "        self.bn3b = nn.BatchNorm2d(128)\n",
        "        self.ap3 = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        self.fc1 = nn.Linear(128, num_classes)\n",
        "\n",
        "\n",
        "    def forward(self, x, debug=False):\n",
        "        x = self.activation(self.bn1a(self.conv1a(x)))\n",
        "        x = self.activation(self.bn1b(self.conv1b(x)))\n",
        "        x = self.mp1(x)\n",
        "        \n",
        "        x = self.activation(self.bn2a(self.conv2a(x)))\n",
        "        x = self.activation(self.bn2b(self.conv2b(x)))\n",
        "        x = self.mp2(x)\n",
        "        \n",
        "        x = self.activation(self.bn3a(self.conv3a(x)))\n",
        "        x = self.activation(self.bn3b(self.conv3b(x)))\n",
        "        x = self.ap3(x)\n",
        "\n",
        "        x = x.view(-1, 128)\n",
        "\n",
        "        return self.fc1(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuOYGXp5LAcC"
      },
      "source": [
        "# Create a custom dataset for CIFAR-10\n",
        "PyTorch comes with a built-in dataset class for the CIFAR-10 dataset, but we need extra funcionalities to simulate label noise. The label noise type we will be using is a synthetic noise where labels are flipped uniformly at random to any other class with a pre-defined probability or noise ratio (self.noise_ratio). \n",
        "PyTorch also has built-in dataset classes for other common datasets and tasks like ImageNet. See: https://pytorch.org/docs/stable/torchvision/datasets.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdRbO8l_Lx2X"
      },
      "source": [
        "class Cifar10Train(torchvision.datasets.CIFAR10):\n",
        "    def __init__(self, args, train=True, transform=None, target_transform=None, download=False):\n",
        "        super(Cifar10Train, self).__init__(args.train_root, train=train, transform=transform,\n",
        "                                           target_transform=target_transform, download=download)\n",
        "\n",
        "        self.args = args\n",
        "        self.targets = np.asarray(self.targets)\n",
        "        self.soft_labels = np.zeros((len(self.targets), 10), dtype=np.float32)\n",
        "        self.original_labels = np.copy(self.targets)\n",
        "\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        self.train = train  # Training set or validation set\n",
        "\n",
        "        self.num_classes = self.args.num_classes\n",
        "        self.noisy_indexes = []\n",
        "        self.clean_indexes = []\n",
        "        self.clean_labels = []\n",
        "        self.noisy_labels = []\n",
        "        self.soft_labels = []\n",
        "        self.labelsNoisyOriginal = []\n",
        "        self._count = 1\n",
        "        self.prediction = []\n",
        "\n",
        "        # From in ou split function:\n",
        "        self._num = int(len(self.targets) * self.args.noise_ratio)\n",
        "\n",
        "    ################# Random in-distribution noise #########################\n",
        "    def random_in_noise(self):\n",
        "\n",
        "        # to be more equal, every category can be processed separately\n",
        "        np.random.seed(self.args.seed)\n",
        "        idxes = np.random.permutation(len(self.targets))\n",
        "        clean_labels = np.copy(self.targets)\n",
        "        noisy_indexes = idxes[0:self._num]\n",
        "        clean_indexes = idxes[self._num:]\n",
        "        for i in range(len(idxes)):\n",
        "            if i < self._num:\n",
        "                label_sym = np.random.randint(self.num_classes, dtype=np.int32)\n",
        "                while (label_sym == self.targets[idxes[i]]):  # To exclude the original label\n",
        "                    label_sym = np.random.randint(self.num_classes, dtype=np.int32)\n",
        "                self.targets[idxes[i]] = label_sym\n",
        "\n",
        "        self.targets = np.asarray(self.targets, dtype=np.long)\n",
        "        self.noisy_labels = np.copy(self.targets)\n",
        "        self.noisy_indexes = noisy_indexes\n",
        "        self.clean_labels = clean_labels\n",
        "        self.clean_indexes = clean_indexes\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        img, labels, clean_labels = self.data[index], self.targets[index], self.clean_labels[index]\n",
        "\n",
        "        img = Image.fromarray(img)\n",
        "\n",
        "        img_noDA = self.target_transform(img)\n",
        "\n",
        "        img1 = self.transform(img)\n",
        "\n",
        "        return img1, img_noDA, labels, index, clean_labels\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pm9todeR7JDv"
      },
      "source": [
        "\n",
        "#Standard training results: oracle visualization\n",
        "First, download the provided data. Then, load loss curves of a standard training using a cross-entropy loss. Using an oracle to distinguish between clean and noisy samples, plot the median loss for each type."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xB14Zvbh7iRV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4df930d-3abe-49a1-99bb-1624b057c67e"
      },
      "source": [
        "!gdown --id 1qTnjdVOyE57WJdhEHAsO_iMGTCBkTUze\n",
        "#!gdown --id 1MN3PW2-0v602DMrwvUI45WMeG-Iptoat\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1qTnjdVOyE57WJdhEHAsO_iMGTCBkTUze\n",
            "To: /content/metrics_LabelNoise_lab.tar\n",
            "100% 20.4M/20.4M [00:01<00:00, 12.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBMFVMqyB8fs"
      },
      "source": [
        "!tar xf metrics_LabelNoise_lab.tar\n",
        "!rm metrics_LabelNoise_lab.tar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovU9B7F57GzU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "1035732c-b19f-4e8d-846b-f321895c0313"
      },
      "source": [
        "##Accuracy\n",
        "res_path = \".\"\n",
        "all_loss_train_epoch = np.load(res_path + '/' + 'losses_per_sample_train_CE.npy')\n",
        "clean_idx = np.load(res_path + '/' + 'clean_idx.npy')\n",
        "noisy_idx = np.load(res_path + '/' + 'noisy_idx.npy')\n",
        "\n",
        "numEpochs = all_loss_train_epoch.shape[0]\n",
        "epochs = range(numEpochs)\n",
        "\n",
        "plt.figure(1)\n",
        "plt.plot(epochs, np.median(all_loss_train_epoch[:, np.sort(clean_idx)], 1), label='Clean samples loss')\n",
        "plt.plot(epochs, np.median(all_loss_train_epoch[:, np.sort(noisy_idx)], 1), label='Noisy samples loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2iKhIG9G_CA"
      },
      "source": [
        "**QUESTION FOR STUDENTS**\n",
        "\n",
        "Explain the loss behaviour. For noisy samples, why the behaviour is different compared to clean samples?\n",
        "\n",
        "Answer (edit the cell):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhqlVAZkAzJJ"
      },
      "source": [
        "# Training functions\n",
        "Define a training loop that uses a label noise-robust loss function. In particular, we are going to add mixup data augmentation and bootstrapping loss correction. The loss is similar to that in Eq. 13 in the CVPR 2021 paper https://arxiv.org/abs/2012.04462, but using soft labels and the regularizations in Eq. 10 and 12 from https://arxiv.org/abs/1803.11364. The first regularization encourages a uniform prediction across classes in the mini-batch samples, while the second is an entropy minimization term for each sample, i.e a term that encourages spiky predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gn29-7H91D7d"
      },
      "source": [
        "def reg_loss_class(mean_tab, num_classes):\n",
        "\n",
        "    p = 1./num_classes\n",
        "    loss = torch.sum(torch.log(p/mean_tab) * p)\n",
        "\n",
        "    return loss\n",
        "\n",
        "def train_mixup_boot(args, model, device, train_loader, optimizer, epoch, sample_loss_per_epoch_tensor):\n",
        "    train_loss = []\n",
        "    acc_per_batch = []\n",
        "\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "\n",
        "    alpha = args.Mixup_Alpha\n",
        "\n",
        "    counter = 1\n",
        "    correct = 0\n",
        "    criterionCE = torch.nn.CrossEntropyLoss()\n",
        "    criterionCE2 = torch.nn.CrossEntropyLoss(reduction='none')\n",
        "\n",
        "    for batch_idx, (imgs, imgsNoDA, labels, index, _) in enumerate(train_loader):\n",
        "\n",
        "        images = imgs.to(device)\n",
        "        imgsNoDA = imgsNoDA.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        batch_size = images.size()[0]\n",
        "\n",
        "        ########################### Mixup ######################################\n",
        "        ## Extra forward pass to get non-mixed predictions that are needed for labels\n",
        "        optimizer.zero_grad()\n",
        "        with torch.no_grad():\n",
        "            output_noDA = model(imgsNoDA)\n",
        "            # output_noDA.detach()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if alpha > 0:\n",
        "            lam = np.random.beta(alpha, alpha)\n",
        "        else:\n",
        "            lam = 1\n",
        "\n",
        "        index_mix = torch.randperm(batch_size).cuda()\n",
        "        imagesMix = lam * images + (1 - lam) * images[index_mix, :]\n",
        "        labels_1, labels_2 = labels, labels[index_mix]\n",
        "        outputs = model(imagesMix)  ##Logits\n",
        "        output_mean = F.softmax(outputs, dim=1)\n",
        "        tab_mean_class = torch.mean(output_mean, -2)\n",
        "        \n",
        "        ########################################################################\n",
        "        if epoch < args.epochBoot: ## Early training only uses mixup loss\n",
        "            loss = lam*criterionCE(outputs, labels_1) + (1-lam)*criterionCE(outputs, labels_2)\n",
        "        else:\n",
        "            \n",
        "            ##Soft bootstrapping\n",
        "            prob = F.softmax(output_noDA, dim=1)\n",
        "            z1 = prob.clone().detach()\n",
        "            z2 = z1[index_mix, :]\n",
        "\n",
        "            B = 0.2  # Static weight for perceptual term, i.e. always rely 20% on prediction and 80% on original label\n",
        "\n",
        "            # First mixup term\n",
        "            # a) Loss using original labels\n",
        "            loss_x1 = lam * (1 - B) * criterionCE(outputs, labels_1)\n",
        "\n",
        "            # b) Perceptual term using network prediction (data augmentation free)\n",
        "            loss_x1_pred = torch.mean(lam * B * (-torch.sum(z1 * F.log_softmax(outputs, dim=1), dim=1)))\n",
        "\n",
        "\n",
        "            # Second mixup term (permuted order affects here)\n",
        "            # a) Loss using original labels\n",
        "            loss_x2 = (1 - lam) * (1 - B) * criterionCE(outputs, labels_2)\n",
        "\n",
        "            # b) Perceptual term using network prediction (data augmentation free)\n",
        "            loss_x2_pred = torch.mean((1-lam) * B * (-torch.sum(z2 * F.log_softmax(outputs, dim=1), dim=1)))\n",
        "\n",
        "            loss = loss_x1 + loss_x1_pred + loss_x2 + loss_x2_pred\n",
        "            loss_reg = reg_loss_class(tab_mean_class, args.num_classes)\n",
        "            loss_reg2 = -torch.mean(torch.sum(prob * F.log_softmax(outputs, dim=1), dim=1))\n",
        "\n",
        "            ##Final loss: bootstrapping and regularization terms\n",
        "            loss = loss + loss_reg + loss_reg2\n",
        "\n",
        "\n",
        "        train_loss.append(loss.item())\n",
        "        \n",
        "        preds = outputs.max(1, keepdim=True)[1]  # get the index of the max log-probability\n",
        "        correct += preds.eq(labels.view_as(preds)).sum().item()\n",
        "        if images.size(0) < args.batch_size:\n",
        "            acc_per_batch.append(100. * correct / (batch_idx * args.batch_size + images.size(0)))\n",
        "        else:\n",
        "            acc_per_batch.append(100. * correct / ((batch_idx + 1) * args.batch_size))\n",
        "\n",
        "        # compute gradient and do SGD step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (epoch%3)==0: # Every 3 epochs we store a new loss value (we don't do it every epoch because this slows down the training)\n",
        "          with torch.no_grad():\n",
        "              CE_loss = criterionCE2(output_noDA, labels)\n",
        "              sample_loss_per_epoch_tensor[index] = CE_loss\n",
        "\n",
        "        if counter % 15 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}, Accuracy: {:.0f}%, Learning rate: {:.6f}'.format(\n",
        "                epoch, counter * len(images), len(train_loader.dataset),\n",
        "                       100. * counter / len(train_loader), loss.item(),\n",
        "                acc_per_batch[-1], optimizer.param_groups[0]['lr']))\n",
        "        counter = counter + 1\n",
        "\n",
        "    return sum(train_loss) / len(train_loss), acc_per_batch[-1], sample_loss_per_epoch_tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfnS5vjQUurj"
      },
      "source": [
        "# Testing function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__YmdttKUtqH"
      },
      "source": [
        "def testing(args, model, device, test_loader):\n",
        "    model.eval()\n",
        "    loss_per_batch = []\n",
        "    acc_val_per_batch =[]\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, target) in enumerate(test_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            ##Here cross-entropy loss is also estimated, but is split into two parts; log_softmax + negative log likelihood loss\n",
        "            output = F.log_softmax(output, dim=1)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
        "            loss_per_batch.append(F.nll_loss(output, target).item())\n",
        "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "            acc_val_per_batch.append(100. * correct / ((batch_idx+1)*args.test_batch_size))\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "    loss_per_epoch = [np.average(loss_per_batch)]\n",
        "    acc_val_per_epoch = [np.array(100. * correct / len(test_loader.dataset))]\n",
        "\n",
        "    return (loss_per_epoch, acc_val_per_epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hguyy15S-x-"
      },
      "source": [
        "# Data Transformations\n",
        "We need to specify a transform here to convert images to torch tensors.\n",
        "\n",
        "I'm adding a normalization transform here too so that the images have mean zero and unit variance. This is optional. For some problems (models/datasets) proper normalization is important for performance. For others (e.g. models with batch normalization early on), the importance of normalization is less."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1iqLV4IURUv"
      },
      "source": [
        "mean = [0.4914, 0.4822, 0.4465]\n",
        "std = [0.2023, 0.1994, 0.2010]\n",
        "\n",
        "## Transformations for training data\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Pad(2, padding_mode='reflect'),\n",
        "    transforms.RandomCrop(32),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std),\n",
        "])\n",
        "\n",
        "## Transformations for test data\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8f4CbxzKq12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3312de4e-365a-4a21-a2b0-79b8a92f466b"
      },
      "source": [
        "# Create dataset\n",
        "cifar10_train_val = torchvision.datasets.CIFAR10(args.train_root, train=True, download=True)\n",
        "\n",
        "trainset = Cifar10Train(args, train=True, transform=transform_train, target_transform=transform_test)\n",
        "## Add synthetic noise\n",
        "trainset.random_in_noise()\n",
        "\n",
        "# Create dataLoaders\n",
        "train_loader = torch.utils.data.DataLoader(trainset, batch_size=args.batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
        "testset = datasets.CIFAR10(root='./data', train=False, download=False, transform=transform_test)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=args.test_batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
        "\n",
        "print('-------> Data loading')\n",
        "print(\"Training with {0} noise ratio\".format(args.noise_ratio))\n",
        "\n",
        "#Create the CNN\n",
        "model = SimpleCNN(num_classes = 10).to(device)\n",
        "\n",
        "print('Total params: %2.fM' % (sum(p.numel() for p in model.parameters()) / 1000000.0))\n",
        "\n",
        "milestones = args.M\n",
        "\n",
        "##Define optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=0.9, weight_decay=1e-4)\n",
        "##Define scheduler\n",
        "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=milestones, gamma=0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:13<00:00, 12837240.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-56461ed9fcd4>:44: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  self.targets = np.asarray(self.targets, dtype=np.long)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------> Data loading\n",
            "Training with 0.6 noise ratio\n",
            "Total params:  2M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z28ZHYdgUIU4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "879e0a04-c663-4ea8-ea72-b342699edb43"
      },
      "source": [
        "loss_train_epoch = []\n",
        "loss_test_epoch = []\n",
        "acc_train_per_epoch = []\n",
        "acc_test_per_epoch = []\n",
        "sample_loss_per_epoch_train = []\n",
        "\n",
        "sample_loss_per_epoch_tensor = torch.zeros(len(train_loader.dataset)).float().to(device)\n",
        "\n",
        "res_path = \"./metrics_\" + args.experiment_name\n",
        "\n",
        "if not os.path.isdir(res_path):\n",
        "    os.makedirs(res_path)\n",
        "\n",
        "np.save(res_path + '/' + 'clean_idx.npy', trainset.clean_indexes)\n",
        "np.save(res_path + '/' + 'noisy_idx.npy', trainset.noisy_indexes)\n",
        "\n",
        "cont = 0\n",
        "\n",
        "for epoch in range(1, args.epoch + 1):\n",
        "\n",
        "    # One epoch of training\n",
        "    st = time.time()\n",
        "\n",
        "    print(\"Training with \" + str(args.noise_ratio) + \" noise ratio of uniform random label noise\")\n",
        "\n",
        "    loss_per_epoch, top1_train_ac, sample_loss_per_epoch_tensor = train_mixup_boot(args, model, device, train_loader, optimizer, epoch, sample_loss_per_epoch_tensor)\n",
        "    scheduler.step()\n",
        "    loss_train_epoch += [loss_per_epoch]\n",
        "\n",
        "    # test\n",
        "    loss_per_epoch_test, acc_val_per_epoch_i = testing(args, model, device, test_loader)\n",
        "\n",
        "    loss_test_epoch += loss_per_epoch_test\n",
        "    acc_train_per_epoch += [top1_train_ac]\n",
        "    acc_test_per_epoch += acc_val_per_epoch_i\n",
        "\n",
        "    sample_loss_per_epoch_train.append(sample_loss_per_epoch_tensor.cpu().numpy())\n",
        "\n",
        "    if epoch == 1:\n",
        "        best_acc_val = acc_val_per_epoch_i[-1]\n",
        "\n",
        "    else:\n",
        "        if acc_val_per_epoch_i[-1] > best_acc_val:\n",
        "            best_acc_val = acc_val_per_epoch_i[-1]\n",
        "\n",
        "    \n",
        "    np.save(res_path + '/' + 'LOSS_epoch_train_mixBoot.npy', np.asarray(loss_train_epoch))\n",
        "    np.save(res_path + '/' + 'LOSS_epoch_val_mixBoot.npy', np.asarray(loss_test_epoch))\n",
        "\n",
        "    # save accuracies:\n",
        "    np.save(res_path + '/' + 'accuracy_per_epoch_train_mixBoot.npy', np.asarray(acc_train_per_epoch))\n",
        "    np.save(res_path + '/' + 'accuracy_per_epoch_val_mixBoot.npy', np.asarray(acc_test_per_epoch))\n",
        "\n",
        "    # save individual losses per epoch\n",
        "    np.save(res_path + '/' + 'losses_per_sample_train_mixBoot.npy', np.asarray(sample_loss_per_epoch_train))\n",
        "\n",
        "    cont += 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 1 [1500/50000 (3%)]\tLoss: 2.316605, Accuracy: 12%, Learning rate: 0.100000\n",
            "Train Epoch: 1 [3000/50000 (6%)]\tLoss: 2.282095, Accuracy: 11%, Learning rate: 0.100000\n",
            "Train Epoch: 1 [4500/50000 (9%)]\tLoss: 2.338314, Accuracy: 11%, Learning rate: 0.100000\n",
            "Train Epoch: 1 [6000/50000 (12%)]\tLoss: 2.341707, Accuracy: 11%, Learning rate: 0.100000\n",
            "Train Epoch: 1 [7500/50000 (15%)]\tLoss: 2.368055, Accuracy: 11%, Learning rate: 0.100000\n",
            "Train Epoch: 1 [9000/50000 (18%)]\tLoss: 2.289942, Accuracy: 11%, Learning rate: 0.100000\n",
            "Train Epoch: 1 [10500/50000 (21%)]\tLoss: 2.319464, Accuracy: 11%, Learning rate: 0.100000\n",
            "Train Epoch: 1 [12000/50000 (24%)]\tLoss: 2.282553, Accuracy: 12%, Learning rate: 0.100000\n",
            "Train Epoch: 1 [13500/50000 (27%)]\tLoss: 2.275986, Accuracy: 12%, Learning rate: 0.100000\n",
            "Train Epoch: 1 [15000/50000 (30%)]\tLoss: 2.275390, Accuracy: 12%, Learning rate: 0.100000\n",
            "Train Epoch: 1 [16500/50000 (33%)]\tLoss: 2.293794, Accuracy: 12%, Learning rate: 0.100000\n",
            "Train Epoch: 1 [18000/50000 (36%)]\tLoss: 2.301345, Accuracy: 12%, Learning rate: 0.100000\n",
            "Train Epoch: 1 [19500/50000 (39%)]\tLoss: 2.272665, Accuracy: 12%, Learning rate: 0.100000\n",
            "Train Epoch: 1 [21000/50000 (42%)]\tLoss: 2.274948, Accuracy: 12%, Learning rate: 0.100000\n",
            "Train Epoch: 1 [22500/50000 (45%)]\tLoss: 2.276172, Accuracy: 13%, Learning rate: 0.100000\n",
            "Train Epoch: 1 [24000/50000 (48%)]\tLoss: 2.300214, Accuracy: 13%, Learning rate: 0.100000\n",
            "Train Epoch: 1 [25500/50000 (51%)]\tLoss: 2.282387, Accuracy: 13%, Learning rate: 0.100000\n",
            "Train Epoch: 1 [27000/50000 (54%)]\tLoss: 2.230214, Accuracy: 13%, Learning rate: 0.100000\n",
            "Train Epoch: 1 [28500/50000 (57%)]\tLoss: 2.253798, Accuracy: 13%, Learning rate: 0.100000\n",
            "Train Epoch: 1 [30000/50000 (60%)]\tLoss: 2.293994, Accuracy: 13%, Learning rate: 0.100000\n",
            "Train Epoch: 1 [31500/50000 (63%)]\tLoss: 2.227684, Accuracy: 13%, Learning rate: 0.100000\n",
            "Train Epoch: 1 [33000/50000 (66%)]\tLoss: 2.312229, Accuracy: 13%, Learning rate: 0.100000\n",
            "Train Epoch: 1 [34500/50000 (69%)]\tLoss: 2.274287, Accuracy: 13%, Learning rate: 0.100000\n",
            "Train Epoch: 1 [36000/50000 (72%)]\tLoss: 2.292045, Accuracy: 13%, Learning rate: 0.100000\n",
            "Train Epoch: 1 [37500/50000 (75%)]\tLoss: 2.257596, Accuracy: 13%, Learning rate: 0.100000\n",
            "Train Epoch: 1 [39000/50000 (78%)]\tLoss: 2.244976, Accuracy: 13%, Learning rate: 0.100000\n",
            "Train Epoch: 1 [40500/50000 (81%)]\tLoss: 2.277652, Accuracy: 13%, Learning rate: 0.100000\n",
            "Train Epoch: 1 [42000/50000 (84%)]\tLoss: 2.232733, Accuracy: 13%, Learning rate: 0.100000\n",
            "Train Epoch: 1 [43500/50000 (87%)]\tLoss: 2.329140, Accuracy: 13%, Learning rate: 0.100000\n",
            "Train Epoch: 1 [45000/50000 (90%)]\tLoss: 2.239277, Accuracy: 13%, Learning rate: 0.100000\n",
            "Train Epoch: 1 [46500/50000 (93%)]\tLoss: 2.278609, Accuracy: 13%, Learning rate: 0.100000\n",
            "Train Epoch: 1 [48000/50000 (96%)]\tLoss: 2.263992, Accuracy: 13%, Learning rate: 0.100000\n",
            "Train Epoch: 1 [49500/50000 (99%)]\tLoss: 2.302250, Accuracy: 13%, Learning rate: 0.100000\n",
            "\n",
            "Test set: Average loss: 2.0492, Accuracy: 3382/10000 (34%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 2 [1500/50000 (3%)]\tLoss: 2.244052, Accuracy: 14%, Learning rate: 0.100000\n",
            "Train Epoch: 2 [3000/50000 (6%)]\tLoss: 2.158403, Accuracy: 14%, Learning rate: 0.100000\n",
            "Train Epoch: 2 [4500/50000 (9%)]\tLoss: 2.285340, Accuracy: 14%, Learning rate: 0.100000\n",
            "Train Epoch: 2 [6000/50000 (12%)]\tLoss: 2.291830, Accuracy: 14%, Learning rate: 0.100000\n",
            "Train Epoch: 2 [7500/50000 (15%)]\tLoss: 2.281128, Accuracy: 14%, Learning rate: 0.100000\n",
            "Train Epoch: 2 [9000/50000 (18%)]\tLoss: 2.266681, Accuracy: 14%, Learning rate: 0.100000\n",
            "Train Epoch: 2 [10500/50000 (21%)]\tLoss: 2.292417, Accuracy: 14%, Learning rate: 0.100000\n",
            "Train Epoch: 2 [12000/50000 (24%)]\tLoss: 2.274178, Accuracy: 14%, Learning rate: 0.100000\n",
            "Train Epoch: 2 [13500/50000 (27%)]\tLoss: 2.244773, Accuracy: 14%, Learning rate: 0.100000\n",
            "Train Epoch: 2 [15000/50000 (30%)]\tLoss: 2.261869, Accuracy: 14%, Learning rate: 0.100000\n",
            "Train Epoch: 2 [16500/50000 (33%)]\tLoss: 2.281506, Accuracy: 14%, Learning rate: 0.100000\n",
            "Train Epoch: 2 [18000/50000 (36%)]\tLoss: 2.228584, Accuracy: 14%, Learning rate: 0.100000\n",
            "Train Epoch: 2 [19500/50000 (39%)]\tLoss: 2.320827, Accuracy: 14%, Learning rate: 0.100000\n",
            "Train Epoch: 2 [21000/50000 (42%)]\tLoss: 2.249871, Accuracy: 14%, Learning rate: 0.100000\n",
            "Train Epoch: 2 [22500/50000 (45%)]\tLoss: 2.313506, Accuracy: 14%, Learning rate: 0.100000\n",
            "Train Epoch: 2 [24000/50000 (48%)]\tLoss: 2.278856, Accuracy: 14%, Learning rate: 0.100000\n",
            "Train Epoch: 2 [25500/50000 (51%)]\tLoss: 2.253896, Accuracy: 14%, Learning rate: 0.100000\n",
            "Train Epoch: 2 [27000/50000 (54%)]\tLoss: 2.253558, Accuracy: 14%, Learning rate: 0.100000\n",
            "Train Epoch: 2 [28500/50000 (57%)]\tLoss: 2.305921, Accuracy: 14%, Learning rate: 0.100000\n",
            "Train Epoch: 2 [30000/50000 (60%)]\tLoss: 2.253867, Accuracy: 14%, Learning rate: 0.100000\n",
            "Train Epoch: 2 [31500/50000 (63%)]\tLoss: 2.291714, Accuracy: 14%, Learning rate: 0.100000\n",
            "Train Epoch: 2 [33000/50000 (66%)]\tLoss: 2.262382, Accuracy: 14%, Learning rate: 0.100000\n",
            "Train Epoch: 2 [34500/50000 (69%)]\tLoss: 2.318371, Accuracy: 15%, Learning rate: 0.100000\n",
            "Train Epoch: 2 [36000/50000 (72%)]\tLoss: 2.230075, Accuracy: 15%, Learning rate: 0.100000\n",
            "Train Epoch: 2 [37500/50000 (75%)]\tLoss: 2.208101, Accuracy: 15%, Learning rate: 0.100000\n",
            "Train Epoch: 2 [39000/50000 (78%)]\tLoss: 2.255298, Accuracy: 15%, Learning rate: 0.100000\n",
            "Train Epoch: 2 [40500/50000 (81%)]\tLoss: 2.313847, Accuracy: 15%, Learning rate: 0.100000\n",
            "Train Epoch: 2 [42000/50000 (84%)]\tLoss: 2.252360, Accuracy: 15%, Learning rate: 0.100000\n",
            "Train Epoch: 2 [43500/50000 (87%)]\tLoss: 2.161116, Accuracy: 14%, Learning rate: 0.100000\n",
            "Train Epoch: 2 [45000/50000 (90%)]\tLoss: 2.247290, Accuracy: 14%, Learning rate: 0.100000\n",
            "Train Epoch: 2 [46500/50000 (93%)]\tLoss: 2.254661, Accuracy: 14%, Learning rate: 0.100000\n",
            "Train Epoch: 2 [48000/50000 (96%)]\tLoss: 2.292830, Accuracy: 15%, Learning rate: 0.100000\n",
            "Train Epoch: 2 [49500/50000 (99%)]\tLoss: 2.164440, Accuracy: 14%, Learning rate: 0.100000\n",
            "\n",
            "Test set: Average loss: 1.9491, Accuracy: 4233/10000 (42%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 3 [1500/50000 (3%)]\tLoss: 2.221290, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 3 [3000/50000 (6%)]\tLoss: 2.221597, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 3 [4500/50000 (9%)]\tLoss: 2.241605, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 3 [6000/50000 (12%)]\tLoss: 2.270432, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 3 [7500/50000 (15%)]\tLoss: 2.266195, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 3 [9000/50000 (18%)]\tLoss: 2.244772, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 3 [10500/50000 (21%)]\tLoss: 2.269372, Accuracy: 15%, Learning rate: 0.100000\n",
            "Train Epoch: 3 [12000/50000 (24%)]\tLoss: 2.336464, Accuracy: 15%, Learning rate: 0.100000\n",
            "Train Epoch: 3 [13500/50000 (27%)]\tLoss: 2.228131, Accuracy: 15%, Learning rate: 0.100000\n",
            "Train Epoch: 3 [15000/50000 (30%)]\tLoss: 2.249144, Accuracy: 15%, Learning rate: 0.100000\n",
            "Train Epoch: 3 [16500/50000 (33%)]\tLoss: 2.224083, Accuracy: 15%, Learning rate: 0.100000\n",
            "Train Epoch: 3 [18000/50000 (36%)]\tLoss: 2.253529, Accuracy: 15%, Learning rate: 0.100000\n",
            "Train Epoch: 3 [19500/50000 (39%)]\tLoss: 2.312022, Accuracy: 15%, Learning rate: 0.100000\n",
            "Train Epoch: 3 [21000/50000 (42%)]\tLoss: 2.274060, Accuracy: 15%, Learning rate: 0.100000\n",
            "Train Epoch: 3 [22500/50000 (45%)]\tLoss: 2.228027, Accuracy: 15%, Learning rate: 0.100000\n",
            "Train Epoch: 3 [24000/50000 (48%)]\tLoss: 2.254654, Accuracy: 15%, Learning rate: 0.100000\n",
            "Train Epoch: 3 [25500/50000 (51%)]\tLoss: 2.171751, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 3 [27000/50000 (54%)]\tLoss: 2.268373, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 3 [28500/50000 (57%)]\tLoss: 2.245363, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 3 [30000/50000 (60%)]\tLoss: 2.217225, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 3 [31500/50000 (63%)]\tLoss: 2.258050, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 3 [33000/50000 (66%)]\tLoss: 2.205085, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 3 [34500/50000 (69%)]\tLoss: 2.193674, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 3 [36000/50000 (72%)]\tLoss: 2.298131, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 3 [37500/50000 (75%)]\tLoss: 2.200048, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 3 [39000/50000 (78%)]\tLoss: 2.225605, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 3 [40500/50000 (81%)]\tLoss: 2.296654, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 3 [42000/50000 (84%)]\tLoss: 2.325768, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 3 [43500/50000 (87%)]\tLoss: 2.257369, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 3 [45000/50000 (90%)]\tLoss: 2.254345, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 3 [46500/50000 (93%)]\tLoss: 2.189477, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 3 [48000/50000 (96%)]\tLoss: 2.293462, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 3 [49500/50000 (99%)]\tLoss: 2.251007, Accuracy: 16%, Learning rate: 0.100000\n",
            "\n",
            "Test set: Average loss: 1.8366, Accuracy: 4963/10000 (50%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 4 [1500/50000 (3%)]\tLoss: 2.275394, Accuracy: 15%, Learning rate: 0.100000\n",
            "Train Epoch: 4 [3000/50000 (6%)]\tLoss: 2.263662, Accuracy: 14%, Learning rate: 0.100000\n",
            "Train Epoch: 4 [4500/50000 (9%)]\tLoss: 2.284733, Accuracy: 14%, Learning rate: 0.100000\n",
            "Train Epoch: 4 [6000/50000 (12%)]\tLoss: 2.242944, Accuracy: 15%, Learning rate: 0.100000\n",
            "Train Epoch: 4 [7500/50000 (15%)]\tLoss: 2.200826, Accuracy: 15%, Learning rate: 0.100000\n",
            "Train Epoch: 4 [9000/50000 (18%)]\tLoss: 2.231974, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 4 [10500/50000 (21%)]\tLoss: 2.318305, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 4 [12000/50000 (24%)]\tLoss: 2.239870, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 4 [13500/50000 (27%)]\tLoss: 2.282434, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 4 [15000/50000 (30%)]\tLoss: 2.228588, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 4 [16500/50000 (33%)]\tLoss: 2.189069, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 4 [18000/50000 (36%)]\tLoss: 2.231344, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 4 [19500/50000 (39%)]\tLoss: 2.316653, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 4 [21000/50000 (42%)]\tLoss: 2.278374, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 4 [22500/50000 (45%)]\tLoss: 2.253729, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 4 [24000/50000 (48%)]\tLoss: 2.238945, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 4 [25500/50000 (51%)]\tLoss: 2.232377, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 4 [27000/50000 (54%)]\tLoss: 2.292272, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 4 [28500/50000 (57%)]\tLoss: 2.223904, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 4 [30000/50000 (60%)]\tLoss: 2.281706, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 4 [31500/50000 (63%)]\tLoss: 2.289204, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 4 [33000/50000 (66%)]\tLoss: 2.240783, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 4 [34500/50000 (69%)]\tLoss: 2.217394, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 4 [36000/50000 (72%)]\tLoss: 2.178307, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 4 [37500/50000 (75%)]\tLoss: 2.235865, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 4 [39000/50000 (78%)]\tLoss: 2.283020, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 4 [40500/50000 (81%)]\tLoss: 2.222519, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 4 [42000/50000 (84%)]\tLoss: 2.199377, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 4 [43500/50000 (87%)]\tLoss: 2.260092, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 4 [45000/50000 (90%)]\tLoss: 2.227044, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 4 [46500/50000 (93%)]\tLoss: 2.277753, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 4 [48000/50000 (96%)]\tLoss: 2.233725, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 4 [49500/50000 (99%)]\tLoss: 2.266912, Accuracy: 16%, Learning rate: 0.100000\n",
            "\n",
            "Test set: Average loss: 1.8177, Accuracy: 5089/10000 (51%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 5 [1500/50000 (3%)]\tLoss: 2.202336, Accuracy: 13%, Learning rate: 0.100000\n",
            "Train Epoch: 5 [3000/50000 (6%)]\tLoss: 2.253333, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 5 [4500/50000 (9%)]\tLoss: 2.290729, Accuracy: 15%, Learning rate: 0.100000\n",
            "Train Epoch: 5 [6000/50000 (12%)]\tLoss: 2.180142, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 5 [7500/50000 (15%)]\tLoss: 2.227838, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 5 [9000/50000 (18%)]\tLoss: 2.226614, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 5 [10500/50000 (21%)]\tLoss: 2.257882, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 5 [12000/50000 (24%)]\tLoss: 2.237834, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 5 [13500/50000 (27%)]\tLoss: 2.306427, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 5 [15000/50000 (30%)]\tLoss: 2.204371, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 5 [16500/50000 (33%)]\tLoss: 2.205652, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 5 [18000/50000 (36%)]\tLoss: 2.311861, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 5 [19500/50000 (39%)]\tLoss: 2.199069, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 5 [21000/50000 (42%)]\tLoss: 2.276113, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 5 [22500/50000 (45%)]\tLoss: 2.225891, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 5 [24000/50000 (48%)]\tLoss: 2.202305, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 5 [25500/50000 (51%)]\tLoss: 2.285683, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 5 [27000/50000 (54%)]\tLoss: 2.231550, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 5 [28500/50000 (57%)]\tLoss: 2.275256, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 5 [30000/50000 (60%)]\tLoss: 2.269914, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 5 [31500/50000 (63%)]\tLoss: 2.243173, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 5 [33000/50000 (66%)]\tLoss: 2.195675, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 5 [34500/50000 (69%)]\tLoss: 2.198402, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 5 [36000/50000 (72%)]\tLoss: 2.202124, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 5 [37500/50000 (75%)]\tLoss: 2.261165, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 5 [39000/50000 (78%)]\tLoss: 2.277378, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 5 [40500/50000 (81%)]\tLoss: 2.233163, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 5 [42000/50000 (84%)]\tLoss: 2.196410, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 5 [43500/50000 (87%)]\tLoss: 2.149282, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 5 [45000/50000 (90%)]\tLoss: 2.254628, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 5 [46500/50000 (93%)]\tLoss: 2.240210, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 5 [48000/50000 (96%)]\tLoss: 2.224703, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 5 [49500/50000 (99%)]\tLoss: 2.238972, Accuracy: 17%, Learning rate: 0.100000\n",
            "\n",
            "Test set: Average loss: 1.8209, Accuracy: 4771/10000 (48%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 6 [1500/50000 (3%)]\tLoss: 2.213681, Accuracy: 15%, Learning rate: 0.100000\n",
            "Train Epoch: 6 [3000/50000 (6%)]\tLoss: 2.207935, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 6 [4500/50000 (9%)]\tLoss: 2.182881, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 6 [6000/50000 (12%)]\tLoss: 2.280202, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 6 [7500/50000 (15%)]\tLoss: 2.250261, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 6 [9000/50000 (18%)]\tLoss: 2.201923, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 6 [10500/50000 (21%)]\tLoss: 2.242332, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 6 [12000/50000 (24%)]\tLoss: 2.254628, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 6 [13500/50000 (27%)]\tLoss: 2.245562, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 6 [15000/50000 (30%)]\tLoss: 2.234039, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 6 [16500/50000 (33%)]\tLoss: 2.162002, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 6 [18000/50000 (36%)]\tLoss: 2.264227, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 6 [19500/50000 (39%)]\tLoss: 2.091578, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 6 [21000/50000 (42%)]\tLoss: 2.230779, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 6 [22500/50000 (45%)]\tLoss: 2.172824, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 6 [24000/50000 (48%)]\tLoss: 2.241429, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 6 [25500/50000 (51%)]\tLoss: 2.263650, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 6 [27000/50000 (54%)]\tLoss: 2.216779, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 6 [28500/50000 (57%)]\tLoss: 2.298539, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 6 [30000/50000 (60%)]\tLoss: 2.273050, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 6 [31500/50000 (63%)]\tLoss: 2.300428, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 6 [33000/50000 (66%)]\tLoss: 2.249484, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 6 [34500/50000 (69%)]\tLoss: 2.225154, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 6 [36000/50000 (72%)]\tLoss: 2.204202, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 6 [37500/50000 (75%)]\tLoss: 2.243297, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 6 [39000/50000 (78%)]\tLoss: 2.284964, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 6 [40500/50000 (81%)]\tLoss: 2.265162, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 6 [42000/50000 (84%)]\tLoss: 2.246567, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 6 [43500/50000 (87%)]\tLoss: 2.230507, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 6 [45000/50000 (90%)]\tLoss: 2.246245, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 6 [46500/50000 (93%)]\tLoss: 2.214011, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 6 [48000/50000 (96%)]\tLoss: 2.284569, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 6 [49500/50000 (99%)]\tLoss: 2.230625, Accuracy: 18%, Learning rate: 0.100000\n",
            "\n",
            "Test set: Average loss: 1.7533, Accuracy: 5297/10000 (53%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 7 [1500/50000 (3%)]\tLoss: 2.209348, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 7 [3000/50000 (6%)]\tLoss: 2.111017, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 7 [4500/50000 (9%)]\tLoss: 2.201586, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 7 [6000/50000 (12%)]\tLoss: 2.227875, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 7 [7500/50000 (15%)]\tLoss: 2.226295, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 7 [9000/50000 (18%)]\tLoss: 2.196334, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 7 [10500/50000 (21%)]\tLoss: 2.275969, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 7 [12000/50000 (24%)]\tLoss: 2.177605, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 7 [13500/50000 (27%)]\tLoss: 2.193225, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 7 [15000/50000 (30%)]\tLoss: 2.270434, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 7 [16500/50000 (33%)]\tLoss: 2.252041, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 7 [18000/50000 (36%)]\tLoss: 2.227010, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 7 [19500/50000 (39%)]\tLoss: 2.191737, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 7 [21000/50000 (42%)]\tLoss: 2.156322, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 7 [22500/50000 (45%)]\tLoss: 2.192306, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 7 [24000/50000 (48%)]\tLoss: 2.235653, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 7 [25500/50000 (51%)]\tLoss: 2.224784, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 7 [27000/50000 (54%)]\tLoss: 2.212962, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 7 [28500/50000 (57%)]\tLoss: 2.181731, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 7 [30000/50000 (60%)]\tLoss: 2.196117, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 7 [31500/50000 (63%)]\tLoss: 2.235662, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 7 [33000/50000 (66%)]\tLoss: 2.209773, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 7 [34500/50000 (69%)]\tLoss: 2.222652, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 7 [36000/50000 (72%)]\tLoss: 2.186045, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 7 [37500/50000 (75%)]\tLoss: 2.230626, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 7 [39000/50000 (78%)]\tLoss: 2.164003, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 7 [40500/50000 (81%)]\tLoss: 2.230437, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 7 [42000/50000 (84%)]\tLoss: 2.311134, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 7 [43500/50000 (87%)]\tLoss: 2.091116, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 7 [45000/50000 (90%)]\tLoss: 2.256704, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 7 [46500/50000 (93%)]\tLoss: 2.236064, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 7 [48000/50000 (96%)]\tLoss: 2.298509, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 7 [49500/50000 (99%)]\tLoss: 2.223489, Accuracy: 18%, Learning rate: 0.100000\n",
            "\n",
            "Test set: Average loss: 1.7551, Accuracy: 5806/10000 (58%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 8 [1500/50000 (3%)]\tLoss: 2.217776, Accuracy: 14%, Learning rate: 0.100000\n",
            "Train Epoch: 8 [3000/50000 (6%)]\tLoss: 2.201385, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 8 [4500/50000 (9%)]\tLoss: 2.156072, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 8 [6000/50000 (12%)]\tLoss: 2.285601, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 8 [7500/50000 (15%)]\tLoss: 2.254576, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 8 [9000/50000 (18%)]\tLoss: 2.214702, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 8 [10500/50000 (21%)]\tLoss: 2.282191, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 8 [12000/50000 (24%)]\tLoss: 2.142402, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 8 [13500/50000 (27%)]\tLoss: 2.239074, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 8 [15000/50000 (30%)]\tLoss: 2.281751, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 8 [16500/50000 (33%)]\tLoss: 2.246167, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 8 [18000/50000 (36%)]\tLoss: 2.174004, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 8 [19500/50000 (39%)]\tLoss: 2.194605, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 8 [21000/50000 (42%)]\tLoss: 2.161785, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 8 [22500/50000 (45%)]\tLoss: 2.166044, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 8 [24000/50000 (48%)]\tLoss: 2.178915, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 8 [25500/50000 (51%)]\tLoss: 2.282657, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 8 [27000/50000 (54%)]\tLoss: 2.234896, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 8 [28500/50000 (57%)]\tLoss: 2.295181, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 8 [30000/50000 (60%)]\tLoss: 2.260427, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 8 [31500/50000 (63%)]\tLoss: 2.244807, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 8 [33000/50000 (66%)]\tLoss: 2.253863, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 8 [34500/50000 (69%)]\tLoss: 2.193193, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 8 [36000/50000 (72%)]\tLoss: 2.280616, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 8 [37500/50000 (75%)]\tLoss: 2.259634, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 8 [39000/50000 (78%)]\tLoss: 2.245386, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 8 [40500/50000 (81%)]\tLoss: 2.103383, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 8 [42000/50000 (84%)]\tLoss: 2.285062, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 8 [43500/50000 (87%)]\tLoss: 2.230554, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 8 [45000/50000 (90%)]\tLoss: 2.270013, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 8 [46500/50000 (93%)]\tLoss: 2.279141, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 8 [48000/50000 (96%)]\tLoss: 2.216767, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 8 [49500/50000 (99%)]\tLoss: 2.173135, Accuracy: 17%, Learning rate: 0.100000\n",
            "\n",
            "Test set: Average loss: 1.7035, Accuracy: 6010/10000 (60%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 9 [1500/50000 (3%)]\tLoss: 2.218753, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 9 [3000/50000 (6%)]\tLoss: 2.293055, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 9 [4500/50000 (9%)]\tLoss: 2.163476, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 9 [6000/50000 (12%)]\tLoss: 2.291794, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 9 [7500/50000 (15%)]\tLoss: 2.250405, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 9 [9000/50000 (18%)]\tLoss: 2.207993, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 9 [10500/50000 (21%)]\tLoss: 2.243960, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 9 [12000/50000 (24%)]\tLoss: 2.268657, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 9 [13500/50000 (27%)]\tLoss: 2.288878, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 9 [15000/50000 (30%)]\tLoss: 2.214389, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 9 [16500/50000 (33%)]\tLoss: 2.233057, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 9 [18000/50000 (36%)]\tLoss: 2.182461, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 9 [19500/50000 (39%)]\tLoss: 2.122863, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 9 [21000/50000 (42%)]\tLoss: 2.127622, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 9 [22500/50000 (45%)]\tLoss: 2.222013, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 9 [24000/50000 (48%)]\tLoss: 2.259590, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 9 [25500/50000 (51%)]\tLoss: 2.179089, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 9 [27000/50000 (54%)]\tLoss: 2.163450, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 9 [28500/50000 (57%)]\tLoss: 2.138544, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 9 [30000/50000 (60%)]\tLoss: 2.211187, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 9 [31500/50000 (63%)]\tLoss: 2.176683, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 9 [33000/50000 (66%)]\tLoss: 2.222955, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 9 [34500/50000 (69%)]\tLoss: 2.222790, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 9 [36000/50000 (72%)]\tLoss: 2.159080, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 9 [37500/50000 (75%)]\tLoss: 2.183806, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 9 [39000/50000 (78%)]\tLoss: 2.190415, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 9 [40500/50000 (81%)]\tLoss: 2.194848, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 9 [42000/50000 (84%)]\tLoss: 2.267615, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 9 [43500/50000 (87%)]\tLoss: 2.227374, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 9 [45000/50000 (90%)]\tLoss: 2.152015, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 9 [46500/50000 (93%)]\tLoss: 2.150343, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 9 [48000/50000 (96%)]\tLoss: 2.246970, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 9 [49500/50000 (99%)]\tLoss: 2.246305, Accuracy: 19%, Learning rate: 0.100000\n",
            "\n",
            "Test set: Average loss: 1.6617, Accuracy: 6146/10000 (61%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 10 [1500/50000 (3%)]\tLoss: 2.243638, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 10 [3000/50000 (6%)]\tLoss: 2.144393, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 10 [4500/50000 (9%)]\tLoss: 2.128344, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 10 [6000/50000 (12%)]\tLoss: 2.195930, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 10 [7500/50000 (15%)]\tLoss: 2.193492, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 10 [9000/50000 (18%)]\tLoss: 2.197324, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 10 [10500/50000 (21%)]\tLoss: 2.229350, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 10 [12000/50000 (24%)]\tLoss: 2.235527, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 10 [13500/50000 (27%)]\tLoss: 2.225505, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 10 [15000/50000 (30%)]\tLoss: 2.269097, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 10 [16500/50000 (33%)]\tLoss: 2.127247, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 10 [18000/50000 (36%)]\tLoss: 2.182755, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 10 [19500/50000 (39%)]\tLoss: 2.296227, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 10 [21000/50000 (42%)]\tLoss: 2.244865, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 10 [22500/50000 (45%)]\tLoss: 2.245944, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 10 [24000/50000 (48%)]\tLoss: 2.280573, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 10 [25500/50000 (51%)]\tLoss: 2.170938, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 10 [27000/50000 (54%)]\tLoss: 2.162464, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 10 [28500/50000 (57%)]\tLoss: 2.276973, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 10 [30000/50000 (60%)]\tLoss: 2.277855, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 10 [31500/50000 (63%)]\tLoss: 2.175648, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 10 [33000/50000 (66%)]\tLoss: 2.218907, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 10 [34500/50000 (69%)]\tLoss: 2.262272, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 10 [36000/50000 (72%)]\tLoss: 2.164434, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 10 [37500/50000 (75%)]\tLoss: 2.242092, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 10 [39000/50000 (78%)]\tLoss: 2.190754, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 10 [40500/50000 (81%)]\tLoss: 2.222005, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 10 [42000/50000 (84%)]\tLoss: 2.197104, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 10 [43500/50000 (87%)]\tLoss: 2.237650, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 10 [45000/50000 (90%)]\tLoss: 2.238154, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 10 [46500/50000 (93%)]\tLoss: 2.161682, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 10 [48000/50000 (96%)]\tLoss: 2.180264, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 10 [49500/50000 (99%)]\tLoss: 2.079137, Accuracy: 19%, Learning rate: 0.100000\n",
            "\n",
            "Test set: Average loss: 1.6588, Accuracy: 6163/10000 (62%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 11 [1500/50000 (3%)]\tLoss: 2.235857, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 11 [3000/50000 (6%)]\tLoss: 2.205560, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 11 [4500/50000 (9%)]\tLoss: 2.171982, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 11 [6000/50000 (12%)]\tLoss: 2.250197, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 11 [7500/50000 (15%)]\tLoss: 2.220611, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 11 [9000/50000 (18%)]\tLoss: 2.227331, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 11 [10500/50000 (21%)]\tLoss: 2.240029, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 11 [12000/50000 (24%)]\tLoss: 2.197412, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 11 [13500/50000 (27%)]\tLoss: 2.230677, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 11 [15000/50000 (30%)]\tLoss: 2.218779, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 11 [16500/50000 (33%)]\tLoss: 2.192384, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 11 [18000/50000 (36%)]\tLoss: 2.257747, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 11 [19500/50000 (39%)]\tLoss: 2.169941, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 11 [21000/50000 (42%)]\tLoss: 2.216594, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 11 [22500/50000 (45%)]\tLoss: 2.016013, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 11 [24000/50000 (48%)]\tLoss: 2.226494, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 11 [25500/50000 (51%)]\tLoss: 2.200512, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 11 [27000/50000 (54%)]\tLoss: 2.226715, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 11 [28500/50000 (57%)]\tLoss: 2.142527, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 11 [30000/50000 (60%)]\tLoss: 2.236691, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 11 [31500/50000 (63%)]\tLoss: 2.177940, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 11 [33000/50000 (66%)]\tLoss: 2.261620, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 11 [34500/50000 (69%)]\tLoss: 2.240011, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 11 [36000/50000 (72%)]\tLoss: 2.230319, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 11 [37500/50000 (75%)]\tLoss: 2.220717, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 11 [39000/50000 (78%)]\tLoss: 2.165531, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 11 [40500/50000 (81%)]\tLoss: 2.165234, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 11 [42000/50000 (84%)]\tLoss: 2.286532, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 11 [43500/50000 (87%)]\tLoss: 2.217405, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 11 [45000/50000 (90%)]\tLoss: 2.251724, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 11 [46500/50000 (93%)]\tLoss: 2.225750, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 11 [48000/50000 (96%)]\tLoss: 2.224532, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 11 [49500/50000 (99%)]\tLoss: 2.106679, Accuracy: 18%, Learning rate: 0.100000\n",
            "\n",
            "Test set: Average loss: 1.6578, Accuracy: 6347/10000 (63%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 12 [1500/50000 (3%)]\tLoss: 2.223095, Accuracy: 23%, Learning rate: 0.100000\n",
            "Train Epoch: 12 [3000/50000 (6%)]\tLoss: 2.194548, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 12 [4500/50000 (9%)]\tLoss: 2.149588, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 12 [6000/50000 (12%)]\tLoss: 2.202106, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 12 [7500/50000 (15%)]\tLoss: 2.196726, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 12 [9000/50000 (18%)]\tLoss: 2.204125, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 12 [10500/50000 (21%)]\tLoss: 2.198997, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 12 [12000/50000 (24%)]\tLoss: 2.041007, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 12 [13500/50000 (27%)]\tLoss: 2.121943, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 12 [15000/50000 (30%)]\tLoss: 2.164884, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 12 [16500/50000 (33%)]\tLoss: 2.247328, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 12 [18000/50000 (36%)]\tLoss: 2.273774, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 12 [19500/50000 (39%)]\tLoss: 2.238388, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 12 [21000/50000 (42%)]\tLoss: 2.225107, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 12 [22500/50000 (45%)]\tLoss: 2.164515, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 12 [24000/50000 (48%)]\tLoss: 2.218927, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 12 [25500/50000 (51%)]\tLoss: 2.201383, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 12 [27000/50000 (54%)]\tLoss: 2.223533, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 12 [28500/50000 (57%)]\tLoss: 2.199352, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 12 [30000/50000 (60%)]\tLoss: 2.232144, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 12 [31500/50000 (63%)]\tLoss: 2.209066, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 12 [33000/50000 (66%)]\tLoss: 2.246869, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 12 [34500/50000 (69%)]\tLoss: 2.196363, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 12 [36000/50000 (72%)]\tLoss: 2.151335, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 12 [37500/50000 (75%)]\tLoss: 2.349393, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 12 [39000/50000 (78%)]\tLoss: 2.163431, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 12 [40500/50000 (81%)]\tLoss: 2.228124, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 12 [42000/50000 (84%)]\tLoss: 2.275138, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 12 [43500/50000 (87%)]\tLoss: 2.170527, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 12 [45000/50000 (90%)]\tLoss: 2.231207, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 12 [46500/50000 (93%)]\tLoss: 2.186561, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 12 [48000/50000 (96%)]\tLoss: 2.219614, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 12 [49500/50000 (99%)]\tLoss: 2.274831, Accuracy: 19%, Learning rate: 0.100000\n",
            "\n",
            "Test set: Average loss: 1.6196, Accuracy: 6536/10000 (65%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 13 [1500/50000 (3%)]\tLoss: 2.181440, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 13 [3000/50000 (6%)]\tLoss: 2.330862, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 13 [4500/50000 (9%)]\tLoss: 2.201481, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 13 [6000/50000 (12%)]\tLoss: 2.077772, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 13 [7500/50000 (15%)]\tLoss: 2.196870, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 13 [9000/50000 (18%)]\tLoss: 2.054449, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 13 [10500/50000 (21%)]\tLoss: 2.187366, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 13 [12000/50000 (24%)]\tLoss: 2.259912, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 13 [13500/50000 (27%)]\tLoss: 2.257257, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 13 [15000/50000 (30%)]\tLoss: 2.261791, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 13 [16500/50000 (33%)]\tLoss: 2.209359, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 13 [18000/50000 (36%)]\tLoss: 2.288792, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 13 [19500/50000 (39%)]\tLoss: 2.199308, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 13 [21000/50000 (42%)]\tLoss: 2.196303, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 13 [22500/50000 (45%)]\tLoss: 2.166728, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 13 [24000/50000 (48%)]\tLoss: 2.282874, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 13 [25500/50000 (51%)]\tLoss: 2.197294, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 13 [27000/50000 (54%)]\tLoss: 2.228796, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 13 [28500/50000 (57%)]\tLoss: 2.219744, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 13 [30000/50000 (60%)]\tLoss: 2.285740, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 13 [31500/50000 (63%)]\tLoss: 2.196620, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 13 [33000/50000 (66%)]\tLoss: 2.214439, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 13 [34500/50000 (69%)]\tLoss: 2.181619, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 13 [36000/50000 (72%)]\tLoss: 2.194783, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 13 [37500/50000 (75%)]\tLoss: 2.156254, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 13 [39000/50000 (78%)]\tLoss: 2.264457, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 13 [40500/50000 (81%)]\tLoss: 2.219943, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 13 [42000/50000 (84%)]\tLoss: 2.134925, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 13 [43500/50000 (87%)]\tLoss: 2.278703, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 13 [45000/50000 (90%)]\tLoss: 2.183476, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 13 [46500/50000 (93%)]\tLoss: 2.217811, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 13 [48000/50000 (96%)]\tLoss: 2.161943, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 13 [49500/50000 (99%)]\tLoss: 2.196131, Accuracy: 19%, Learning rate: 0.100000\n",
            "\n",
            "Test set: Average loss: 1.6249, Accuracy: 6588/10000 (66%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 14 [1500/50000 (3%)]\tLoss: 2.264159, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 14 [3000/50000 (6%)]\tLoss: 2.189649, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 14 [4500/50000 (9%)]\tLoss: 2.267567, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 14 [6000/50000 (12%)]\tLoss: 2.212107, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 14 [7500/50000 (15%)]\tLoss: 2.208481, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 14 [9000/50000 (18%)]\tLoss: 2.235554, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 14 [10500/50000 (21%)]\tLoss: 2.159144, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 14 [12000/50000 (24%)]\tLoss: 2.259054, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 14 [13500/50000 (27%)]\tLoss: 2.225400, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 14 [15000/50000 (30%)]\tLoss: 2.128711, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 14 [16500/50000 (33%)]\tLoss: 2.226917, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 14 [18000/50000 (36%)]\tLoss: 2.213245, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 14 [19500/50000 (39%)]\tLoss: 2.282474, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 14 [21000/50000 (42%)]\tLoss: 2.237647, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 14 [22500/50000 (45%)]\tLoss: 2.226313, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 14 [24000/50000 (48%)]\tLoss: 2.242043, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 14 [25500/50000 (51%)]\tLoss: 2.195046, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 14 [27000/50000 (54%)]\tLoss: 2.100903, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 14 [28500/50000 (57%)]\tLoss: 2.233580, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 14 [30000/50000 (60%)]\tLoss: 2.107013, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 14 [31500/50000 (63%)]\tLoss: 2.162205, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 14 [33000/50000 (66%)]\tLoss: 2.211148, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 14 [34500/50000 (69%)]\tLoss: 2.246189, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 14 [36000/50000 (72%)]\tLoss: 2.196171, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 14 [37500/50000 (75%)]\tLoss: 2.136177, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 14 [39000/50000 (78%)]\tLoss: 2.183030, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 14 [40500/50000 (81%)]\tLoss: 2.233812, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 14 [42000/50000 (84%)]\tLoss: 2.258175, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 14 [43500/50000 (87%)]\tLoss: 2.228629, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 14 [45000/50000 (90%)]\tLoss: 2.230390, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 14 [46500/50000 (93%)]\tLoss: 2.196460, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 14 [48000/50000 (96%)]\tLoss: 2.160580, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 14 [49500/50000 (99%)]\tLoss: 2.220177, Accuracy: 20%, Learning rate: 0.100000\n",
            "\n",
            "Test set: Average loss: 1.6484, Accuracy: 6656/10000 (67%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 15 [1500/50000 (3%)]\tLoss: 2.117101, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 15 [3000/50000 (6%)]\tLoss: 2.242730, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 15 [4500/50000 (9%)]\tLoss: 2.086917, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 15 [6000/50000 (12%)]\tLoss: 2.272979, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 15 [7500/50000 (15%)]\tLoss: 2.177692, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 15 [9000/50000 (18%)]\tLoss: 2.266483, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 15 [10500/50000 (21%)]\tLoss: 2.167171, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 15 [12000/50000 (24%)]\tLoss: 2.247610, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 15 [13500/50000 (27%)]\tLoss: 2.179099, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 15 [15000/50000 (30%)]\tLoss: 2.223670, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 15 [16500/50000 (33%)]\tLoss: 2.188348, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 15 [18000/50000 (36%)]\tLoss: 2.243642, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 15 [19500/50000 (39%)]\tLoss: 2.222115, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 15 [21000/50000 (42%)]\tLoss: 2.148113, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 15 [22500/50000 (45%)]\tLoss: 2.318253, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 15 [24000/50000 (48%)]\tLoss: 2.208890, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 15 [25500/50000 (51%)]\tLoss: 2.178091, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 15 [27000/50000 (54%)]\tLoss: 2.222710, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 15 [28500/50000 (57%)]\tLoss: 2.263555, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 15 [30000/50000 (60%)]\tLoss: 2.197809, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 15 [31500/50000 (63%)]\tLoss: 2.061560, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 15 [33000/50000 (66%)]\tLoss: 2.089503, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 15 [34500/50000 (69%)]\tLoss: 2.183177, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 15 [36000/50000 (72%)]\tLoss: 2.180641, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 15 [37500/50000 (75%)]\tLoss: 2.101177, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 15 [39000/50000 (78%)]\tLoss: 2.212966, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 15 [40500/50000 (81%)]\tLoss: 2.085847, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 15 [42000/50000 (84%)]\tLoss: 2.149031, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 15 [43500/50000 (87%)]\tLoss: 2.338385, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 15 [45000/50000 (90%)]\tLoss: 2.243018, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 15 [46500/50000 (93%)]\tLoss: 1.953414, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 15 [48000/50000 (96%)]\tLoss: 2.232892, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 15 [49500/50000 (99%)]\tLoss: 2.235217, Accuracy: 19%, Learning rate: 0.100000\n",
            "\n",
            "Test set: Average loss: 1.5620, Accuracy: 6764/10000 (68%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 16 [1500/50000 (3%)]\tLoss: 2.216285, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 16 [3000/50000 (6%)]\tLoss: 2.150195, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 16 [4500/50000 (9%)]\tLoss: 2.208312, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 16 [6000/50000 (12%)]\tLoss: 2.161608, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 16 [7500/50000 (15%)]\tLoss: 2.204502, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 16 [9000/50000 (18%)]\tLoss: 2.154111, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 16 [10500/50000 (21%)]\tLoss: 2.173216, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 16 [12000/50000 (24%)]\tLoss: 2.178807, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 16 [13500/50000 (27%)]\tLoss: 2.163804, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 16 [15000/50000 (30%)]\tLoss: 2.275023, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 16 [16500/50000 (33%)]\tLoss: 2.292589, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 16 [18000/50000 (36%)]\tLoss: 2.269309, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 16 [19500/50000 (39%)]\tLoss: 2.187414, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 16 [21000/50000 (42%)]\tLoss: 2.196730, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 16 [22500/50000 (45%)]\tLoss: 2.160056, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 16 [24000/50000 (48%)]\tLoss: 2.287454, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 16 [25500/50000 (51%)]\tLoss: 2.292075, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 16 [27000/50000 (54%)]\tLoss: 2.268029, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 16 [28500/50000 (57%)]\tLoss: 2.165395, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 16 [30000/50000 (60%)]\tLoss: 2.225945, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 16 [31500/50000 (63%)]\tLoss: 2.221394, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 16 [33000/50000 (66%)]\tLoss: 2.190092, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 16 [34500/50000 (69%)]\tLoss: 2.197774, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 16 [36000/50000 (72%)]\tLoss: 2.227372, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 16 [37500/50000 (75%)]\tLoss: 2.162317, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 16 [39000/50000 (78%)]\tLoss: 2.233110, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 16 [40500/50000 (81%)]\tLoss: 2.231929, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 16 [42000/50000 (84%)]\tLoss: 2.166236, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 16 [43500/50000 (87%)]\tLoss: 2.215345, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 16 [45000/50000 (90%)]\tLoss: 2.136745, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 16 [46500/50000 (93%)]\tLoss: 2.170421, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 16 [48000/50000 (96%)]\tLoss: 2.309589, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 16 [49500/50000 (99%)]\tLoss: 2.177391, Accuracy: 19%, Learning rate: 0.100000\n",
            "\n",
            "Test set: Average loss: 1.5876, Accuracy: 6945/10000 (69%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 17 [1500/50000 (3%)]\tLoss: 2.143758, Accuracy: 25%, Learning rate: 0.100000\n",
            "Train Epoch: 17 [3000/50000 (6%)]\tLoss: 2.236181, Accuracy: 24%, Learning rate: 0.100000\n",
            "Train Epoch: 17 [4500/50000 (9%)]\tLoss: 2.309736, Accuracy: 23%, Learning rate: 0.100000\n",
            "Train Epoch: 17 [6000/50000 (12%)]\tLoss: 2.219781, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 17 [7500/50000 (15%)]\tLoss: 2.194012, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 17 [9000/50000 (18%)]\tLoss: 2.126612, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 17 [10500/50000 (21%)]\tLoss: 2.171206, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 17 [12000/50000 (24%)]\tLoss: 2.192106, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 17 [13500/50000 (27%)]\tLoss: 2.197046, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 17 [15000/50000 (30%)]\tLoss: 2.206098, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 17 [16500/50000 (33%)]\tLoss: 2.107914, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 17 [18000/50000 (36%)]\tLoss: 2.190419, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 17 [19500/50000 (39%)]\tLoss: 2.223774, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 17 [21000/50000 (42%)]\tLoss: 2.176447, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 17 [22500/50000 (45%)]\tLoss: 2.262691, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 17 [24000/50000 (48%)]\tLoss: 2.238702, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 17 [25500/50000 (51%)]\tLoss: 2.266906, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 17 [27000/50000 (54%)]\tLoss: 2.203830, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 17 [28500/50000 (57%)]\tLoss: 2.187105, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 17 [30000/50000 (60%)]\tLoss: 2.257154, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 17 [31500/50000 (63%)]\tLoss: 2.083025, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 17 [33000/50000 (66%)]\tLoss: 2.234248, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 17 [34500/50000 (69%)]\tLoss: 2.168271, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 17 [36000/50000 (72%)]\tLoss: 2.189726, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 17 [37500/50000 (75%)]\tLoss: 2.211889, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 17 [39000/50000 (78%)]\tLoss: 2.074249, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 17 [40500/50000 (81%)]\tLoss: 2.339063, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 17 [42000/50000 (84%)]\tLoss: 2.264737, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 17 [43500/50000 (87%)]\tLoss: 2.223306, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 17 [45000/50000 (90%)]\tLoss: 2.269300, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 17 [46500/50000 (93%)]\tLoss: 2.186245, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 17 [48000/50000 (96%)]\tLoss: 2.169096, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 17 [49500/50000 (99%)]\tLoss: 2.255048, Accuracy: 20%, Learning rate: 0.100000\n",
            "\n",
            "Test set: Average loss: 1.5556, Accuracy: 6700/10000 (67%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 18 [1500/50000 (3%)]\tLoss: 2.224686, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 18 [3000/50000 (6%)]\tLoss: 2.210817, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 18 [4500/50000 (9%)]\tLoss: 2.264664, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 18 [6000/50000 (12%)]\tLoss: 2.244819, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 18 [7500/50000 (15%)]\tLoss: 2.180124, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 18 [9000/50000 (18%)]\tLoss: 2.224663, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 18 [10500/50000 (21%)]\tLoss: 2.221130, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 18 [12000/50000 (24%)]\tLoss: 2.148104, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 18 [13500/50000 (27%)]\tLoss: 2.190113, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 18 [15000/50000 (30%)]\tLoss: 2.238471, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 18 [16500/50000 (33%)]\tLoss: 2.237890, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 18 [18000/50000 (36%)]\tLoss: 2.201397, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 18 [19500/50000 (39%)]\tLoss: 2.168906, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 18 [21000/50000 (42%)]\tLoss: 2.187019, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 18 [22500/50000 (45%)]\tLoss: 2.236666, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 18 [24000/50000 (48%)]\tLoss: 2.229892, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 18 [25500/50000 (51%)]\tLoss: 2.052074, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 18 [27000/50000 (54%)]\tLoss: 2.243611, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 18 [28500/50000 (57%)]\tLoss: 2.155436, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 18 [30000/50000 (60%)]\tLoss: 2.203707, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 18 [31500/50000 (63%)]\tLoss: 2.158984, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 18 [33000/50000 (66%)]\tLoss: 2.238827, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 18 [34500/50000 (69%)]\tLoss: 2.216014, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 18 [36000/50000 (72%)]\tLoss: 2.183844, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 18 [37500/50000 (75%)]\tLoss: 2.220494, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 18 [39000/50000 (78%)]\tLoss: 2.129290, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 18 [40500/50000 (81%)]\tLoss: 2.241575, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 18 [42000/50000 (84%)]\tLoss: 2.239782, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 18 [43500/50000 (87%)]\tLoss: 2.311752, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 18 [45000/50000 (90%)]\tLoss: 2.059521, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 18 [46500/50000 (93%)]\tLoss: 2.163413, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 18 [48000/50000 (96%)]\tLoss: 2.225300, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 18 [49500/50000 (99%)]\tLoss: 2.232235, Accuracy: 20%, Learning rate: 0.100000\n",
            "\n",
            "Test set: Average loss: 1.5572, Accuracy: 6736/10000 (67%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 19 [1500/50000 (3%)]\tLoss: 2.250441, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 19 [3000/50000 (6%)]\tLoss: 2.248116, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 19 [4500/50000 (9%)]\tLoss: 1.995786, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 19 [6000/50000 (12%)]\tLoss: 2.071274, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 19 [7500/50000 (15%)]\tLoss: 2.170801, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 19 [9000/50000 (18%)]\tLoss: 2.183114, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 19 [10500/50000 (21%)]\tLoss: 2.239918, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 19 [12000/50000 (24%)]\tLoss: 2.217007, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 19 [13500/50000 (27%)]\tLoss: 2.203494, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 19 [15000/50000 (30%)]\tLoss: 2.108535, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 19 [16500/50000 (33%)]\tLoss: 2.214828, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 19 [18000/50000 (36%)]\tLoss: 2.323564, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 19 [19500/50000 (39%)]\tLoss: 2.226010, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 19 [21000/50000 (42%)]\tLoss: 2.227118, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 19 [22500/50000 (45%)]\tLoss: 2.228422, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 19 [24000/50000 (48%)]\tLoss: 2.169118, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 19 [25500/50000 (51%)]\tLoss: 2.190000, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 19 [27000/50000 (54%)]\tLoss: 2.237284, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 19 [28500/50000 (57%)]\tLoss: 2.195577, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 19 [30000/50000 (60%)]\tLoss: 2.163006, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 19 [31500/50000 (63%)]\tLoss: 2.212656, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 19 [33000/50000 (66%)]\tLoss: 2.247915, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 19 [34500/50000 (69%)]\tLoss: 2.096745, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 19 [36000/50000 (72%)]\tLoss: 2.091665, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 19 [37500/50000 (75%)]\tLoss: 2.175636, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 19 [39000/50000 (78%)]\tLoss: 2.223567, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 19 [40500/50000 (81%)]\tLoss: 2.228486, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 19 [42000/50000 (84%)]\tLoss: 2.111311, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 19 [43500/50000 (87%)]\tLoss: 2.189185, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 19 [45000/50000 (90%)]\tLoss: 2.211354, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 19 [46500/50000 (93%)]\tLoss: 2.170860, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 19 [48000/50000 (96%)]\tLoss: 2.143728, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 19 [49500/50000 (99%)]\tLoss: 2.295527, Accuracy: 20%, Learning rate: 0.100000\n",
            "\n",
            "Test set: Average loss: 1.5752, Accuracy: 6738/10000 (67%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 20 [1500/50000 (3%)]\tLoss: 2.138504, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 20 [3000/50000 (6%)]\tLoss: 2.156672, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 20 [4500/50000 (9%)]\tLoss: 2.194948, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 20 [6000/50000 (12%)]\tLoss: 2.123372, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 20 [7500/50000 (15%)]\tLoss: 2.134932, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 20 [9000/50000 (18%)]\tLoss: 2.179109, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 20 [10500/50000 (21%)]\tLoss: 2.129911, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 20 [12000/50000 (24%)]\tLoss: 2.292214, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 20 [13500/50000 (27%)]\tLoss: 2.226201, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 20 [15000/50000 (30%)]\tLoss: 2.260613, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 20 [16500/50000 (33%)]\tLoss: 2.173602, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 20 [18000/50000 (36%)]\tLoss: 2.124762, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 20 [19500/50000 (39%)]\tLoss: 2.252339, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 20 [21000/50000 (42%)]\tLoss: 2.183460, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 20 [22500/50000 (45%)]\tLoss: 2.197954, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 20 [24000/50000 (48%)]\tLoss: 2.214124, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 20 [25500/50000 (51%)]\tLoss: 1.993413, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 20 [27000/50000 (54%)]\tLoss: 2.203815, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 20 [28500/50000 (57%)]\tLoss: 2.219942, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 20 [30000/50000 (60%)]\tLoss: 2.229259, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 20 [31500/50000 (63%)]\tLoss: 2.267196, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 20 [33000/50000 (66%)]\tLoss: 2.177992, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 20 [34500/50000 (69%)]\tLoss: 2.186281, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 20 [36000/50000 (72%)]\tLoss: 2.142310, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 20 [37500/50000 (75%)]\tLoss: 2.269710, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 20 [39000/50000 (78%)]\tLoss: 2.050164, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 20 [40500/50000 (81%)]\tLoss: 2.227097, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 20 [42000/50000 (84%)]\tLoss: 2.111224, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 20 [43500/50000 (87%)]\tLoss: 2.233607, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 20 [45000/50000 (90%)]\tLoss: 2.253468, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 20 [46500/50000 (93%)]\tLoss: 2.188177, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 20 [48000/50000 (96%)]\tLoss: 2.155252, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 20 [49500/50000 (99%)]\tLoss: 2.181602, Accuracy: 19%, Learning rate: 0.100000\n",
            "\n",
            "Test set: Average loss: 1.6162, Accuracy: 6571/10000 (66%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 21 [1500/50000 (3%)]\tLoss: 2.133969, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 21 [3000/50000 (6%)]\tLoss: 2.246933, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 21 [4500/50000 (9%)]\tLoss: 2.073487, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 21 [6000/50000 (12%)]\tLoss: 2.161411, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 21 [7500/50000 (15%)]\tLoss: 2.176165, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 21 [9000/50000 (18%)]\tLoss: 2.147264, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 21 [10500/50000 (21%)]\tLoss: 2.179858, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 21 [12000/50000 (24%)]\tLoss: 2.146519, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 21 [13500/50000 (27%)]\tLoss: 2.246287, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 21 [15000/50000 (30%)]\tLoss: 2.181818, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 21 [16500/50000 (33%)]\tLoss: 2.148198, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 21 [18000/50000 (36%)]\tLoss: 2.208368, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 21 [19500/50000 (39%)]\tLoss: 2.167360, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 21 [21000/50000 (42%)]\tLoss: 2.066297, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 21 [22500/50000 (45%)]\tLoss: 2.145693, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 21 [24000/50000 (48%)]\tLoss: 2.172779, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 21 [25500/50000 (51%)]\tLoss: 2.307729, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 21 [27000/50000 (54%)]\tLoss: 2.161362, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 21 [28500/50000 (57%)]\tLoss: 2.114833, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 21 [30000/50000 (60%)]\tLoss: 2.133482, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 21 [31500/50000 (63%)]\tLoss: 2.196506, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 21 [33000/50000 (66%)]\tLoss: 2.200797, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 21 [34500/50000 (69%)]\tLoss: 2.148772, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 21 [36000/50000 (72%)]\tLoss: 2.185299, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 21 [37500/50000 (75%)]\tLoss: 2.223079, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 21 [39000/50000 (78%)]\tLoss: 2.310531, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 21 [40500/50000 (81%)]\tLoss: 2.191831, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 21 [42000/50000 (84%)]\tLoss: 2.241665, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 21 [43500/50000 (87%)]\tLoss: 2.158408, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 21 [45000/50000 (90%)]\tLoss: 2.190173, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 21 [46500/50000 (93%)]\tLoss: 2.162281, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 21 [48000/50000 (96%)]\tLoss: 2.123705, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 21 [49500/50000 (99%)]\tLoss: 1.997729, Accuracy: 20%, Learning rate: 0.100000\n",
            "\n",
            "Test set: Average loss: 1.5356, Accuracy: 6897/10000 (69%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 22 [1500/50000 (3%)]\tLoss: 2.194157, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 22 [3000/50000 (6%)]\tLoss: 2.153234, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 22 [4500/50000 (9%)]\tLoss: 2.163144, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 22 [6000/50000 (12%)]\tLoss: 2.143084, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 22 [7500/50000 (15%)]\tLoss: 2.165880, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 22 [9000/50000 (18%)]\tLoss: 2.173050, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 22 [10500/50000 (21%)]\tLoss: 2.148698, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 22 [12000/50000 (24%)]\tLoss: 2.053735, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 22 [13500/50000 (27%)]\tLoss: 2.265356, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 22 [15000/50000 (30%)]\tLoss: 2.177460, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 22 [16500/50000 (33%)]\tLoss: 2.175583, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 22 [18000/50000 (36%)]\tLoss: 2.291646, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 22 [19500/50000 (39%)]\tLoss: 2.202094, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 22 [21000/50000 (42%)]\tLoss: 2.168260, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 22 [22500/50000 (45%)]\tLoss: 2.198673, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 22 [24000/50000 (48%)]\tLoss: 2.132347, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 22 [25500/50000 (51%)]\tLoss: 2.187519, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 22 [27000/50000 (54%)]\tLoss: 2.273251, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 22 [28500/50000 (57%)]\tLoss: 2.231763, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 22 [30000/50000 (60%)]\tLoss: 2.231205, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 22 [31500/50000 (63%)]\tLoss: 2.261801, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 22 [33000/50000 (66%)]\tLoss: 2.097124, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 22 [34500/50000 (69%)]\tLoss: 2.261277, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 22 [36000/50000 (72%)]\tLoss: 2.279535, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 22 [37500/50000 (75%)]\tLoss: 2.162686, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 22 [39000/50000 (78%)]\tLoss: 2.112875, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 22 [40500/50000 (81%)]\tLoss: 2.129430, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 22 [42000/50000 (84%)]\tLoss: 2.174538, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 22 [43500/50000 (87%)]\tLoss: 2.184307, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 22 [45000/50000 (90%)]\tLoss: 2.285594, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 22 [46500/50000 (93%)]\tLoss: 2.217605, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 22 [48000/50000 (96%)]\tLoss: 2.229883, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 22 [49500/50000 (99%)]\tLoss: 2.119243, Accuracy: 20%, Learning rate: 0.100000\n",
            "\n",
            "Test set: Average loss: 1.5116, Accuracy: 7174/10000 (72%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 23 [1500/50000 (3%)]\tLoss: 2.096091, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 23 [3000/50000 (6%)]\tLoss: 2.050052, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 23 [4500/50000 (9%)]\tLoss: 2.147395, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 23 [6000/50000 (12%)]\tLoss: 2.265437, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 23 [7500/50000 (15%)]\tLoss: 2.202224, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 23 [9000/50000 (18%)]\tLoss: 2.184954, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 23 [10500/50000 (21%)]\tLoss: 2.236535, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 23 [12000/50000 (24%)]\tLoss: 2.279855, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 23 [13500/50000 (27%)]\tLoss: 2.130720, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 23 [15000/50000 (30%)]\tLoss: 2.256553, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 23 [16500/50000 (33%)]\tLoss: 2.251794, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 23 [18000/50000 (36%)]\tLoss: 2.162670, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 23 [19500/50000 (39%)]\tLoss: 2.218577, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 23 [21000/50000 (42%)]\tLoss: 2.188852, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 23 [22500/50000 (45%)]\tLoss: 2.243897, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 23 [24000/50000 (48%)]\tLoss: 2.318286, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 23 [25500/50000 (51%)]\tLoss: 2.100048, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 23 [27000/50000 (54%)]\tLoss: 2.238628, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 23 [28500/50000 (57%)]\tLoss: 2.085734, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 23 [30000/50000 (60%)]\tLoss: 2.119699, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 23 [31500/50000 (63%)]\tLoss: 2.112388, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 23 [33000/50000 (66%)]\tLoss: 2.244004, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 23 [34500/50000 (69%)]\tLoss: 2.204305, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 23 [36000/50000 (72%)]\tLoss: 2.296417, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 23 [37500/50000 (75%)]\tLoss: 2.274985, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 23 [39000/50000 (78%)]\tLoss: 2.286395, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 23 [40500/50000 (81%)]\tLoss: 2.201981, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 23 [42000/50000 (84%)]\tLoss: 2.189541, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 23 [43500/50000 (87%)]\tLoss: 2.215210, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 23 [45000/50000 (90%)]\tLoss: 2.192205, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 23 [46500/50000 (93%)]\tLoss: 2.225232, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 23 [48000/50000 (96%)]\tLoss: 2.285716, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 23 [49500/50000 (99%)]\tLoss: 2.230698, Accuracy: 20%, Learning rate: 0.100000\n",
            "\n",
            "Test set: Average loss: 1.5218, Accuracy: 7094/10000 (71%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 24 [1500/50000 (3%)]\tLoss: 2.102658, Accuracy: 25%, Learning rate: 0.100000\n",
            "Train Epoch: 24 [3000/50000 (6%)]\tLoss: 2.123550, Accuracy: 25%, Learning rate: 0.100000\n",
            "Train Epoch: 24 [4500/50000 (9%)]\tLoss: 2.154002, Accuracy: 23%, Learning rate: 0.100000\n",
            "Train Epoch: 24 [6000/50000 (12%)]\tLoss: 2.176881, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 24 [7500/50000 (15%)]\tLoss: 2.163964, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 24 [9000/50000 (18%)]\tLoss: 2.231998, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 24 [10500/50000 (21%)]\tLoss: 2.218533, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 24 [12000/50000 (24%)]\tLoss: 2.231911, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 24 [13500/50000 (27%)]\tLoss: 2.138269, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 24 [15000/50000 (30%)]\tLoss: 2.252512, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 24 [16500/50000 (33%)]\tLoss: 2.191514, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 24 [18000/50000 (36%)]\tLoss: 2.146996, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 24 [19500/50000 (39%)]\tLoss: 2.113588, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 24 [21000/50000 (42%)]\tLoss: 2.216282, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 24 [22500/50000 (45%)]\tLoss: 2.155294, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 24 [24000/50000 (48%)]\tLoss: 2.134026, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 24 [25500/50000 (51%)]\tLoss: 2.248664, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 24 [27000/50000 (54%)]\tLoss: 2.239846, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 24 [28500/50000 (57%)]\tLoss: 2.149795, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 24 [30000/50000 (60%)]\tLoss: 2.092982, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 24 [31500/50000 (63%)]\tLoss: 2.113739, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 24 [33000/50000 (66%)]\tLoss: 2.192049, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 24 [34500/50000 (69%)]\tLoss: 2.197682, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 24 [36000/50000 (72%)]\tLoss: 2.243038, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 24 [37500/50000 (75%)]\tLoss: 2.265886, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 24 [39000/50000 (78%)]\tLoss: 2.152576, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 24 [40500/50000 (81%)]\tLoss: 2.117051, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 24 [42000/50000 (84%)]\tLoss: 2.129449, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 24 [43500/50000 (87%)]\tLoss: 2.204561, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 24 [45000/50000 (90%)]\tLoss: 2.234118, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 24 [46500/50000 (93%)]\tLoss: 2.192387, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 24 [48000/50000 (96%)]\tLoss: 2.067186, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 24 [49500/50000 (99%)]\tLoss: 2.149594, Accuracy: 20%, Learning rate: 0.100000\n",
            "\n",
            "Test set: Average loss: 1.5348, Accuracy: 6937/10000 (69%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 25 [1500/50000 (3%)]\tLoss: 2.130914, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 25 [3000/50000 (6%)]\tLoss: 2.110314, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 25 [4500/50000 (9%)]\tLoss: 2.181402, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 25 [6000/50000 (12%)]\tLoss: 2.299170, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 25 [7500/50000 (15%)]\tLoss: 2.181462, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 25 [9000/50000 (18%)]\tLoss: 2.181721, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 25 [10500/50000 (21%)]\tLoss: 2.304884, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 25 [12000/50000 (24%)]\tLoss: 2.030157, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 25 [13500/50000 (27%)]\tLoss: 2.143772, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 25 [15000/50000 (30%)]\tLoss: 2.243154, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 25 [16500/50000 (33%)]\tLoss: 2.171398, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 25 [18000/50000 (36%)]\tLoss: 2.250391, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 25 [19500/50000 (39%)]\tLoss: 2.183816, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 25 [21000/50000 (42%)]\tLoss: 2.224536, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 25 [22500/50000 (45%)]\tLoss: 2.205430, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 25 [24000/50000 (48%)]\tLoss: 2.281171, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 25 [25500/50000 (51%)]\tLoss: 2.166611, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 25 [27000/50000 (54%)]\tLoss: 2.188660, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 25 [28500/50000 (57%)]\tLoss: 2.116192, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 25 [30000/50000 (60%)]\tLoss: 2.268719, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 25 [31500/50000 (63%)]\tLoss: 2.144812, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 25 [33000/50000 (66%)]\tLoss: 2.275646, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 25 [34500/50000 (69%)]\tLoss: 2.220519, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 25 [36000/50000 (72%)]\tLoss: 2.263820, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 25 [37500/50000 (75%)]\tLoss: 2.181044, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 25 [39000/50000 (78%)]\tLoss: 2.122409, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 25 [40500/50000 (81%)]\tLoss: 2.243244, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 25 [42000/50000 (84%)]\tLoss: 2.181392, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 25 [43500/50000 (87%)]\tLoss: 2.187435, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 25 [45000/50000 (90%)]\tLoss: 2.207252, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 25 [46500/50000 (93%)]\tLoss: 2.198246, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 25 [48000/50000 (96%)]\tLoss: 2.225557, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 25 [49500/50000 (99%)]\tLoss: 2.196412, Accuracy: 21%, Learning rate: 0.100000\n",
            "\n",
            "Test set: Average loss: 1.5475, Accuracy: 7434/10000 (74%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 26 [1500/50000 (3%)]\tLoss: 2.169006, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 26 [3000/50000 (6%)]\tLoss: 2.208076, Accuracy: 17%, Learning rate: 0.100000\n",
            "Train Epoch: 26 [4500/50000 (9%)]\tLoss: 2.185555, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 26 [6000/50000 (12%)]\tLoss: 2.134788, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 26 [7500/50000 (15%)]\tLoss: 2.179685, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 26 [9000/50000 (18%)]\tLoss: 2.191747, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 26 [10500/50000 (21%)]\tLoss: 2.189662, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 26 [12000/50000 (24%)]\tLoss: 2.164565, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 26 [13500/50000 (27%)]\tLoss: 2.092042, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 26 [15000/50000 (30%)]\tLoss: 2.185694, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 26 [16500/50000 (33%)]\tLoss: 2.216232, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 26 [18000/50000 (36%)]\tLoss: 2.137579, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 26 [19500/50000 (39%)]\tLoss: 2.046542, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 26 [21000/50000 (42%)]\tLoss: 2.165816, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 26 [22500/50000 (45%)]\tLoss: 2.195436, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 26 [24000/50000 (48%)]\tLoss: 2.131170, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 26 [25500/50000 (51%)]\tLoss: 2.179689, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 26 [27000/50000 (54%)]\tLoss: 2.222907, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 26 [28500/50000 (57%)]\tLoss: 2.173939, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 26 [30000/50000 (60%)]\tLoss: 2.168239, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 26 [31500/50000 (63%)]\tLoss: 2.157853, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 26 [33000/50000 (66%)]\tLoss: 2.219537, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 26 [34500/50000 (69%)]\tLoss: 2.140142, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 26 [36000/50000 (72%)]\tLoss: 2.161354, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 26 [37500/50000 (75%)]\tLoss: 2.134523, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 26 [39000/50000 (78%)]\tLoss: 2.214088, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 26 [40500/50000 (81%)]\tLoss: 2.206470, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 26 [42000/50000 (84%)]\tLoss: 2.254642, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 26 [43500/50000 (87%)]\tLoss: 2.220622, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 26 [45000/50000 (90%)]\tLoss: 2.152871, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 26 [46500/50000 (93%)]\tLoss: 2.229537, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 26 [48000/50000 (96%)]\tLoss: 2.190045, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 26 [49500/50000 (99%)]\tLoss: 2.263678, Accuracy: 21%, Learning rate: 0.100000\n",
            "\n",
            "Test set: Average loss: 1.5263, Accuracy: 7409/10000 (74%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 27 [1500/50000 (3%)]\tLoss: 2.201182, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 27 [3000/50000 (6%)]\tLoss: 2.154745, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 27 [4500/50000 (9%)]\tLoss: 2.188733, Accuracy: 23%, Learning rate: 0.100000\n",
            "Train Epoch: 27 [6000/50000 (12%)]\tLoss: 2.137127, Accuracy: 23%, Learning rate: 0.100000\n",
            "Train Epoch: 27 [7500/50000 (15%)]\tLoss: 2.218115, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 27 [9000/50000 (18%)]\tLoss: 2.261979, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 27 [10500/50000 (21%)]\tLoss: 2.245809, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 27 [12000/50000 (24%)]\tLoss: 2.135067, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 27 [13500/50000 (27%)]\tLoss: 2.216785, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 27 [15000/50000 (30%)]\tLoss: 2.096115, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 27 [16500/50000 (33%)]\tLoss: 2.176015, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 27 [18000/50000 (36%)]\tLoss: 2.270789, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 27 [19500/50000 (39%)]\tLoss: 2.149104, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 27 [21000/50000 (42%)]\tLoss: 2.182505, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 27 [22500/50000 (45%)]\tLoss: 2.057575, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 27 [24000/50000 (48%)]\tLoss: 2.154026, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 27 [25500/50000 (51%)]\tLoss: 2.187425, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 27 [27000/50000 (54%)]\tLoss: 2.098784, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 27 [28500/50000 (57%)]\tLoss: 2.267758, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 27 [30000/50000 (60%)]\tLoss: 2.196237, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 27 [31500/50000 (63%)]\tLoss: 2.033185, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 27 [33000/50000 (66%)]\tLoss: 2.171708, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 27 [34500/50000 (69%)]\tLoss: 2.112174, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 27 [36000/50000 (72%)]\tLoss: 2.283902, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 27 [37500/50000 (75%)]\tLoss: 2.217206, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 27 [39000/50000 (78%)]\tLoss: 2.127769, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 27 [40500/50000 (81%)]\tLoss: 2.162504, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 27 [42000/50000 (84%)]\tLoss: 2.259315, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 27 [43500/50000 (87%)]\tLoss: 2.184380, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 27 [45000/50000 (90%)]\tLoss: 2.180280, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 27 [46500/50000 (93%)]\tLoss: 2.095688, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 27 [48000/50000 (96%)]\tLoss: 2.243133, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 27 [49500/50000 (99%)]\tLoss: 2.172340, Accuracy: 21%, Learning rate: 0.100000\n",
            "\n",
            "Test set: Average loss: 1.5499, Accuracy: 7036/10000 (70%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 28 [1500/50000 (3%)]\tLoss: 2.255587, Accuracy: 16%, Learning rate: 0.100000\n",
            "Train Epoch: 28 [3000/50000 (6%)]\tLoss: 2.244104, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 28 [4500/50000 (9%)]\tLoss: 2.017603, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 28 [6000/50000 (12%)]\tLoss: 2.114776, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 28 [7500/50000 (15%)]\tLoss: 2.321374, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 28 [9000/50000 (18%)]\tLoss: 2.107709, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 28 [10500/50000 (21%)]\tLoss: 2.225486, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 28 [12000/50000 (24%)]\tLoss: 2.114742, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 28 [13500/50000 (27%)]\tLoss: 2.159376, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 28 [15000/50000 (30%)]\tLoss: 2.175406, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 28 [16500/50000 (33%)]\tLoss: 2.193795, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 28 [18000/50000 (36%)]\tLoss: 2.106868, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 28 [19500/50000 (39%)]\tLoss: 2.253523, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 28 [21000/50000 (42%)]\tLoss: 2.138404, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 28 [22500/50000 (45%)]\tLoss: 2.159611, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 28 [24000/50000 (48%)]\tLoss: 2.070218, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 28 [25500/50000 (51%)]\tLoss: 2.187057, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 28 [27000/50000 (54%)]\tLoss: 2.114604, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 28 [28500/50000 (57%)]\tLoss: 2.046141, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 28 [30000/50000 (60%)]\tLoss: 2.156627, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 28 [31500/50000 (63%)]\tLoss: 2.032782, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 28 [33000/50000 (66%)]\tLoss: 2.205797, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 28 [34500/50000 (69%)]\tLoss: 2.153436, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 28 [36000/50000 (72%)]\tLoss: 2.262306, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 28 [37500/50000 (75%)]\tLoss: 2.196767, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 28 [39000/50000 (78%)]\tLoss: 2.134322, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 28 [40500/50000 (81%)]\tLoss: 2.125669, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 28 [42000/50000 (84%)]\tLoss: 2.197805, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 28 [43500/50000 (87%)]\tLoss: 2.117635, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 28 [45000/50000 (90%)]\tLoss: 2.121537, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 28 [46500/50000 (93%)]\tLoss: 2.239726, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 28 [48000/50000 (96%)]\tLoss: 2.266889, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 28 [49500/50000 (99%)]\tLoss: 2.198500, Accuracy: 21%, Learning rate: 0.100000\n",
            "\n",
            "Test set: Average loss: 1.5537, Accuracy: 7219/10000 (72%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 29 [1500/50000 (3%)]\tLoss: 2.183118, Accuracy: 24%, Learning rate: 0.100000\n",
            "Train Epoch: 29 [3000/50000 (6%)]\tLoss: 2.239058, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 29 [4500/50000 (9%)]\tLoss: 2.230413, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 29 [6000/50000 (12%)]\tLoss: 2.245471, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 29 [7500/50000 (15%)]\tLoss: 2.159359, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 29 [9000/50000 (18%)]\tLoss: 2.224161, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 29 [10500/50000 (21%)]\tLoss: 2.096549, Accuracy: 18%, Learning rate: 0.100000\n",
            "Train Epoch: 29 [12000/50000 (24%)]\tLoss: 2.262677, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 29 [13500/50000 (27%)]\tLoss: 2.214218, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 29 [15000/50000 (30%)]\tLoss: 2.235212, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 29 [16500/50000 (33%)]\tLoss: 2.210044, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 29 [18000/50000 (36%)]\tLoss: 2.291996, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 29 [19500/50000 (39%)]\tLoss: 2.179609, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 29 [21000/50000 (42%)]\tLoss: 2.220965, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 29 [22500/50000 (45%)]\tLoss: 2.076010, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 29 [24000/50000 (48%)]\tLoss: 2.303398, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 29 [25500/50000 (51%)]\tLoss: 2.024672, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 29 [27000/50000 (54%)]\tLoss: 2.110636, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 29 [28500/50000 (57%)]\tLoss: 2.274572, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 29 [30000/50000 (60%)]\tLoss: 2.194784, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 29 [31500/50000 (63%)]\tLoss: 2.238769, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 29 [33000/50000 (66%)]\tLoss: 1.965883, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 29 [34500/50000 (69%)]\tLoss: 2.150830, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 29 [36000/50000 (72%)]\tLoss: 2.181469, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 29 [37500/50000 (75%)]\tLoss: 2.237679, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 29 [39000/50000 (78%)]\tLoss: 2.175611, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 29 [40500/50000 (81%)]\tLoss: 2.251702, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 29 [42000/50000 (84%)]\tLoss: 2.234875, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 29 [43500/50000 (87%)]\tLoss: 2.121321, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 29 [45000/50000 (90%)]\tLoss: 2.153807, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 29 [46500/50000 (93%)]\tLoss: 2.143028, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 29 [48000/50000 (96%)]\tLoss: 2.169251, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 29 [49500/50000 (99%)]\tLoss: 2.168925, Accuracy: 20%, Learning rate: 0.100000\n",
            "\n",
            "Test set: Average loss: 1.4856, Accuracy: 7420/10000 (74%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 30 [1500/50000 (3%)]\tLoss: 2.115079, Accuracy: 23%, Learning rate: 0.100000\n",
            "Train Epoch: 30 [3000/50000 (6%)]\tLoss: 2.258160, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 30 [4500/50000 (9%)]\tLoss: 2.155918, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 30 [6000/50000 (12%)]\tLoss: 2.262629, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 30 [7500/50000 (15%)]\tLoss: 2.064586, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 30 [9000/50000 (18%)]\tLoss: 2.226092, Accuracy: 23%, Learning rate: 0.100000\n",
            "Train Epoch: 30 [10500/50000 (21%)]\tLoss: 2.004220, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 30 [12000/50000 (24%)]\tLoss: 2.155878, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 30 [13500/50000 (27%)]\tLoss: 2.269881, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 30 [15000/50000 (30%)]\tLoss: 2.107613, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 30 [16500/50000 (33%)]\tLoss: 2.106806, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 30 [18000/50000 (36%)]\tLoss: 2.154471, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 30 [19500/50000 (39%)]\tLoss: 2.257684, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 30 [21000/50000 (42%)]\tLoss: 2.140399, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 30 [22500/50000 (45%)]\tLoss: 2.175614, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 30 [24000/50000 (48%)]\tLoss: 2.094639, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 30 [25500/50000 (51%)]\tLoss: 2.213087, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 30 [27000/50000 (54%)]\tLoss: 2.124358, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 30 [28500/50000 (57%)]\tLoss: 2.143778, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 30 [30000/50000 (60%)]\tLoss: 2.158529, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 30 [31500/50000 (63%)]\tLoss: 2.262301, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 30 [33000/50000 (66%)]\tLoss: 2.142598, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 30 [34500/50000 (69%)]\tLoss: 2.166696, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 30 [36000/50000 (72%)]\tLoss: 2.130350, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 30 [37500/50000 (75%)]\tLoss: 2.128330, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 30 [39000/50000 (78%)]\tLoss: 2.254203, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 30 [40500/50000 (81%)]\tLoss: 2.266907, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 30 [42000/50000 (84%)]\tLoss: 2.211525, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 30 [43500/50000 (87%)]\tLoss: 2.163226, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 30 [45000/50000 (90%)]\tLoss: 2.251714, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 30 [46500/50000 (93%)]\tLoss: 2.165029, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 30 [48000/50000 (96%)]\tLoss: 2.087992, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 30 [49500/50000 (99%)]\tLoss: 2.201941, Accuracy: 22%, Learning rate: 0.100000\n",
            "\n",
            "Test set: Average loss: 1.5207, Accuracy: 7158/10000 (72%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 31 [1500/50000 (3%)]\tLoss: 2.124382, Accuracy: 23%, Learning rate: 0.100000\n",
            "Train Epoch: 31 [3000/50000 (6%)]\tLoss: 2.065813, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 31 [4500/50000 (9%)]\tLoss: 2.261292, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 31 [6000/50000 (12%)]\tLoss: 2.108972, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 31 [7500/50000 (15%)]\tLoss: 2.270278, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 31 [9000/50000 (18%)]\tLoss: 2.172951, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 31 [10500/50000 (21%)]\tLoss: 2.135392, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 31 [12000/50000 (24%)]\tLoss: 2.100707, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 31 [13500/50000 (27%)]\tLoss: 2.108545, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 31 [15000/50000 (30%)]\tLoss: 2.260864, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 31 [16500/50000 (33%)]\tLoss: 2.206342, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 31 [18000/50000 (36%)]\tLoss: 2.033442, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 31 [19500/50000 (39%)]\tLoss: 2.155732, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 31 [21000/50000 (42%)]\tLoss: 2.142299, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 31 [22500/50000 (45%)]\tLoss: 2.117452, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 31 [24000/50000 (48%)]\tLoss: 2.241341, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 31 [25500/50000 (51%)]\tLoss: 2.109950, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 31 [27000/50000 (54%)]\tLoss: 2.233985, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 31 [28500/50000 (57%)]\tLoss: 2.172728, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 31 [30000/50000 (60%)]\tLoss: 2.243228, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 31 [31500/50000 (63%)]\tLoss: 2.113990, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 31 [33000/50000 (66%)]\tLoss: 2.224432, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 31 [34500/50000 (69%)]\tLoss: 2.127295, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 31 [36000/50000 (72%)]\tLoss: 2.182167, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 31 [37500/50000 (75%)]\tLoss: 2.284036, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 31 [39000/50000 (78%)]\tLoss: 2.218590, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 31 [40500/50000 (81%)]\tLoss: 2.134236, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 31 [42000/50000 (84%)]\tLoss: 2.113137, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 31 [43500/50000 (87%)]\tLoss: 2.104193, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 31 [45000/50000 (90%)]\tLoss: 2.168666, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 31 [46500/50000 (93%)]\tLoss: 2.271716, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 31 [48000/50000 (96%)]\tLoss: 2.210525, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 31 [49500/50000 (99%)]\tLoss: 2.166746, Accuracy: 21%, Learning rate: 0.100000\n",
            "\n",
            "Test set: Average loss: 1.4460, Accuracy: 7247/10000 (72%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 32 [1500/50000 (3%)]\tLoss: 2.295327, Accuracy: 23%, Learning rate: 0.100000\n",
            "Train Epoch: 32 [3000/50000 (6%)]\tLoss: 2.027646, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 32 [4500/50000 (9%)]\tLoss: 2.079225, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 32 [6000/50000 (12%)]\tLoss: 2.082816, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 32 [7500/50000 (15%)]\tLoss: 2.109077, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 32 [9000/50000 (18%)]\tLoss: 2.017350, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 32 [10500/50000 (21%)]\tLoss: 2.026269, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 32 [12000/50000 (24%)]\tLoss: 2.187034, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 32 [13500/50000 (27%)]\tLoss: 2.200557, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 32 [15000/50000 (30%)]\tLoss: 2.227579, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 32 [16500/50000 (33%)]\tLoss: 2.296133, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 32 [18000/50000 (36%)]\tLoss: 2.145196, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 32 [19500/50000 (39%)]\tLoss: 2.160430, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 32 [21000/50000 (42%)]\tLoss: 2.148698, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 32 [22500/50000 (45%)]\tLoss: 2.115658, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 32 [24000/50000 (48%)]\tLoss: 2.163130, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 32 [25500/50000 (51%)]\tLoss: 2.150314, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 32 [27000/50000 (54%)]\tLoss: 2.172906, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 32 [28500/50000 (57%)]\tLoss: 2.131506, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 32 [30000/50000 (60%)]\tLoss: 2.070333, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 32 [31500/50000 (63%)]\tLoss: 2.198057, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 32 [33000/50000 (66%)]\tLoss: 2.126306, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 32 [34500/50000 (69%)]\tLoss: 2.277134, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 32 [36000/50000 (72%)]\tLoss: 2.176013, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 32 [37500/50000 (75%)]\tLoss: 2.208505, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 32 [39000/50000 (78%)]\tLoss: 2.143894, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 32 [40500/50000 (81%)]\tLoss: 2.213636, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 32 [42000/50000 (84%)]\tLoss: 2.175247, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 32 [43500/50000 (87%)]\tLoss: 2.254817, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 32 [45000/50000 (90%)]\tLoss: 2.193171, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 32 [46500/50000 (93%)]\tLoss: 2.122418, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 32 [48000/50000 (96%)]\tLoss: 2.231679, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 32 [49500/50000 (99%)]\tLoss: 2.065830, Accuracy: 21%, Learning rate: 0.100000\n",
            "\n",
            "Test set: Average loss: 1.5085, Accuracy: 7265/10000 (73%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 33 [1500/50000 (3%)]\tLoss: 2.080013, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 33 [3000/50000 (6%)]\tLoss: 2.177346, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 33 [4500/50000 (9%)]\tLoss: 2.119024, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 33 [6000/50000 (12%)]\tLoss: 2.147894, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 33 [7500/50000 (15%)]\tLoss: 2.252518, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 33 [9000/50000 (18%)]\tLoss: 2.198240, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 33 [10500/50000 (21%)]\tLoss: 2.248288, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 33 [12000/50000 (24%)]\tLoss: 2.255924, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 33 [13500/50000 (27%)]\tLoss: 2.093273, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 33 [15000/50000 (30%)]\tLoss: 2.191271, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 33 [16500/50000 (33%)]\tLoss: 2.087224, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 33 [18000/50000 (36%)]\tLoss: 2.156911, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 33 [19500/50000 (39%)]\tLoss: 2.160728, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 33 [21000/50000 (42%)]\tLoss: 2.220670, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 33 [22500/50000 (45%)]\tLoss: 2.182980, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 33 [24000/50000 (48%)]\tLoss: 2.178499, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 33 [25500/50000 (51%)]\tLoss: 2.114086, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 33 [27000/50000 (54%)]\tLoss: 2.208402, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 33 [28500/50000 (57%)]\tLoss: 2.215486, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 33 [30000/50000 (60%)]\tLoss: 2.031403, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 33 [31500/50000 (63%)]\tLoss: 2.085994, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 33 [33000/50000 (66%)]\tLoss: 2.238203, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 33 [34500/50000 (69%)]\tLoss: 2.254292, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 33 [36000/50000 (72%)]\tLoss: 2.117913, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 33 [37500/50000 (75%)]\tLoss: 2.181667, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 33 [39000/50000 (78%)]\tLoss: 2.137033, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 33 [40500/50000 (81%)]\tLoss: 2.231026, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 33 [42000/50000 (84%)]\tLoss: 2.128039, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 33 [43500/50000 (87%)]\tLoss: 2.229815, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 33 [45000/50000 (90%)]\tLoss: 2.252661, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 33 [46500/50000 (93%)]\tLoss: 2.222148, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 33 [48000/50000 (96%)]\tLoss: 2.265197, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 33 [49500/50000 (99%)]\tLoss: 2.226345, Accuracy: 21%, Learning rate: 0.100000\n",
            "\n",
            "Test set: Average loss: 1.5252, Accuracy: 7227/10000 (72%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 34 [1500/50000 (3%)]\tLoss: 2.253679, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 34 [3000/50000 (6%)]\tLoss: 2.173380, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 34 [4500/50000 (9%)]\tLoss: 2.147929, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 34 [6000/50000 (12%)]\tLoss: 2.093969, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 34 [7500/50000 (15%)]\tLoss: 2.154282, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 34 [9000/50000 (18%)]\tLoss: 2.186455, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 34 [10500/50000 (21%)]\tLoss: 2.258883, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 34 [12000/50000 (24%)]\tLoss: 2.166244, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 34 [13500/50000 (27%)]\tLoss: 2.204192, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 34 [15000/50000 (30%)]\tLoss: 2.156980, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 34 [16500/50000 (33%)]\tLoss: 2.207561, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 34 [18000/50000 (36%)]\tLoss: 2.227110, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 34 [19500/50000 (39%)]\tLoss: 2.186623, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 34 [21000/50000 (42%)]\tLoss: 2.227380, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 34 [22500/50000 (45%)]\tLoss: 2.199721, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 34 [24000/50000 (48%)]\tLoss: 2.095523, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 34 [25500/50000 (51%)]\tLoss: 2.215474, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 34 [27000/50000 (54%)]\tLoss: 1.963205, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 34 [28500/50000 (57%)]\tLoss: 2.049814, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 34 [30000/50000 (60%)]\tLoss: 2.162299, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 34 [31500/50000 (63%)]\tLoss: 2.085227, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 34 [33000/50000 (66%)]\tLoss: 2.243039, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 34 [34500/50000 (69%)]\tLoss: 2.176929, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 34 [36000/50000 (72%)]\tLoss: 2.165419, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 34 [37500/50000 (75%)]\tLoss: 2.130143, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 34 [39000/50000 (78%)]\tLoss: 2.176188, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 34 [40500/50000 (81%)]\tLoss: 2.242339, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 34 [42000/50000 (84%)]\tLoss: 2.205643, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 34 [43500/50000 (87%)]\tLoss: 2.115100, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 34 [45000/50000 (90%)]\tLoss: 2.156893, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 34 [46500/50000 (93%)]\tLoss: 2.143452, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 34 [48000/50000 (96%)]\tLoss: 2.212889, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 34 [49500/50000 (99%)]\tLoss: 2.336384, Accuracy: 20%, Learning rate: 0.100000\n",
            "\n",
            "Test set: Average loss: 1.5408, Accuracy: 7596/10000 (76%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 35 [1500/50000 (3%)]\tLoss: 2.035522, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 35 [3000/50000 (6%)]\tLoss: 2.048375, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 35 [4500/50000 (9%)]\tLoss: 2.125558, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 35 [6000/50000 (12%)]\tLoss: 2.213025, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 35 [7500/50000 (15%)]\tLoss: 2.237170, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 35 [9000/50000 (18%)]\tLoss: 2.191846, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 35 [10500/50000 (21%)]\tLoss: 2.192375, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 35 [12000/50000 (24%)]\tLoss: 2.118823, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 35 [13500/50000 (27%)]\tLoss: 2.249153, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 35 [15000/50000 (30%)]\tLoss: 2.091313, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 35 [16500/50000 (33%)]\tLoss: 2.210070, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 35 [18000/50000 (36%)]\tLoss: 2.146150, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 35 [19500/50000 (39%)]\tLoss: 2.256244, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 35 [21000/50000 (42%)]\tLoss: 2.163680, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 35 [22500/50000 (45%)]\tLoss: 2.181398, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 35 [24000/50000 (48%)]\tLoss: 2.133344, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 35 [25500/50000 (51%)]\tLoss: 2.265600, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 35 [27000/50000 (54%)]\tLoss: 2.097343, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 35 [28500/50000 (57%)]\tLoss: 2.186039, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 35 [30000/50000 (60%)]\tLoss: 2.169748, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 35 [31500/50000 (63%)]\tLoss: 2.222086, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 35 [33000/50000 (66%)]\tLoss: 2.273871, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 35 [34500/50000 (69%)]\tLoss: 2.204778, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 35 [36000/50000 (72%)]\tLoss: 2.258830, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 35 [37500/50000 (75%)]\tLoss: 2.215396, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 35 [39000/50000 (78%)]\tLoss: 2.133060, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 35 [40500/50000 (81%)]\tLoss: 2.144331, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 35 [42000/50000 (84%)]\tLoss: 2.204566, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 35 [43500/50000 (87%)]\tLoss: 2.065087, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 35 [45000/50000 (90%)]\tLoss: 2.070027, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 35 [46500/50000 (93%)]\tLoss: 2.246520, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 35 [48000/50000 (96%)]\tLoss: 2.232964, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 35 [49500/50000 (99%)]\tLoss: 2.148668, Accuracy: 21%, Learning rate: 0.100000\n",
            "\n",
            "Test set: Average loss: 1.4922, Accuracy: 7328/10000 (73%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 36 [1500/50000 (3%)]\tLoss: 2.050744, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 36 [3000/50000 (6%)]\tLoss: 2.207403, Accuracy: 23%, Learning rate: 0.100000\n",
            "Train Epoch: 36 [4500/50000 (9%)]\tLoss: 2.006951, Accuracy: 23%, Learning rate: 0.100000\n",
            "Train Epoch: 36 [6000/50000 (12%)]\tLoss: 2.065623, Accuracy: 24%, Learning rate: 0.100000\n",
            "Train Epoch: 36 [7500/50000 (15%)]\tLoss: 2.114239, Accuracy: 23%, Learning rate: 0.100000\n",
            "Train Epoch: 36 [9000/50000 (18%)]\tLoss: 2.237269, Accuracy: 23%, Learning rate: 0.100000\n",
            "Train Epoch: 36 [10500/50000 (21%)]\tLoss: 2.124547, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 36 [12000/50000 (24%)]\tLoss: 2.224259, Accuracy: 23%, Learning rate: 0.100000\n",
            "Train Epoch: 36 [13500/50000 (27%)]\tLoss: 2.280997, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 36 [15000/50000 (30%)]\tLoss: 2.221160, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 36 [16500/50000 (33%)]\tLoss: 2.289043, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 36 [18000/50000 (36%)]\tLoss: 2.222668, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 36 [19500/50000 (39%)]\tLoss: 2.142227, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 36 [21000/50000 (42%)]\tLoss: 2.119236, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 36 [22500/50000 (45%)]\tLoss: 2.088696, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 36 [24000/50000 (48%)]\tLoss: 2.195302, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 36 [25500/50000 (51%)]\tLoss: 2.231962, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 36 [27000/50000 (54%)]\tLoss: 2.271253, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 36 [28500/50000 (57%)]\tLoss: 2.268317, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 36 [30000/50000 (60%)]\tLoss: 2.103140, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 36 [31500/50000 (63%)]\tLoss: 2.066082, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 36 [33000/50000 (66%)]\tLoss: 2.156236, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 36 [34500/50000 (69%)]\tLoss: 2.171785, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 36 [36000/50000 (72%)]\tLoss: 2.248806, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 36 [37500/50000 (75%)]\tLoss: 2.304274, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 36 [39000/50000 (78%)]\tLoss: 2.097671, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 36 [40500/50000 (81%)]\tLoss: 2.166435, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 36 [42000/50000 (84%)]\tLoss: 2.171022, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 36 [43500/50000 (87%)]\tLoss: 2.145790, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 36 [45000/50000 (90%)]\tLoss: 2.142923, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 36 [46500/50000 (93%)]\tLoss: 2.203228, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 36 [48000/50000 (96%)]\tLoss: 2.084017, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 36 [49500/50000 (99%)]\tLoss: 2.192044, Accuracy: 21%, Learning rate: 0.100000\n",
            "\n",
            "Test set: Average loss: 1.4691, Accuracy: 7258/10000 (73%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 37 [1500/50000 (3%)]\tLoss: 2.122694, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 37 [3000/50000 (6%)]\tLoss: 2.099256, Accuracy: 24%, Learning rate: 0.100000\n",
            "Train Epoch: 37 [4500/50000 (9%)]\tLoss: 2.259502, Accuracy: 23%, Learning rate: 0.100000\n",
            "Train Epoch: 37 [6000/50000 (12%)]\tLoss: 2.240669, Accuracy: 23%, Learning rate: 0.100000\n",
            "Train Epoch: 37 [7500/50000 (15%)]\tLoss: 2.140087, Accuracy: 23%, Learning rate: 0.100000\n",
            "Train Epoch: 37 [9000/50000 (18%)]\tLoss: 2.157316, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 37 [10500/50000 (21%)]\tLoss: 2.255407, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 37 [12000/50000 (24%)]\tLoss: 2.163046, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 37 [13500/50000 (27%)]\tLoss: 2.204622, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 37 [15000/50000 (30%)]\tLoss: 2.012199, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 37 [16500/50000 (33%)]\tLoss: 2.155509, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 37 [18000/50000 (36%)]\tLoss: 2.115319, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 37 [19500/50000 (39%)]\tLoss: 2.186759, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 37 [21000/50000 (42%)]\tLoss: 2.201478, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 37 [22500/50000 (45%)]\tLoss: 2.127997, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 37 [24000/50000 (48%)]\tLoss: 2.247664, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 37 [25500/50000 (51%)]\tLoss: 2.234682, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 37 [27000/50000 (54%)]\tLoss: 2.237682, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 37 [28500/50000 (57%)]\tLoss: 2.183070, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 37 [30000/50000 (60%)]\tLoss: 2.166507, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 37 [31500/50000 (63%)]\tLoss: 2.215801, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 37 [33000/50000 (66%)]\tLoss: 2.156365, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 37 [34500/50000 (69%)]\tLoss: 2.275525, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 37 [36000/50000 (72%)]\tLoss: 2.162471, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 37 [37500/50000 (75%)]\tLoss: 2.254857, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 37 [39000/50000 (78%)]\tLoss: 2.122568, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 37 [40500/50000 (81%)]\tLoss: 2.038757, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 37 [42000/50000 (84%)]\tLoss: 2.310913, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 37 [43500/50000 (87%)]\tLoss: 2.137805, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 37 [45000/50000 (90%)]\tLoss: 2.222623, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 37 [46500/50000 (93%)]\tLoss: 2.092996, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 37 [48000/50000 (96%)]\tLoss: 2.223559, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 37 [49500/50000 (99%)]\tLoss: 2.177299, Accuracy: 21%, Learning rate: 0.100000\n",
            "\n",
            "Test set: Average loss: 1.4645, Accuracy: 7564/10000 (76%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 38 [1500/50000 (3%)]\tLoss: 2.208782, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 38 [3000/50000 (6%)]\tLoss: 2.110009, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 38 [4500/50000 (9%)]\tLoss: 2.284260, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 38 [6000/50000 (12%)]\tLoss: 2.133731, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 38 [7500/50000 (15%)]\tLoss: 2.209939, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 38 [9000/50000 (18%)]\tLoss: 2.071429, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 38 [10500/50000 (21%)]\tLoss: 2.126352, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 38 [12000/50000 (24%)]\tLoss: 2.149496, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 38 [13500/50000 (27%)]\tLoss: 2.182799, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 38 [15000/50000 (30%)]\tLoss: 2.098344, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 38 [16500/50000 (33%)]\tLoss: 2.115822, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 38 [18000/50000 (36%)]\tLoss: 2.211884, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 38 [19500/50000 (39%)]\tLoss: 2.031901, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 38 [21000/50000 (42%)]\tLoss: 2.175951, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 38 [22500/50000 (45%)]\tLoss: 2.268046, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 38 [24000/50000 (48%)]\tLoss: 2.170762, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 38 [25500/50000 (51%)]\tLoss: 2.142622, Accuracy: 20%, Learning rate: 0.100000\n",
            "Train Epoch: 38 [27000/50000 (54%)]\tLoss: 2.135381, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 38 [28500/50000 (57%)]\tLoss: 2.164135, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 38 [30000/50000 (60%)]\tLoss: 2.151814, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 38 [31500/50000 (63%)]\tLoss: 2.188756, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 38 [33000/50000 (66%)]\tLoss: 2.162486, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 38 [34500/50000 (69%)]\tLoss: 2.254752, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 38 [36000/50000 (72%)]\tLoss: 2.130311, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 38 [37500/50000 (75%)]\tLoss: 2.113819, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 38 [39000/50000 (78%)]\tLoss: 2.208871, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 38 [40500/50000 (81%)]\tLoss: 2.144736, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 38 [42000/50000 (84%)]\tLoss: 2.236843, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 38 [43500/50000 (87%)]\tLoss: 2.142537, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 38 [45000/50000 (90%)]\tLoss: 2.219565, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 38 [46500/50000 (93%)]\tLoss: 2.134220, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 38 [48000/50000 (96%)]\tLoss: 2.180974, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 38 [49500/50000 (99%)]\tLoss: 2.197938, Accuracy: 21%, Learning rate: 0.100000\n",
            "\n",
            "Test set: Average loss: 1.5311, Accuracy: 7359/10000 (74%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 39 [1500/50000 (3%)]\tLoss: 2.213111, Accuracy: 25%, Learning rate: 0.100000\n",
            "Train Epoch: 39 [3000/50000 (6%)]\tLoss: 2.271356, Accuracy: 23%, Learning rate: 0.100000\n",
            "Train Epoch: 39 [4500/50000 (9%)]\tLoss: 2.036050, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 39 [6000/50000 (12%)]\tLoss: 2.139072, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 39 [7500/50000 (15%)]\tLoss: 2.133884, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 39 [9000/50000 (18%)]\tLoss: 2.191083, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 39 [10500/50000 (21%)]\tLoss: 2.154539, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 39 [12000/50000 (24%)]\tLoss: 2.240646, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 39 [13500/50000 (27%)]\tLoss: 2.196877, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 39 [15000/50000 (30%)]\tLoss: 2.189974, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 39 [16500/50000 (33%)]\tLoss: 2.098440, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 39 [18000/50000 (36%)]\tLoss: 2.269756, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 39 [19500/50000 (39%)]\tLoss: 2.265073, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 39 [21000/50000 (42%)]\tLoss: 2.243536, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 39 [22500/50000 (45%)]\tLoss: 2.192796, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 39 [24000/50000 (48%)]\tLoss: 2.233420, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 39 [25500/50000 (51%)]\tLoss: 2.061199, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 39 [27000/50000 (54%)]\tLoss: 2.220531, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 39 [28500/50000 (57%)]\tLoss: 2.115289, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 39 [30000/50000 (60%)]\tLoss: 2.216875, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 39 [31500/50000 (63%)]\tLoss: 2.232260, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 39 [33000/50000 (66%)]\tLoss: 2.228897, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 39 [34500/50000 (69%)]\tLoss: 2.099895, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 39 [36000/50000 (72%)]\tLoss: 2.196119, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 39 [37500/50000 (75%)]\tLoss: 2.222145, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 39 [39000/50000 (78%)]\tLoss: 2.102035, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 39 [40500/50000 (81%)]\tLoss: 2.233026, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 39 [42000/50000 (84%)]\tLoss: 2.054083, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 39 [43500/50000 (87%)]\tLoss: 2.023979, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 39 [45000/50000 (90%)]\tLoss: 2.164419, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 39 [46500/50000 (93%)]\tLoss: 2.102655, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 39 [48000/50000 (96%)]\tLoss: 2.197409, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 39 [49500/50000 (99%)]\tLoss: 2.035644, Accuracy: 21%, Learning rate: 0.100000\n",
            "\n",
            "Test set: Average loss: 1.4868, Accuracy: 7455/10000 (75%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 40 [1500/50000 (3%)]\tLoss: 2.282413, Accuracy: 19%, Learning rate: 0.100000\n",
            "Train Epoch: 40 [3000/50000 (6%)]\tLoss: 2.157416, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 40 [4500/50000 (9%)]\tLoss: 2.150194, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 40 [6000/50000 (12%)]\tLoss: 2.250434, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 40 [7500/50000 (15%)]\tLoss: 2.245330, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 40 [9000/50000 (18%)]\tLoss: 2.171708, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 40 [10500/50000 (21%)]\tLoss: 2.227505, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 40 [12000/50000 (24%)]\tLoss: 2.057152, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 40 [13500/50000 (27%)]\tLoss: 2.216288, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 40 [15000/50000 (30%)]\tLoss: 2.105115, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 40 [16500/50000 (33%)]\tLoss: 2.162776, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 40 [18000/50000 (36%)]\tLoss: 2.188431, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 40 [19500/50000 (39%)]\tLoss: 2.050676, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 40 [21000/50000 (42%)]\tLoss: 2.187400, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 40 [22500/50000 (45%)]\tLoss: 2.114578, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 40 [24000/50000 (48%)]\tLoss: 2.134317, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 40 [25500/50000 (51%)]\tLoss: 2.188426, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 40 [27000/50000 (54%)]\tLoss: 2.085949, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 40 [28500/50000 (57%)]\tLoss: 2.115653, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 40 [30000/50000 (60%)]\tLoss: 2.168929, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 40 [31500/50000 (63%)]\tLoss: 2.280629, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 40 [33000/50000 (66%)]\tLoss: 2.075591, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 40 [34500/50000 (69%)]\tLoss: 2.196352, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 40 [36000/50000 (72%)]\tLoss: 2.155510, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 40 [37500/50000 (75%)]\tLoss: 2.301628, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 40 [39000/50000 (78%)]\tLoss: 2.153564, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 40 [40500/50000 (81%)]\tLoss: 2.021945, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 40 [42000/50000 (84%)]\tLoss: 2.248929, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 40 [43500/50000 (87%)]\tLoss: 2.097697, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 40 [45000/50000 (90%)]\tLoss: 2.218995, Accuracy: 21%, Learning rate: 0.100000\n",
            "Train Epoch: 40 [46500/50000 (93%)]\tLoss: 2.161840, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 40 [48000/50000 (96%)]\tLoss: 2.106009, Accuracy: 22%, Learning rate: 0.100000\n",
            "Train Epoch: 40 [49500/50000 (99%)]\tLoss: 2.203515, Accuracy: 22%, Learning rate: 0.100000\n",
            "\n",
            "Test set: Average loss: 1.4350, Accuracy: 7365/10000 (74%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 41 [1500/50000 (3%)]\tLoss: 2.128354, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 41 [3000/50000 (6%)]\tLoss: 2.221486, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 41 [4500/50000 (9%)]\tLoss: 2.108991, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 41 [6000/50000 (12%)]\tLoss: 2.181202, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 41 [7500/50000 (15%)]\tLoss: 2.193382, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 41 [9000/50000 (18%)]\tLoss: 2.152078, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 41 [10500/50000 (21%)]\tLoss: 2.148576, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 41 [12000/50000 (24%)]\tLoss: 2.159818, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 41 [13500/50000 (27%)]\tLoss: 2.218272, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 41 [15000/50000 (30%)]\tLoss: 2.147375, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 41 [16500/50000 (33%)]\tLoss: 2.133661, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 41 [18000/50000 (36%)]\tLoss: 2.223732, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 41 [19500/50000 (39%)]\tLoss: 2.261128, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 41 [21000/50000 (42%)]\tLoss: 2.107360, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 41 [22500/50000 (45%)]\tLoss: 2.230351, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 41 [24000/50000 (48%)]\tLoss: 2.129704, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 41 [25500/50000 (51%)]\tLoss: 2.249543, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 41 [27000/50000 (54%)]\tLoss: 2.103888, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 41 [28500/50000 (57%)]\tLoss: 2.141062, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 41 [30000/50000 (60%)]\tLoss: 2.114661, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 41 [31500/50000 (63%)]\tLoss: 2.211835, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 41 [33000/50000 (66%)]\tLoss: 2.093148, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 41 [34500/50000 (69%)]\tLoss: 2.137671, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 41 [36000/50000 (72%)]\tLoss: 2.234141, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 41 [37500/50000 (75%)]\tLoss: 2.248976, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 41 [39000/50000 (78%)]\tLoss: 2.009007, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 41 [40500/50000 (81%)]\tLoss: 2.214322, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 41 [42000/50000 (84%)]\tLoss: 2.103208, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 41 [43500/50000 (87%)]\tLoss: 2.014835, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 41 [45000/50000 (90%)]\tLoss: 2.100714, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 41 [46500/50000 (93%)]\tLoss: 2.190960, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 41 [48000/50000 (96%)]\tLoss: 2.194264, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 41 [49500/50000 (99%)]\tLoss: 2.150192, Accuracy: 23%, Learning rate: 0.010000\n",
            "\n",
            "Test set: Average loss: 1.3639, Accuracy: 8031/10000 (80%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 42 [1500/50000 (3%)]\tLoss: 1.955158, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 42 [3000/50000 (6%)]\tLoss: 2.147622, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 42 [4500/50000 (9%)]\tLoss: 2.150313, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 42 [6000/50000 (12%)]\tLoss: 2.155305, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 42 [7500/50000 (15%)]\tLoss: 2.182873, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 42 [9000/50000 (18%)]\tLoss: 2.214970, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 42 [10500/50000 (21%)]\tLoss: 2.107937, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 42 [12000/50000 (24%)]\tLoss: 2.100493, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 42 [13500/50000 (27%)]\tLoss: 2.128090, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 42 [15000/50000 (30%)]\tLoss: 2.145054, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 42 [16500/50000 (33%)]\tLoss: 2.168350, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 42 [18000/50000 (36%)]\tLoss: 2.138367, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 42 [19500/50000 (39%)]\tLoss: 2.143084, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 42 [21000/50000 (42%)]\tLoss: 2.154096, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 42 [22500/50000 (45%)]\tLoss: 2.043612, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 42 [24000/50000 (48%)]\tLoss: 2.150140, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 42 [25500/50000 (51%)]\tLoss: 2.120341, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 42 [27000/50000 (54%)]\tLoss: 2.044265, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 42 [28500/50000 (57%)]\tLoss: 2.193037, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 42 [30000/50000 (60%)]\tLoss: 2.164672, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 42 [31500/50000 (63%)]\tLoss: 2.219760, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 42 [33000/50000 (66%)]\tLoss: 2.100665, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 42 [34500/50000 (69%)]\tLoss: 2.016969, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 42 [36000/50000 (72%)]\tLoss: 2.183973, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 42 [37500/50000 (75%)]\tLoss: 2.087805, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 42 [39000/50000 (78%)]\tLoss: 2.126652, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 42 [40500/50000 (81%)]\tLoss: 2.066381, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 42 [42000/50000 (84%)]\tLoss: 2.138819, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 42 [43500/50000 (87%)]\tLoss: 2.222278, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 42 [45000/50000 (90%)]\tLoss: 2.237140, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 42 [46500/50000 (93%)]\tLoss: 2.086889, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 42 [48000/50000 (96%)]\tLoss: 2.192267, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 42 [49500/50000 (99%)]\tLoss: 2.117718, Accuracy: 23%, Learning rate: 0.010000\n",
            "\n",
            "Test set: Average loss: 1.3591, Accuracy: 8066/10000 (81%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 43 [1500/50000 (3%)]\tLoss: 2.176622, Accuracy: 26%, Learning rate: 0.010000\n",
            "Train Epoch: 43 [3000/50000 (6%)]\tLoss: 2.136495, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 43 [4500/50000 (9%)]\tLoss: 2.216326, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 43 [6000/50000 (12%)]\tLoss: 2.114935, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 43 [7500/50000 (15%)]\tLoss: 2.177454, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 43 [9000/50000 (18%)]\tLoss: 2.145478, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 43 [10500/50000 (21%)]\tLoss: 2.109204, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 43 [12000/50000 (24%)]\tLoss: 1.996304, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 43 [13500/50000 (27%)]\tLoss: 2.117995, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 43 [15000/50000 (30%)]\tLoss: 2.177619, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 43 [16500/50000 (33%)]\tLoss: 2.155931, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 43 [18000/50000 (36%)]\tLoss: 2.157633, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 43 [19500/50000 (39%)]\tLoss: 2.148247, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 43 [21000/50000 (42%)]\tLoss: 2.116761, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 43 [22500/50000 (45%)]\tLoss: 2.119102, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 43 [24000/50000 (48%)]\tLoss: 2.153180, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 43 [25500/50000 (51%)]\tLoss: 2.286818, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 43 [27000/50000 (54%)]\tLoss: 2.163880, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 43 [28500/50000 (57%)]\tLoss: 2.207291, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 43 [30000/50000 (60%)]\tLoss: 2.101814, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 43 [31500/50000 (63%)]\tLoss: 2.036525, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 43 [33000/50000 (66%)]\tLoss: 1.996449, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 43 [34500/50000 (69%)]\tLoss: 2.215691, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 43 [36000/50000 (72%)]\tLoss: 2.124888, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 43 [37500/50000 (75%)]\tLoss: 2.189084, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 43 [39000/50000 (78%)]\tLoss: 2.144355, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 43 [40500/50000 (81%)]\tLoss: 2.230507, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 43 [42000/50000 (84%)]\tLoss: 2.133346, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 43 [43500/50000 (87%)]\tLoss: 2.145730, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 43 [45000/50000 (90%)]\tLoss: 2.035416, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 43 [46500/50000 (93%)]\tLoss: 2.014768, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 43 [48000/50000 (96%)]\tLoss: 2.120234, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 43 [49500/50000 (99%)]\tLoss: 2.140232, Accuracy: 23%, Learning rate: 0.010000\n",
            "\n",
            "Test set: Average loss: 1.3335, Accuracy: 8077/10000 (81%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 44 [1500/50000 (3%)]\tLoss: 2.051584, Accuracy: 17%, Learning rate: 0.010000\n",
            "Train Epoch: 44 [3000/50000 (6%)]\tLoss: 2.283442, Accuracy: 19%, Learning rate: 0.010000\n",
            "Train Epoch: 44 [4500/50000 (9%)]\tLoss: 2.228040, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 44 [6000/50000 (12%)]\tLoss: 2.193083, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 44 [7500/50000 (15%)]\tLoss: 2.113869, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 44 [9000/50000 (18%)]\tLoss: 2.064208, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 44 [10500/50000 (21%)]\tLoss: 2.087256, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 44 [12000/50000 (24%)]\tLoss: 2.168211, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 44 [13500/50000 (27%)]\tLoss: 2.147050, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 44 [15000/50000 (30%)]\tLoss: 2.209817, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 44 [16500/50000 (33%)]\tLoss: 2.244983, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 44 [18000/50000 (36%)]\tLoss: 2.197774, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 44 [19500/50000 (39%)]\tLoss: 2.013010, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 44 [21000/50000 (42%)]\tLoss: 2.207308, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 44 [22500/50000 (45%)]\tLoss: 2.171896, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 44 [24000/50000 (48%)]\tLoss: 2.161852, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 44 [25500/50000 (51%)]\tLoss: 2.140464, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 44 [27000/50000 (54%)]\tLoss: 2.106925, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 44 [28500/50000 (57%)]\tLoss: 2.247311, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 44 [30000/50000 (60%)]\tLoss: 2.222940, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 44 [31500/50000 (63%)]\tLoss: 2.056784, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 44 [33000/50000 (66%)]\tLoss: 2.094512, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 44 [34500/50000 (69%)]\tLoss: 1.946782, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 44 [36000/50000 (72%)]\tLoss: 2.188346, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 44 [37500/50000 (75%)]\tLoss: 1.926082, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 44 [39000/50000 (78%)]\tLoss: 2.172474, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 44 [40500/50000 (81%)]\tLoss: 2.175924, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 44 [42000/50000 (84%)]\tLoss: 2.029521, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 44 [43500/50000 (87%)]\tLoss: 2.129692, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 44 [45000/50000 (90%)]\tLoss: 2.172282, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 44 [46500/50000 (93%)]\tLoss: 2.160976, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 44 [48000/50000 (96%)]\tLoss: 2.183241, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 44 [49500/50000 (99%)]\tLoss: 2.191662, Accuracy: 23%, Learning rate: 0.010000\n",
            "\n",
            "Test set: Average loss: 1.3671, Accuracy: 8010/10000 (80%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 45 [1500/50000 (3%)]\tLoss: 4.583867, Accuracy: 18%, Learning rate: 0.010000\n",
            "Train Epoch: 45 [3000/50000 (6%)]\tLoss: 4.378333, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 45 [4500/50000 (9%)]\tLoss: 4.249380, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 45 [6000/50000 (12%)]\tLoss: 4.396491, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 45 [7500/50000 (15%)]\tLoss: 4.557507, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 45 [9000/50000 (18%)]\tLoss: 4.578587, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 45 [10500/50000 (21%)]\tLoss: 4.341698, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 45 [12000/50000 (24%)]\tLoss: 4.527885, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 45 [13500/50000 (27%)]\tLoss: 4.526958, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 45 [15000/50000 (30%)]\tLoss: 4.399974, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 45 [16500/50000 (33%)]\tLoss: 4.446228, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 45 [18000/50000 (36%)]\tLoss: 4.318382, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 45 [19500/50000 (39%)]\tLoss: 4.300340, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 45 [21000/50000 (42%)]\tLoss: 4.501694, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 45 [22500/50000 (45%)]\tLoss: 4.255507, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 45 [24000/50000 (48%)]\tLoss: 4.513824, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 45 [25500/50000 (51%)]\tLoss: 4.438862, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 45 [27000/50000 (54%)]\tLoss: 4.509614, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 45 [28500/50000 (57%)]\tLoss: 4.400427, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 45 [30000/50000 (60%)]\tLoss: 4.442040, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 45 [31500/50000 (63%)]\tLoss: 4.470179, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 45 [33000/50000 (66%)]\tLoss: 4.473301, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 45 [34500/50000 (69%)]\tLoss: 4.529131, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 45 [36000/50000 (72%)]\tLoss: 4.537738, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 45 [37500/50000 (75%)]\tLoss: 4.530520, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 45 [39000/50000 (78%)]\tLoss: 4.563860, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 45 [40500/50000 (81%)]\tLoss: 4.443589, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 45 [42000/50000 (84%)]\tLoss: 4.449336, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 45 [43500/50000 (87%)]\tLoss: 4.439328, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 45 [45000/50000 (90%)]\tLoss: 4.537527, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 45 [46500/50000 (93%)]\tLoss: 4.477868, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 45 [48000/50000 (96%)]\tLoss: 4.365348, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 45 [49500/50000 (99%)]\tLoss: 4.543350, Accuracy: 23%, Learning rate: 0.010000\n",
            "\n",
            "Test set: Average loss: 1.5565, Accuracy: 8028/10000 (80%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 46 [1500/50000 (3%)]\tLoss: 4.438418, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 46 [3000/50000 (6%)]\tLoss: 4.244744, Accuracy: 20%, Learning rate: 0.010000\n",
            "Train Epoch: 46 [4500/50000 (9%)]\tLoss: 4.532533, Accuracy: 20%, Learning rate: 0.010000\n",
            "Train Epoch: 46 [6000/50000 (12%)]\tLoss: 4.490307, Accuracy: 20%, Learning rate: 0.010000\n",
            "Train Epoch: 46 [7500/50000 (15%)]\tLoss: 4.434690, Accuracy: 21%, Learning rate: 0.010000\n",
            "Train Epoch: 46 [9000/50000 (18%)]\tLoss: 4.544324, Accuracy: 21%, Learning rate: 0.010000\n",
            "Train Epoch: 46 [10500/50000 (21%)]\tLoss: 4.544436, Accuracy: 21%, Learning rate: 0.010000\n",
            "Train Epoch: 46 [12000/50000 (24%)]\tLoss: 4.509565, Accuracy: 21%, Learning rate: 0.010000\n",
            "Train Epoch: 46 [13500/50000 (27%)]\tLoss: 4.360889, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 46 [15000/50000 (30%)]\tLoss: 4.547840, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 46 [16500/50000 (33%)]\tLoss: 4.422656, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 46 [18000/50000 (36%)]\tLoss: 4.365187, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 46 [19500/50000 (39%)]\tLoss: 4.523038, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 46 [21000/50000 (42%)]\tLoss: 4.240250, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 46 [22500/50000 (45%)]\tLoss: 4.507825, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 46 [24000/50000 (48%)]\tLoss: 4.305537, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 46 [25500/50000 (51%)]\tLoss: 4.433273, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 46 [27000/50000 (54%)]\tLoss: 4.497542, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 46 [28500/50000 (57%)]\tLoss: 4.247298, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 46 [30000/50000 (60%)]\tLoss: 4.404653, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 46 [31500/50000 (63%)]\tLoss: 4.488752, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 46 [33000/50000 (66%)]\tLoss: 4.435953, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 46 [34500/50000 (69%)]\tLoss: 4.507319, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 46 [36000/50000 (72%)]\tLoss: 4.315374, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 46 [37500/50000 (75%)]\tLoss: 4.384740, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 46 [39000/50000 (78%)]\tLoss: 4.229425, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 46 [40500/50000 (81%)]\tLoss: 4.479439, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 46 [42000/50000 (84%)]\tLoss: 4.380277, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 46 [43500/50000 (87%)]\tLoss: 4.392440, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 46 [45000/50000 (90%)]\tLoss: 4.410086, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 46 [46500/50000 (93%)]\tLoss: 4.332556, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 46 [48000/50000 (96%)]\tLoss: 4.248277, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 46 [49500/50000 (99%)]\tLoss: 4.497382, Accuracy: 23%, Learning rate: 0.010000\n",
            "\n",
            "Test set: Average loss: 1.5301, Accuracy: 8007/10000 (80%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 47 [1500/50000 (3%)]\tLoss: 4.487069, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 47 [3000/50000 (6%)]\tLoss: 4.511906, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 47 [4500/50000 (9%)]\tLoss: 4.510504, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 47 [6000/50000 (12%)]\tLoss: 4.544018, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 47 [7500/50000 (15%)]\tLoss: 4.412059, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 47 [9000/50000 (18%)]\tLoss: 4.354421, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 47 [10500/50000 (21%)]\tLoss: 4.498549, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 47 [12000/50000 (24%)]\tLoss: 4.322917, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 47 [13500/50000 (27%)]\tLoss: 4.464102, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 47 [15000/50000 (30%)]\tLoss: 4.502204, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 47 [16500/50000 (33%)]\tLoss: 4.353024, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 47 [18000/50000 (36%)]\tLoss: 4.331182, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 47 [19500/50000 (39%)]\tLoss: 4.288586, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 47 [21000/50000 (42%)]\tLoss: 4.301403, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 47 [22500/50000 (45%)]\tLoss: 4.483319, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 47 [24000/50000 (48%)]\tLoss: 4.417121, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 47 [25500/50000 (51%)]\tLoss: 4.448950, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 47 [27000/50000 (54%)]\tLoss: 4.346125, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 47 [28500/50000 (57%)]\tLoss: 4.559978, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 47 [30000/50000 (60%)]\tLoss: 4.514310, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 47 [31500/50000 (63%)]\tLoss: 4.550862, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 47 [33000/50000 (66%)]\tLoss: 4.288186, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 47 [34500/50000 (69%)]\tLoss: 4.520598, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 47 [36000/50000 (72%)]\tLoss: 4.511297, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 47 [37500/50000 (75%)]\tLoss: 4.338309, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 47 [39000/50000 (78%)]\tLoss: 4.396240, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 47 [40500/50000 (81%)]\tLoss: 4.273188, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 47 [42000/50000 (84%)]\tLoss: 4.499625, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 47 [43500/50000 (87%)]\tLoss: 4.221857, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 47 [45000/50000 (90%)]\tLoss: 4.550119, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 47 [46500/50000 (93%)]\tLoss: 4.493380, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 47 [48000/50000 (96%)]\tLoss: 4.406604, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 47 [49500/50000 (99%)]\tLoss: 4.546022, Accuracy: 24%, Learning rate: 0.010000\n",
            "\n",
            "Test set: Average loss: 1.5549, Accuracy: 8042/10000 (80%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 48 [1500/50000 (3%)]\tLoss: 4.492972, Accuracy: 20%, Learning rate: 0.010000\n",
            "Train Epoch: 48 [3000/50000 (6%)]\tLoss: 4.264144, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 48 [4500/50000 (9%)]\tLoss: 4.569485, Accuracy: 21%, Learning rate: 0.010000\n",
            "Train Epoch: 48 [6000/50000 (12%)]\tLoss: 4.406412, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 48 [7500/50000 (15%)]\tLoss: 4.399674, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 48 [9000/50000 (18%)]\tLoss: 4.467578, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 48 [10500/50000 (21%)]\tLoss: 4.411522, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 48 [12000/50000 (24%)]\tLoss: 4.349362, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 48 [13500/50000 (27%)]\tLoss: 4.288158, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 48 [15000/50000 (30%)]\tLoss: 4.366168, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 48 [16500/50000 (33%)]\tLoss: 4.471784, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 48 [18000/50000 (36%)]\tLoss: 4.443116, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 48 [19500/50000 (39%)]\tLoss: 4.486867, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 48 [21000/50000 (42%)]\tLoss: 4.465573, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 48 [22500/50000 (45%)]\tLoss: 4.524010, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 48 [24000/50000 (48%)]\tLoss: 4.390606, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 48 [25500/50000 (51%)]\tLoss: 4.328115, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 48 [27000/50000 (54%)]\tLoss: 4.463630, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 48 [28500/50000 (57%)]\tLoss: 4.473250, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 48 [30000/50000 (60%)]\tLoss: 4.486553, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 48 [31500/50000 (63%)]\tLoss: 4.512554, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 48 [33000/50000 (66%)]\tLoss: 4.514703, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 48 [34500/50000 (69%)]\tLoss: 4.435517, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 48 [36000/50000 (72%)]\tLoss: 4.521745, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 48 [37500/50000 (75%)]\tLoss: 4.378685, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 48 [39000/50000 (78%)]\tLoss: 4.533170, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 48 [40500/50000 (81%)]\tLoss: 4.480380, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 48 [42000/50000 (84%)]\tLoss: 4.329908, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 48 [43500/50000 (87%)]\tLoss: 4.534329, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 48 [45000/50000 (90%)]\tLoss: 4.488896, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 48 [46500/50000 (93%)]\tLoss: 4.430905, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 48 [48000/50000 (96%)]\tLoss: 4.507292, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 48 [49500/50000 (99%)]\tLoss: 4.524682, Accuracy: 23%, Learning rate: 0.010000\n",
            "\n",
            "Test set: Average loss: 1.5654, Accuracy: 8086/10000 (81%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 49 [1500/50000 (3%)]\tLoss: 4.552366, Accuracy: 20%, Learning rate: 0.010000\n",
            "Train Epoch: 49 [3000/50000 (6%)]\tLoss: 4.540740, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 49 [4500/50000 (9%)]\tLoss: 4.462415, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 49 [6000/50000 (12%)]\tLoss: 4.558223, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 49 [7500/50000 (15%)]\tLoss: 4.443257, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 49 [9000/50000 (18%)]\tLoss: 4.481622, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 49 [10500/50000 (21%)]\tLoss: 4.378256, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 49 [12000/50000 (24%)]\tLoss: 4.373161, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 49 [13500/50000 (27%)]\tLoss: 4.513349, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 49 [15000/50000 (30%)]\tLoss: 4.314686, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 49 [16500/50000 (33%)]\tLoss: 4.255471, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 49 [18000/50000 (36%)]\tLoss: 4.465023, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 49 [19500/50000 (39%)]\tLoss: 4.476505, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 49 [21000/50000 (42%)]\tLoss: 4.409874, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 49 [22500/50000 (45%)]\tLoss: 4.430723, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 49 [24000/50000 (48%)]\tLoss: 4.396904, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 49 [25500/50000 (51%)]\tLoss: 4.380817, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 49 [27000/50000 (54%)]\tLoss: 4.234470, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 49 [28500/50000 (57%)]\tLoss: 4.272053, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 49 [30000/50000 (60%)]\tLoss: 4.434761, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 49 [31500/50000 (63%)]\tLoss: 4.468189, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 49 [33000/50000 (66%)]\tLoss: 4.493547, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 49 [34500/50000 (69%)]\tLoss: 4.488555, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 49 [36000/50000 (72%)]\tLoss: 4.540465, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 49 [37500/50000 (75%)]\tLoss: 4.502982, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 49 [39000/50000 (78%)]\tLoss: 4.405346, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 49 [40500/50000 (81%)]\tLoss: 4.534030, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 49 [42000/50000 (84%)]\tLoss: 4.403524, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 49 [43500/50000 (87%)]\tLoss: 4.414273, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 49 [45000/50000 (90%)]\tLoss: 4.539634, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 49 [46500/50000 (93%)]\tLoss: 4.323618, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 49 [48000/50000 (96%)]\tLoss: 4.312401, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 49 [49500/50000 (99%)]\tLoss: 4.348258, Accuracy: 23%, Learning rate: 0.010000\n",
            "\n",
            "Test set: Average loss: 1.5771, Accuracy: 8050/10000 (80%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 50 [1500/50000 (3%)]\tLoss: 4.370664, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 50 [3000/50000 (6%)]\tLoss: 4.511087, Accuracy: 26%, Learning rate: 0.010000\n",
            "Train Epoch: 50 [4500/50000 (9%)]\tLoss: 4.448717, Accuracy: 26%, Learning rate: 0.010000\n",
            "Train Epoch: 50 [6000/50000 (12%)]\tLoss: 4.434825, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 50 [7500/50000 (15%)]\tLoss: 4.487622, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 50 [9000/50000 (18%)]\tLoss: 4.335449, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 50 [10500/50000 (21%)]\tLoss: 4.504660, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 50 [12000/50000 (24%)]\tLoss: 4.514391, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 50 [13500/50000 (27%)]\tLoss: 4.512753, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 50 [15000/50000 (30%)]\tLoss: 4.505887, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 50 [16500/50000 (33%)]\tLoss: 4.437578, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 50 [18000/50000 (36%)]\tLoss: 4.468101, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 50 [19500/50000 (39%)]\tLoss: 4.470046, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 50 [21000/50000 (42%)]\tLoss: 4.354971, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 50 [22500/50000 (45%)]\tLoss: 4.528811, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 50 [24000/50000 (48%)]\tLoss: 4.450833, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 50 [25500/50000 (51%)]\tLoss: 4.353165, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 50 [27000/50000 (54%)]\tLoss: 4.510605, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 50 [28500/50000 (57%)]\tLoss: 4.484594, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 50 [30000/50000 (60%)]\tLoss: 4.494252, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 50 [31500/50000 (63%)]\tLoss: 4.228202, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 50 [33000/50000 (66%)]\tLoss: 4.263034, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 50 [34500/50000 (69%)]\tLoss: 4.506296, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 50 [36000/50000 (72%)]\tLoss: 4.297650, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 50 [37500/50000 (75%)]\tLoss: 4.523213, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 50 [39000/50000 (78%)]\tLoss: 4.520832, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 50 [40500/50000 (81%)]\tLoss: 4.445700, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 50 [42000/50000 (84%)]\tLoss: 4.473296, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 50 [43500/50000 (87%)]\tLoss: 4.391081, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 50 [45000/50000 (90%)]\tLoss: 4.475295, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 50 [46500/50000 (93%)]\tLoss: 4.512376, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 50 [48000/50000 (96%)]\tLoss: 4.488877, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 50 [49500/50000 (99%)]\tLoss: 4.537168, Accuracy: 24%, Learning rate: 0.010000\n",
            "\n",
            "Test set: Average loss: 1.5588, Accuracy: 8094/10000 (81%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 51 [1500/50000 (3%)]\tLoss: 4.527151, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 51 [3000/50000 (6%)]\tLoss: 4.467649, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 51 [4500/50000 (9%)]\tLoss: 4.427164, Accuracy: 21%, Learning rate: 0.010000\n",
            "Train Epoch: 51 [6000/50000 (12%)]\tLoss: 4.483157, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 51 [7500/50000 (15%)]\tLoss: 4.355117, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 51 [9000/50000 (18%)]\tLoss: 4.568210, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 51 [10500/50000 (21%)]\tLoss: 4.494497, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 51 [12000/50000 (24%)]\tLoss: 4.178554, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 51 [13500/50000 (27%)]\tLoss: 4.451060, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 51 [15000/50000 (30%)]\tLoss: 4.509069, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 51 [16500/50000 (33%)]\tLoss: 4.457873, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 51 [18000/50000 (36%)]\tLoss: 4.336573, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 51 [19500/50000 (39%)]\tLoss: 4.479774, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 51 [21000/50000 (42%)]\tLoss: 4.521704, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 51 [22500/50000 (45%)]\tLoss: 4.324162, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 51 [24000/50000 (48%)]\tLoss: 4.262066, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 51 [25500/50000 (51%)]\tLoss: 4.387072, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 51 [27000/50000 (54%)]\tLoss: 4.442850, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 51 [28500/50000 (57%)]\tLoss: 4.425964, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 51 [30000/50000 (60%)]\tLoss: 4.374880, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 51 [31500/50000 (63%)]\tLoss: 4.413809, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 51 [33000/50000 (66%)]\tLoss: 4.307079, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 51 [34500/50000 (69%)]\tLoss: 4.294106, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 51 [36000/50000 (72%)]\tLoss: 4.282429, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 51 [37500/50000 (75%)]\tLoss: 4.393789, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 51 [39000/50000 (78%)]\tLoss: 4.508704, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 51 [40500/50000 (81%)]\tLoss: 4.439099, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 51 [42000/50000 (84%)]\tLoss: 4.327545, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 51 [43500/50000 (87%)]\tLoss: 4.469526, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 51 [45000/50000 (90%)]\tLoss: 4.449364, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 51 [46500/50000 (93%)]\tLoss: 4.296524, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 51 [48000/50000 (96%)]\tLoss: 4.355206, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 51 [49500/50000 (99%)]\tLoss: 4.371088, Accuracy: 24%, Learning rate: 0.010000\n",
            "\n",
            "Test set: Average loss: 1.5396, Accuracy: 8050/10000 (80%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 52 [1500/50000 (3%)]\tLoss: 4.516026, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 52 [3000/50000 (6%)]\tLoss: 4.552900, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 52 [4500/50000 (9%)]\tLoss: 4.553526, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 52 [6000/50000 (12%)]\tLoss: 4.433771, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 52 [7500/50000 (15%)]\tLoss: 4.478140, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 52 [9000/50000 (18%)]\tLoss: 4.315173, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 52 [10500/50000 (21%)]\tLoss: 4.349859, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 52 [12000/50000 (24%)]\tLoss: 4.519581, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 52 [13500/50000 (27%)]\tLoss: 4.453123, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 52 [15000/50000 (30%)]\tLoss: 4.460484, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 52 [16500/50000 (33%)]\tLoss: 4.444685, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 52 [18000/50000 (36%)]\tLoss: 4.479338, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 52 [19500/50000 (39%)]\tLoss: 4.348454, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 52 [21000/50000 (42%)]\tLoss: 4.437666, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 52 [22500/50000 (45%)]\tLoss: 4.390292, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 52 [24000/50000 (48%)]\tLoss: 4.368744, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 52 [25500/50000 (51%)]\tLoss: 4.504126, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 52 [27000/50000 (54%)]\tLoss: 4.524663, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 52 [28500/50000 (57%)]\tLoss: 4.478683, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 52 [30000/50000 (60%)]\tLoss: 4.402494, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 52 [31500/50000 (63%)]\tLoss: 4.527692, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 52 [33000/50000 (66%)]\tLoss: 4.342092, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 52 [34500/50000 (69%)]\tLoss: 4.530521, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 52 [36000/50000 (72%)]\tLoss: 4.358895, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 52 [37500/50000 (75%)]\tLoss: 4.287842, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 52 [39000/50000 (78%)]\tLoss: 4.391871, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 52 [40500/50000 (81%)]\tLoss: 4.443785, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 52 [42000/50000 (84%)]\tLoss: 4.511147, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 52 [43500/50000 (87%)]\tLoss: 4.237681, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 52 [45000/50000 (90%)]\tLoss: 4.270750, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 52 [46500/50000 (93%)]\tLoss: 4.498886, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 52 [48000/50000 (96%)]\tLoss: 4.315446, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 52 [49500/50000 (99%)]\tLoss: 4.527189, Accuracy: 24%, Learning rate: 0.010000\n",
            "\n",
            "Test set: Average loss: 1.5243, Accuracy: 8037/10000 (80%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 53 [1500/50000 (3%)]\tLoss: 4.322977, Accuracy: 28%, Learning rate: 0.010000\n",
            "Train Epoch: 53 [3000/50000 (6%)]\tLoss: 4.436522, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 53 [4500/50000 (9%)]\tLoss: 4.321973, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 53 [6000/50000 (12%)]\tLoss: 4.342765, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 53 [7500/50000 (15%)]\tLoss: 4.418551, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 53 [9000/50000 (18%)]\tLoss: 4.524555, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 53 [10500/50000 (21%)]\tLoss: 4.423391, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 53 [12000/50000 (24%)]\tLoss: 4.407942, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 53 [13500/50000 (27%)]\tLoss: 4.401947, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 53 [15000/50000 (30%)]\tLoss: 4.525521, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 53 [16500/50000 (33%)]\tLoss: 4.530918, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 53 [18000/50000 (36%)]\tLoss: 4.463238, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 53 [19500/50000 (39%)]\tLoss: 4.250847, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 53 [21000/50000 (42%)]\tLoss: 4.390513, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 53 [22500/50000 (45%)]\tLoss: 4.469425, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 53 [24000/50000 (48%)]\tLoss: 4.136531, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 53 [25500/50000 (51%)]\tLoss: 4.283094, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 53 [27000/50000 (54%)]\tLoss: 4.297098, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 53 [28500/50000 (57%)]\tLoss: 4.539628, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 53 [30000/50000 (60%)]\tLoss: 4.516690, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 53 [31500/50000 (63%)]\tLoss: 4.561086, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 53 [33000/50000 (66%)]\tLoss: 4.495917, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 53 [34500/50000 (69%)]\tLoss: 4.489572, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 53 [36000/50000 (72%)]\tLoss: 4.457993, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 53 [37500/50000 (75%)]\tLoss: 4.500917, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 53 [39000/50000 (78%)]\tLoss: 4.526238, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 53 [40500/50000 (81%)]\tLoss: 4.482671, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 53 [42000/50000 (84%)]\tLoss: 4.556252, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 53 [43500/50000 (87%)]\tLoss: 4.303049, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 53 [45000/50000 (90%)]\tLoss: 4.492042, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 53 [46500/50000 (93%)]\tLoss: 4.484899, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 53 [48000/50000 (96%)]\tLoss: 4.531245, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 53 [49500/50000 (99%)]\tLoss: 4.491302, Accuracy: 23%, Learning rate: 0.010000\n",
            "\n",
            "Test set: Average loss: 1.5737, Accuracy: 7980/10000 (80%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 54 [1500/50000 (3%)]\tLoss: 4.499265, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 54 [3000/50000 (6%)]\tLoss: 4.476690, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 54 [4500/50000 (9%)]\tLoss: 4.425074, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 54 [6000/50000 (12%)]\tLoss: 4.480422, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 54 [7500/50000 (15%)]\tLoss: 4.506721, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 54 [9000/50000 (18%)]\tLoss: 4.503421, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 54 [10500/50000 (21%)]\tLoss: 4.410295, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 54 [12000/50000 (24%)]\tLoss: 4.466551, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 54 [13500/50000 (27%)]\tLoss: 4.536091, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 54 [15000/50000 (30%)]\tLoss: 4.540029, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 54 [16500/50000 (33%)]\tLoss: 4.346910, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 54 [18000/50000 (36%)]\tLoss: 4.488927, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 54 [19500/50000 (39%)]\tLoss: 4.490764, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 54 [21000/50000 (42%)]\tLoss: 4.405965, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 54 [22500/50000 (45%)]\tLoss: 4.546681, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 54 [24000/50000 (48%)]\tLoss: 4.450391, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 54 [25500/50000 (51%)]\tLoss: 4.516513, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 54 [27000/50000 (54%)]\tLoss: 4.529391, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 54 [28500/50000 (57%)]\tLoss: 4.500298, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 54 [30000/50000 (60%)]\tLoss: 4.460980, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 54 [31500/50000 (63%)]\tLoss: 4.524895, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 54 [33000/50000 (66%)]\tLoss: 4.472905, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 54 [34500/50000 (69%)]\tLoss: 4.370225, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 54 [36000/50000 (72%)]\tLoss: 4.489093, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 54 [37500/50000 (75%)]\tLoss: 4.532204, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 54 [39000/50000 (78%)]\tLoss: 4.510530, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 54 [40500/50000 (81%)]\tLoss: 4.398284, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 54 [42000/50000 (84%)]\tLoss: 4.473884, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 54 [43500/50000 (87%)]\tLoss: 4.350940, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 54 [45000/50000 (90%)]\tLoss: 4.375920, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 54 [46500/50000 (93%)]\tLoss: 4.545917, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 54 [48000/50000 (96%)]\tLoss: 4.345216, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 54 [49500/50000 (99%)]\tLoss: 4.413538, Accuracy: 22%, Learning rate: 0.010000\n",
            "\n",
            "Test set: Average loss: 1.5775, Accuracy: 8017/10000 (80%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 55 [1500/50000 (3%)]\tLoss: 4.481184, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 55 [3000/50000 (6%)]\tLoss: 4.414787, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 55 [4500/50000 (9%)]\tLoss: 4.374371, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 55 [6000/50000 (12%)]\tLoss: 4.463675, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 55 [7500/50000 (15%)]\tLoss: 4.439632, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 55 [9000/50000 (18%)]\tLoss: 4.410270, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 55 [10500/50000 (21%)]\tLoss: 4.524515, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 55 [12000/50000 (24%)]\tLoss: 4.541824, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 55 [13500/50000 (27%)]\tLoss: 4.466014, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 55 [15000/50000 (30%)]\tLoss: 4.467968, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 55 [16500/50000 (33%)]\tLoss: 4.508728, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 55 [18000/50000 (36%)]\tLoss: 4.525185, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 55 [19500/50000 (39%)]\tLoss: 4.506769, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 55 [21000/50000 (42%)]\tLoss: 4.485359, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 55 [22500/50000 (45%)]\tLoss: 4.459820, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 55 [24000/50000 (48%)]\tLoss: 4.351327, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 55 [25500/50000 (51%)]\tLoss: 4.228327, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 55 [27000/50000 (54%)]\tLoss: 4.503945, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 55 [28500/50000 (57%)]\tLoss: 4.451066, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 55 [30000/50000 (60%)]\tLoss: 4.452979, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 55 [31500/50000 (63%)]\tLoss: 4.296668, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 55 [33000/50000 (66%)]\tLoss: 4.457608, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 55 [34500/50000 (69%)]\tLoss: 4.435408, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 55 [36000/50000 (72%)]\tLoss: 4.551229, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 55 [37500/50000 (75%)]\tLoss: 4.470047, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 55 [39000/50000 (78%)]\tLoss: 4.488003, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 55 [40500/50000 (81%)]\tLoss: 4.480011, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 55 [42000/50000 (84%)]\tLoss: 4.468207, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 55 [43500/50000 (87%)]\tLoss: 4.273667, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 55 [45000/50000 (90%)]\tLoss: 4.488831, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 55 [46500/50000 (93%)]\tLoss: 4.484533, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 55 [48000/50000 (96%)]\tLoss: 4.527280, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 55 [49500/50000 (99%)]\tLoss: 4.351822, Accuracy: 23%, Learning rate: 0.010000\n",
            "\n",
            "Test set: Average loss: 1.5621, Accuracy: 8000/10000 (80%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 56 [1500/50000 (3%)]\tLoss: 4.422627, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 56 [3000/50000 (6%)]\tLoss: 4.457832, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 56 [4500/50000 (9%)]\tLoss: 4.520469, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 56 [6000/50000 (12%)]\tLoss: 4.470911, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 56 [7500/50000 (15%)]\tLoss: 4.521841, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 56 [9000/50000 (18%)]\tLoss: 4.414005, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 56 [10500/50000 (21%)]\tLoss: 4.335413, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 56 [12000/50000 (24%)]\tLoss: 4.297203, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 56 [13500/50000 (27%)]\tLoss: 4.512120, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 56 [15000/50000 (30%)]\tLoss: 4.502645, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 56 [16500/50000 (33%)]\tLoss: 4.282651, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 56 [18000/50000 (36%)]\tLoss: 4.532232, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 56 [19500/50000 (39%)]\tLoss: 4.455410, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 56 [21000/50000 (42%)]\tLoss: 4.478676, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 56 [22500/50000 (45%)]\tLoss: 4.312991, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 56 [24000/50000 (48%)]\tLoss: 4.379277, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 56 [25500/50000 (51%)]\tLoss: 4.544670, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 56 [27000/50000 (54%)]\tLoss: 4.286915, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 56 [28500/50000 (57%)]\tLoss: 4.503010, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 56 [30000/50000 (60%)]\tLoss: 4.397287, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 56 [31500/50000 (63%)]\tLoss: 4.371827, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 56 [33000/50000 (66%)]\tLoss: 4.321152, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 56 [34500/50000 (69%)]\tLoss: 4.298903, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 56 [36000/50000 (72%)]\tLoss: 4.282896, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 56 [37500/50000 (75%)]\tLoss: 4.289471, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 56 [39000/50000 (78%)]\tLoss: 4.476114, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 56 [40500/50000 (81%)]\tLoss: 4.308649, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 56 [42000/50000 (84%)]\tLoss: 4.375829, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 56 [43500/50000 (87%)]\tLoss: 4.421814, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 56 [45000/50000 (90%)]\tLoss: 4.444253, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 56 [46500/50000 (93%)]\tLoss: 4.241495, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 56 [48000/50000 (96%)]\tLoss: 4.520629, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 56 [49500/50000 (99%)]\tLoss: 4.520218, Accuracy: 24%, Learning rate: 0.010000\n",
            "\n",
            "Test set: Average loss: 1.5436, Accuracy: 7995/10000 (80%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 57 [1500/50000 (3%)]\tLoss: 4.372674, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 57 [3000/50000 (6%)]\tLoss: 4.128974, Accuracy: 26%, Learning rate: 0.010000\n",
            "Train Epoch: 57 [4500/50000 (9%)]\tLoss: 4.484326, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 57 [6000/50000 (12%)]\tLoss: 4.265090, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 57 [7500/50000 (15%)]\tLoss: 4.525617, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 57 [9000/50000 (18%)]\tLoss: 4.487296, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 57 [10500/50000 (21%)]\tLoss: 4.526809, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 57 [12000/50000 (24%)]\tLoss: 4.324044, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 57 [13500/50000 (27%)]\tLoss: 4.521398, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 57 [15000/50000 (30%)]\tLoss: 4.338343, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 57 [16500/50000 (33%)]\tLoss: 4.206658, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 57 [18000/50000 (36%)]\tLoss: 4.492823, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 57 [19500/50000 (39%)]\tLoss: 4.242983, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 57 [21000/50000 (42%)]\tLoss: 4.482078, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 57 [22500/50000 (45%)]\tLoss: 4.444357, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 57 [24000/50000 (48%)]\tLoss: 4.301933, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 57 [25500/50000 (51%)]\tLoss: 4.478923, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 57 [27000/50000 (54%)]\tLoss: 4.464845, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 57 [28500/50000 (57%)]\tLoss: 4.510075, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 57 [30000/50000 (60%)]\tLoss: 4.420780, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 57 [31500/50000 (63%)]\tLoss: 4.498491, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 57 [33000/50000 (66%)]\tLoss: 4.405722, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 57 [34500/50000 (69%)]\tLoss: 4.483984, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 57 [36000/50000 (72%)]\tLoss: 4.239758, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 57 [37500/50000 (75%)]\tLoss: 4.535036, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 57 [39000/50000 (78%)]\tLoss: 4.488476, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 57 [40500/50000 (81%)]\tLoss: 4.367702, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 57 [42000/50000 (84%)]\tLoss: 4.365139, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 57 [43500/50000 (87%)]\tLoss: 4.273356, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 57 [45000/50000 (90%)]\tLoss: 4.455208, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 57 [46500/50000 (93%)]\tLoss: 4.333431, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 57 [48000/50000 (96%)]\tLoss: 4.565103, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 57 [49500/50000 (99%)]\tLoss: 4.400394, Accuracy: 24%, Learning rate: 0.010000\n",
            "\n",
            "Test set: Average loss: 1.5910, Accuracy: 7941/10000 (79%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 58 [1500/50000 (3%)]\tLoss: 4.422787, Accuracy: 27%, Learning rate: 0.010000\n",
            "Train Epoch: 58 [3000/50000 (6%)]\tLoss: 4.440454, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 58 [4500/50000 (9%)]\tLoss: 4.503966, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 58 [6000/50000 (12%)]\tLoss: 4.496517, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 58 [7500/50000 (15%)]\tLoss: 4.480393, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 58 [9000/50000 (18%)]\tLoss: 4.468323, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 58 [10500/50000 (21%)]\tLoss: 4.518920, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 58 [12000/50000 (24%)]\tLoss: 4.485456, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 58 [13500/50000 (27%)]\tLoss: 4.365511, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 58 [15000/50000 (30%)]\tLoss: 4.451294, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 58 [16500/50000 (33%)]\tLoss: 4.500499, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 58 [18000/50000 (36%)]\tLoss: 4.519000, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 58 [19500/50000 (39%)]\tLoss: 4.376612, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 58 [21000/50000 (42%)]\tLoss: 4.388916, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 58 [22500/50000 (45%)]\tLoss: 4.245893, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 58 [24000/50000 (48%)]\tLoss: 4.183244, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 58 [25500/50000 (51%)]\tLoss: 4.450359, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 58 [27000/50000 (54%)]\tLoss: 4.419791, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 58 [28500/50000 (57%)]\tLoss: 4.486176, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 58 [30000/50000 (60%)]\tLoss: 4.487750, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 58 [31500/50000 (63%)]\tLoss: 4.489672, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 58 [33000/50000 (66%)]\tLoss: 4.232389, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 58 [34500/50000 (69%)]\tLoss: 4.516639, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 58 [36000/50000 (72%)]\tLoss: 4.500649, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 58 [37500/50000 (75%)]\tLoss: 4.387967, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 58 [39000/50000 (78%)]\tLoss: 4.386278, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 58 [40500/50000 (81%)]\tLoss: 4.493779, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 58 [42000/50000 (84%)]\tLoss: 4.483420, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 58 [43500/50000 (87%)]\tLoss: 4.261559, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 58 [45000/50000 (90%)]\tLoss: 4.361025, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 58 [46500/50000 (93%)]\tLoss: 4.398170, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 58 [48000/50000 (96%)]\tLoss: 4.375474, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 58 [49500/50000 (99%)]\tLoss: 4.339800, Accuracy: 24%, Learning rate: 0.010000\n",
            "\n",
            "Test set: Average loss: 1.5463, Accuracy: 8008/10000 (80%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 59 [1500/50000 (3%)]\tLoss: 4.527134, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 59 [3000/50000 (6%)]\tLoss: 4.441660, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 59 [4500/50000 (9%)]\tLoss: 4.238002, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 59 [6000/50000 (12%)]\tLoss: 4.386611, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 59 [7500/50000 (15%)]\tLoss: 4.264984, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 59 [9000/50000 (18%)]\tLoss: 4.414580, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 59 [10500/50000 (21%)]\tLoss: 4.354653, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 59 [12000/50000 (24%)]\tLoss: 4.275337, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 59 [13500/50000 (27%)]\tLoss: 4.496037, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 59 [15000/50000 (30%)]\tLoss: 4.390889, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 59 [16500/50000 (33%)]\tLoss: 4.278845, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 59 [18000/50000 (36%)]\tLoss: 4.470231, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 59 [19500/50000 (39%)]\tLoss: 4.267392, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 59 [21000/50000 (42%)]\tLoss: 4.259346, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 59 [22500/50000 (45%)]\tLoss: 4.248137, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 59 [24000/50000 (48%)]\tLoss: 4.512573, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 59 [25500/50000 (51%)]\tLoss: 4.458749, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 59 [27000/50000 (54%)]\tLoss: 4.509162, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 59 [28500/50000 (57%)]\tLoss: 4.475159, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 59 [30000/50000 (60%)]\tLoss: 4.251609, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 59 [31500/50000 (63%)]\tLoss: 4.383508, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 59 [33000/50000 (66%)]\tLoss: 4.440940, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 59 [34500/50000 (69%)]\tLoss: 4.526479, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 59 [36000/50000 (72%)]\tLoss: 4.325483, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 59 [37500/50000 (75%)]\tLoss: 4.473401, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 59 [39000/50000 (78%)]\tLoss: 4.439989, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 59 [40500/50000 (81%)]\tLoss: 4.389000, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 59 [42000/50000 (84%)]\tLoss: 4.395117, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 59 [43500/50000 (87%)]\tLoss: 4.302455, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 59 [45000/50000 (90%)]\tLoss: 4.427145, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 59 [46500/50000 (93%)]\tLoss: 4.449638, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 59 [48000/50000 (96%)]\tLoss: 4.543295, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 59 [49500/50000 (99%)]\tLoss: 4.300602, Accuracy: 24%, Learning rate: 0.010000\n",
            "\n",
            "Test set: Average loss: 1.5844, Accuracy: 7928/10000 (79%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 60 [1500/50000 (3%)]\tLoss: 4.451051, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 60 [3000/50000 (6%)]\tLoss: 4.487838, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 60 [4500/50000 (9%)]\tLoss: 4.476269, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 60 [6000/50000 (12%)]\tLoss: 4.479977, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 60 [7500/50000 (15%)]\tLoss: 4.546247, Accuracy: 21%, Learning rate: 0.010000\n",
            "Train Epoch: 60 [9000/50000 (18%)]\tLoss: 4.513014, Accuracy: 21%, Learning rate: 0.010000\n",
            "Train Epoch: 60 [10500/50000 (21%)]\tLoss: 4.402670, Accuracy: 21%, Learning rate: 0.010000\n",
            "Train Epoch: 60 [12000/50000 (24%)]\tLoss: 4.337952, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 60 [13500/50000 (27%)]\tLoss: 4.411782, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 60 [15000/50000 (30%)]\tLoss: 4.478660, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 60 [16500/50000 (33%)]\tLoss: 4.527735, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 60 [18000/50000 (36%)]\tLoss: 4.387989, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 60 [19500/50000 (39%)]\tLoss: 4.373569, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 60 [21000/50000 (42%)]\tLoss: 4.527204, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 60 [22500/50000 (45%)]\tLoss: 4.478985, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 60 [24000/50000 (48%)]\tLoss: 4.395129, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 60 [25500/50000 (51%)]\tLoss: 4.499969, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 60 [27000/50000 (54%)]\tLoss: 4.492258, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 60 [28500/50000 (57%)]\tLoss: 4.340754, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 60 [30000/50000 (60%)]\tLoss: 4.523028, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 60 [31500/50000 (63%)]\tLoss: 4.412380, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 60 [33000/50000 (66%)]\tLoss: 4.335248, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 60 [34500/50000 (69%)]\tLoss: 4.531684, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 60 [36000/50000 (72%)]\tLoss: 4.339972, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 60 [37500/50000 (75%)]\tLoss: 4.497172, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 60 [39000/50000 (78%)]\tLoss: 4.488483, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 60 [40500/50000 (81%)]\tLoss: 4.339673, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 60 [42000/50000 (84%)]\tLoss: 4.491252, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 60 [43500/50000 (87%)]\tLoss: 4.388436, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 60 [45000/50000 (90%)]\tLoss: 4.308209, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 60 [46500/50000 (93%)]\tLoss: 4.528195, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 60 [48000/50000 (96%)]\tLoss: 4.424534, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 60 [49500/50000 (99%)]\tLoss: 4.485160, Accuracy: 23%, Learning rate: 0.010000\n",
            "\n",
            "Test set: Average loss: 1.6051, Accuracy: 7896/10000 (79%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 61 [1500/50000 (3%)]\tLoss: 4.474754, Accuracy: 26%, Learning rate: 0.010000\n",
            "Train Epoch: 61 [3000/50000 (6%)]\tLoss: 4.191796, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 61 [4500/50000 (9%)]\tLoss: 4.319984, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 61 [6000/50000 (12%)]\tLoss: 4.238585, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 61 [7500/50000 (15%)]\tLoss: 4.405104, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 61 [9000/50000 (18%)]\tLoss: 4.396849, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 61 [10500/50000 (21%)]\tLoss: 4.472190, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 61 [12000/50000 (24%)]\tLoss: 4.236150, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 61 [13500/50000 (27%)]\tLoss: 4.500607, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 61 [15000/50000 (30%)]\tLoss: 4.497508, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 61 [16500/50000 (33%)]\tLoss: 4.489666, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 61 [18000/50000 (36%)]\tLoss: 4.471346, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 61 [19500/50000 (39%)]\tLoss: 4.302348, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 61 [21000/50000 (42%)]\tLoss: 4.389939, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 61 [22500/50000 (45%)]\tLoss: 4.426831, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 61 [24000/50000 (48%)]\tLoss: 4.455996, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 61 [25500/50000 (51%)]\tLoss: 4.380016, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 61 [27000/50000 (54%)]\tLoss: 4.246410, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 61 [28500/50000 (57%)]\tLoss: 4.250861, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 61 [30000/50000 (60%)]\tLoss: 4.532547, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 61 [31500/50000 (63%)]\tLoss: 4.508585, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 61 [33000/50000 (66%)]\tLoss: 4.279512, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 61 [34500/50000 (69%)]\tLoss: 4.500605, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 61 [36000/50000 (72%)]\tLoss: 4.495193, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 61 [37500/50000 (75%)]\tLoss: 4.415158, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 61 [39000/50000 (78%)]\tLoss: 4.294051, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 61 [40500/50000 (81%)]\tLoss: 4.460640, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 61 [42000/50000 (84%)]\tLoss: 4.493800, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 61 [43500/50000 (87%)]\tLoss: 4.425749, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 61 [45000/50000 (90%)]\tLoss: 4.525601, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 61 [46500/50000 (93%)]\tLoss: 4.265164, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 61 [48000/50000 (96%)]\tLoss: 4.442770, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 61 [49500/50000 (99%)]\tLoss: 4.457014, Accuracy: 23%, Learning rate: 0.010000\n",
            "\n",
            "Test set: Average loss: 1.5441, Accuracy: 7927/10000 (79%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 62 [1500/50000 (3%)]\tLoss: 4.394259, Accuracy: 19%, Learning rate: 0.010000\n",
            "Train Epoch: 62 [3000/50000 (6%)]\tLoss: 4.429821, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 62 [4500/50000 (9%)]\tLoss: 4.454516, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 62 [6000/50000 (12%)]\tLoss: 4.347491, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 62 [7500/50000 (15%)]\tLoss: 4.460291, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 62 [9000/50000 (18%)]\tLoss: 4.264831, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 62 [10500/50000 (21%)]\tLoss: 4.409535, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 62 [12000/50000 (24%)]\tLoss: 4.428777, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 62 [13500/50000 (27%)]\tLoss: 4.480725, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 62 [15000/50000 (30%)]\tLoss: 4.506357, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 62 [16500/50000 (33%)]\tLoss: 4.443497, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 62 [18000/50000 (36%)]\tLoss: 4.250354, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 62 [19500/50000 (39%)]\tLoss: 4.461056, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 62 [21000/50000 (42%)]\tLoss: 4.293175, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 62 [22500/50000 (45%)]\tLoss: 4.463440, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 62 [24000/50000 (48%)]\tLoss: 4.508591, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 62 [25500/50000 (51%)]\tLoss: 4.380197, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 62 [27000/50000 (54%)]\tLoss: 4.448140, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 62 [28500/50000 (57%)]\tLoss: 4.407219, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 62 [30000/50000 (60%)]\tLoss: 4.492855, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 62 [31500/50000 (63%)]\tLoss: 4.454638, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 62 [33000/50000 (66%)]\tLoss: 4.510414, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 62 [34500/50000 (69%)]\tLoss: 4.478800, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 62 [36000/50000 (72%)]\tLoss: 4.464481, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 62 [37500/50000 (75%)]\tLoss: 4.467423, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 62 [39000/50000 (78%)]\tLoss: 4.494700, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 62 [40500/50000 (81%)]\tLoss: 4.512248, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 62 [42000/50000 (84%)]\tLoss: 4.531403, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 62 [43500/50000 (87%)]\tLoss: 4.443115, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 62 [45000/50000 (90%)]\tLoss: 4.324134, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 62 [46500/50000 (93%)]\tLoss: 4.390664, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 62 [48000/50000 (96%)]\tLoss: 4.534018, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 62 [49500/50000 (99%)]\tLoss: 4.500255, Accuracy: 24%, Learning rate: 0.010000\n",
            "\n",
            "Test set: Average loss: 1.5772, Accuracy: 7891/10000 (79%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 63 [1500/50000 (3%)]\tLoss: 4.470977, Accuracy: 26%, Learning rate: 0.010000\n",
            "Train Epoch: 63 [3000/50000 (6%)]\tLoss: 4.482855, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 63 [4500/50000 (9%)]\tLoss: 4.388929, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 63 [6000/50000 (12%)]\tLoss: 4.459887, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 63 [7500/50000 (15%)]\tLoss: 4.398807, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 63 [9000/50000 (18%)]\tLoss: 4.490631, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 63 [10500/50000 (21%)]\tLoss: 4.412738, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 63 [12000/50000 (24%)]\tLoss: 4.450330, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 63 [13500/50000 (27%)]\tLoss: 4.333961, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 63 [15000/50000 (30%)]\tLoss: 4.311944, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 63 [16500/50000 (33%)]\tLoss: 4.501688, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 63 [18000/50000 (36%)]\tLoss: 4.278451, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 63 [19500/50000 (39%)]\tLoss: 4.375003, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 63 [21000/50000 (42%)]\tLoss: 4.255587, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 63 [22500/50000 (45%)]\tLoss: 4.514190, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 63 [24000/50000 (48%)]\tLoss: 4.492301, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 63 [25500/50000 (51%)]\tLoss: 4.432433, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 63 [27000/50000 (54%)]\tLoss: 4.400028, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 63 [28500/50000 (57%)]\tLoss: 4.416650, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 63 [30000/50000 (60%)]\tLoss: 4.398058, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 63 [31500/50000 (63%)]\tLoss: 4.490564, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 63 [33000/50000 (66%)]\tLoss: 4.494595, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 63 [34500/50000 (69%)]\tLoss: 4.479348, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 63 [36000/50000 (72%)]\tLoss: 4.398205, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 63 [37500/50000 (75%)]\tLoss: 4.297166, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 63 [39000/50000 (78%)]\tLoss: 4.493241, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 63 [40500/50000 (81%)]\tLoss: 4.448893, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 63 [42000/50000 (84%)]\tLoss: 4.510408, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 63 [43500/50000 (87%)]\tLoss: 4.460105, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 63 [45000/50000 (90%)]\tLoss: 4.465442, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 63 [46500/50000 (93%)]\tLoss: 4.456889, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 63 [48000/50000 (96%)]\tLoss: 4.376573, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 63 [49500/50000 (99%)]\tLoss: 4.480000, Accuracy: 23%, Learning rate: 0.010000\n",
            "\n",
            "Test set: Average loss: 1.6114, Accuracy: 7864/10000 (79%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 64 [1500/50000 (3%)]\tLoss: 4.541813, Accuracy: 20%, Learning rate: 0.010000\n",
            "Train Epoch: 64 [3000/50000 (6%)]\tLoss: 4.445095, Accuracy: 21%, Learning rate: 0.010000\n",
            "Train Epoch: 64 [4500/50000 (9%)]\tLoss: 4.342534, Accuracy: 20%, Learning rate: 0.010000\n",
            "Train Epoch: 64 [6000/50000 (12%)]\tLoss: 4.328918, Accuracy: 21%, Learning rate: 0.010000\n",
            "Train Epoch: 64 [7500/50000 (15%)]\tLoss: 4.408118, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 64 [9000/50000 (18%)]\tLoss: 4.536317, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 64 [10500/50000 (21%)]\tLoss: 4.321185, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 64 [12000/50000 (24%)]\tLoss: 4.356077, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 64 [13500/50000 (27%)]\tLoss: 4.181546, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 64 [15000/50000 (30%)]\tLoss: 4.242531, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 64 [16500/50000 (33%)]\tLoss: 4.356743, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 64 [18000/50000 (36%)]\tLoss: 4.479980, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 64 [19500/50000 (39%)]\tLoss: 4.412720, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 64 [21000/50000 (42%)]\tLoss: 4.486431, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 64 [22500/50000 (45%)]\tLoss: 4.409693, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 64 [24000/50000 (48%)]\tLoss: 4.476145, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 64 [25500/50000 (51%)]\tLoss: 4.374959, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 64 [27000/50000 (54%)]\tLoss: 4.427790, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 64 [28500/50000 (57%)]\tLoss: 4.530768, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 64 [30000/50000 (60%)]\tLoss: 4.386640, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 64 [31500/50000 (63%)]\tLoss: 4.421707, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 64 [33000/50000 (66%)]\tLoss: 4.523417, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 64 [34500/50000 (69%)]\tLoss: 4.351085, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 64 [36000/50000 (72%)]\tLoss: 4.420964, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 64 [37500/50000 (75%)]\tLoss: 4.406663, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 64 [39000/50000 (78%)]\tLoss: 4.423992, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 64 [40500/50000 (81%)]\tLoss: 4.493450, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 64 [42000/50000 (84%)]\tLoss: 4.560841, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 64 [43500/50000 (87%)]\tLoss: 4.231450, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 64 [45000/50000 (90%)]\tLoss: 4.416980, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 64 [46500/50000 (93%)]\tLoss: 4.470629, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 64 [48000/50000 (96%)]\tLoss: 4.299110, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 64 [49500/50000 (99%)]\tLoss: 4.495326, Accuracy: 23%, Learning rate: 0.010000\n",
            "\n",
            "Test set: Average loss: 1.5263, Accuracy: 7899/10000 (79%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 65 [1500/50000 (3%)]\tLoss: 4.265548, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 65 [3000/50000 (6%)]\tLoss: 4.417455, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 65 [4500/50000 (9%)]\tLoss: 4.543210, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 65 [6000/50000 (12%)]\tLoss: 4.483767, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 65 [7500/50000 (15%)]\tLoss: 4.474942, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 65 [9000/50000 (18%)]\tLoss: 4.456529, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 65 [10500/50000 (21%)]\tLoss: 4.502522, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 65 [12000/50000 (24%)]\tLoss: 4.295422, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 65 [13500/50000 (27%)]\tLoss: 4.468843, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 65 [15000/50000 (30%)]\tLoss: 4.487084, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 65 [16500/50000 (33%)]\tLoss: 4.327163, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 65 [18000/50000 (36%)]\tLoss: 4.584224, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 65 [19500/50000 (39%)]\tLoss: 4.505755, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 65 [21000/50000 (42%)]\tLoss: 4.224597, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 65 [22500/50000 (45%)]\tLoss: 4.415194, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 65 [24000/50000 (48%)]\tLoss: 4.204168, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 65 [25500/50000 (51%)]\tLoss: 4.501333, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 65 [27000/50000 (54%)]\tLoss: 4.369021, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 65 [28500/50000 (57%)]\tLoss: 4.482185, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 65 [30000/50000 (60%)]\tLoss: 4.336193, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 65 [31500/50000 (63%)]\tLoss: 4.530263, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 65 [33000/50000 (66%)]\tLoss: 4.497226, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 65 [34500/50000 (69%)]\tLoss: 4.304090, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 65 [36000/50000 (72%)]\tLoss: 4.475531, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 65 [37500/50000 (75%)]\tLoss: 4.491210, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 65 [39000/50000 (78%)]\tLoss: 4.562589, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 65 [40500/50000 (81%)]\tLoss: 4.539800, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 65 [42000/50000 (84%)]\tLoss: 4.432135, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 65 [43500/50000 (87%)]\tLoss: 4.466755, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 65 [45000/50000 (90%)]\tLoss: 4.451648, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 65 [46500/50000 (93%)]\tLoss: 4.395113, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 65 [48000/50000 (96%)]\tLoss: 4.467055, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 65 [49500/50000 (99%)]\tLoss: 4.523354, Accuracy: 23%, Learning rate: 0.010000\n",
            "\n",
            "Test set: Average loss: 1.5970, Accuracy: 7817/10000 (78%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 66 [1500/50000 (3%)]\tLoss: 4.475862, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 66 [3000/50000 (6%)]\tLoss: 4.518776, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 66 [4500/50000 (9%)]\tLoss: 4.464833, Accuracy: 22%, Learning rate: 0.010000\n",
            "Train Epoch: 66 [6000/50000 (12%)]\tLoss: 4.307452, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 66 [7500/50000 (15%)]\tLoss: 4.194490, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 66 [9000/50000 (18%)]\tLoss: 4.540609, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 66 [10500/50000 (21%)]\tLoss: 4.368434, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 66 [12000/50000 (24%)]\tLoss: 4.232356, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 66 [13500/50000 (27%)]\tLoss: 4.489985, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 66 [15000/50000 (30%)]\tLoss: 4.394092, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 66 [16500/50000 (33%)]\tLoss: 4.484842, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 66 [18000/50000 (36%)]\tLoss: 4.461336, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 66 [19500/50000 (39%)]\tLoss: 4.493385, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 66 [21000/50000 (42%)]\tLoss: 4.448082, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 66 [22500/50000 (45%)]\tLoss: 4.465493, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 66 [24000/50000 (48%)]\tLoss: 4.464969, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 66 [25500/50000 (51%)]\tLoss: 4.488094, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 66 [27000/50000 (54%)]\tLoss: 4.378942, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 66 [28500/50000 (57%)]\tLoss: 4.511101, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 66 [30000/50000 (60%)]\tLoss: 4.452950, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 66 [31500/50000 (63%)]\tLoss: 4.314802, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 66 [33000/50000 (66%)]\tLoss: 4.490401, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 66 [34500/50000 (69%)]\tLoss: 4.452780, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 66 [36000/50000 (72%)]\tLoss: 4.336456, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 66 [37500/50000 (75%)]\tLoss: 4.306624, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 66 [39000/50000 (78%)]\tLoss: 4.285108, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 66 [40500/50000 (81%)]\tLoss: 4.432391, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 66 [42000/50000 (84%)]\tLoss: 4.298556, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 66 [43500/50000 (87%)]\tLoss: 4.438519, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 66 [45000/50000 (90%)]\tLoss: 4.544673, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 66 [46500/50000 (93%)]\tLoss: 4.475013, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 66 [48000/50000 (96%)]\tLoss: 4.488023, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 66 [49500/50000 (99%)]\tLoss: 4.457895, Accuracy: 23%, Learning rate: 0.010000\n",
            "\n",
            "Test set: Average loss: 1.5844, Accuracy: 7899/10000 (79%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 67 [1500/50000 (3%)]\tLoss: 4.489998, Accuracy: 26%, Learning rate: 0.010000\n",
            "Train Epoch: 67 [3000/50000 (6%)]\tLoss: 4.516597, Accuracy: 26%, Learning rate: 0.010000\n",
            "Train Epoch: 67 [4500/50000 (9%)]\tLoss: 4.450290, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 67 [6000/50000 (12%)]\tLoss: 4.564756, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 67 [7500/50000 (15%)]\tLoss: 4.512691, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 67 [9000/50000 (18%)]\tLoss: 4.496149, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 67 [10500/50000 (21%)]\tLoss: 4.524995, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 67 [12000/50000 (24%)]\tLoss: 4.511809, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 67 [13500/50000 (27%)]\tLoss: 4.395519, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 67 [15000/50000 (30%)]\tLoss: 4.431568, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 67 [16500/50000 (33%)]\tLoss: 4.451620, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 67 [18000/50000 (36%)]\tLoss: 4.455457, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 67 [19500/50000 (39%)]\tLoss: 4.492411, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 67 [21000/50000 (42%)]\tLoss: 4.503218, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 67 [22500/50000 (45%)]\tLoss: 4.363896, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 67 [24000/50000 (48%)]\tLoss: 4.375508, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 67 [25500/50000 (51%)]\tLoss: 4.472991, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 67 [27000/50000 (54%)]\tLoss: 4.516572, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 67 [28500/50000 (57%)]\tLoss: 4.534073, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 67 [30000/50000 (60%)]\tLoss: 4.284803, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 67 [31500/50000 (63%)]\tLoss: 4.465536, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 67 [33000/50000 (66%)]\tLoss: 4.443750, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 67 [34500/50000 (69%)]\tLoss: 4.473161, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 67 [36000/50000 (72%)]\tLoss: 4.477702, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 67 [37500/50000 (75%)]\tLoss: 4.474979, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 67 [39000/50000 (78%)]\tLoss: 4.291597, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 67 [40500/50000 (81%)]\tLoss: 4.461616, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 67 [42000/50000 (84%)]\tLoss: 4.286813, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 67 [43500/50000 (87%)]\tLoss: 4.462557, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 67 [45000/50000 (90%)]\tLoss: 4.528205, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 67 [46500/50000 (93%)]\tLoss: 4.504994, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 67 [48000/50000 (96%)]\tLoss: 4.452720, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 67 [49500/50000 (99%)]\tLoss: 4.376366, Accuracy: 23%, Learning rate: 0.010000\n",
            "\n",
            "Test set: Average loss: 1.6128, Accuracy: 7782/10000 (78%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 68 [1500/50000 (3%)]\tLoss: 4.375688, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 68 [3000/50000 (6%)]\tLoss: 4.485661, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 68 [4500/50000 (9%)]\tLoss: 4.281393, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 68 [6000/50000 (12%)]\tLoss: 4.354659, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 68 [7500/50000 (15%)]\tLoss: 4.436790, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 68 [9000/50000 (18%)]\tLoss: 4.411809, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 68 [10500/50000 (21%)]\tLoss: 4.527208, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 68 [12000/50000 (24%)]\tLoss: 4.358035, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 68 [13500/50000 (27%)]\tLoss: 4.482690, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 68 [15000/50000 (30%)]\tLoss: 4.492927, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 68 [16500/50000 (33%)]\tLoss: 4.417162, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 68 [18000/50000 (36%)]\tLoss: 4.480425, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 68 [19500/50000 (39%)]\tLoss: 4.457797, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 68 [21000/50000 (42%)]\tLoss: 4.546159, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 68 [22500/50000 (45%)]\tLoss: 4.506029, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 68 [24000/50000 (48%)]\tLoss: 4.305797, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 68 [25500/50000 (51%)]\tLoss: 4.254123, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 68 [27000/50000 (54%)]\tLoss: 4.507777, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 68 [28500/50000 (57%)]\tLoss: 4.391381, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 68 [30000/50000 (60%)]\tLoss: 4.430941, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 68 [31500/50000 (63%)]\tLoss: 4.419962, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 68 [33000/50000 (66%)]\tLoss: 4.484594, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 68 [34500/50000 (69%)]\tLoss: 4.484968, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 68 [36000/50000 (72%)]\tLoss: 4.191573, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 68 [37500/50000 (75%)]\tLoss: 4.250082, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 68 [39000/50000 (78%)]\tLoss: 4.441042, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 68 [40500/50000 (81%)]\tLoss: 4.439176, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 68 [42000/50000 (84%)]\tLoss: 4.419650, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 68 [43500/50000 (87%)]\tLoss: 4.505764, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 68 [45000/50000 (90%)]\tLoss: 4.451340, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 68 [46500/50000 (93%)]\tLoss: 4.459827, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 68 [48000/50000 (96%)]\tLoss: 4.248519, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 68 [49500/50000 (99%)]\tLoss: 4.388322, Accuracy: 24%, Learning rate: 0.010000\n",
            "\n",
            "Test set: Average loss: 1.5230, Accuracy: 7894/10000 (79%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 69 [1500/50000 (3%)]\tLoss: 4.505643, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 69 [3000/50000 (6%)]\tLoss: 4.256735, Accuracy: 26%, Learning rate: 0.010000\n",
            "Train Epoch: 69 [4500/50000 (9%)]\tLoss: 4.395278, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 69 [6000/50000 (12%)]\tLoss: 4.499847, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 69 [7500/50000 (15%)]\tLoss: 4.296139, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 69 [9000/50000 (18%)]\tLoss: 4.456889, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 69 [10500/50000 (21%)]\tLoss: 4.535731, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 69 [12000/50000 (24%)]\tLoss: 4.445379, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 69 [13500/50000 (27%)]\tLoss: 4.520421, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 69 [15000/50000 (30%)]\tLoss: 4.411186, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 69 [16500/50000 (33%)]\tLoss: 4.288357, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 69 [18000/50000 (36%)]\tLoss: 4.389565, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 69 [19500/50000 (39%)]\tLoss: 4.460820, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 69 [21000/50000 (42%)]\tLoss: 4.549272, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 69 [22500/50000 (45%)]\tLoss: 4.497984, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 69 [24000/50000 (48%)]\tLoss: 4.453495, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 69 [25500/50000 (51%)]\tLoss: 4.284378, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 69 [27000/50000 (54%)]\tLoss: 4.473138, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 69 [28500/50000 (57%)]\tLoss: 4.404118, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 69 [30000/50000 (60%)]\tLoss: 4.446205, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 69 [31500/50000 (63%)]\tLoss: 4.552625, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 69 [33000/50000 (66%)]\tLoss: 4.219561, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 69 [34500/50000 (69%)]\tLoss: 4.423759, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 69 [36000/50000 (72%)]\tLoss: 4.448375, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 69 [37500/50000 (75%)]\tLoss: 4.236942, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 69 [39000/50000 (78%)]\tLoss: 4.428973, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 69 [40500/50000 (81%)]\tLoss: 4.321448, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 69 [42000/50000 (84%)]\tLoss: 4.300162, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 69 [43500/50000 (87%)]\tLoss: 4.505956, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 69 [45000/50000 (90%)]\tLoss: 4.544760, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 69 [46500/50000 (93%)]\tLoss: 4.477766, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 69 [48000/50000 (96%)]\tLoss: 4.459479, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 69 [49500/50000 (99%)]\tLoss: 4.545753, Accuracy: 24%, Learning rate: 0.010000\n",
            "\n",
            "Test set: Average loss: 1.6027, Accuracy: 7689/10000 (77%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 70 [1500/50000 (3%)]\tLoss: 4.481804, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 70 [3000/50000 (6%)]\tLoss: 4.544043, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 70 [4500/50000 (9%)]\tLoss: 4.497166, Accuracy: 25%, Learning rate: 0.010000\n",
            "Train Epoch: 70 [6000/50000 (12%)]\tLoss: 4.410222, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 70 [7500/50000 (15%)]\tLoss: 4.452603, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 70 [9000/50000 (18%)]\tLoss: 4.421968, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 70 [10500/50000 (21%)]\tLoss: 4.510445, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 70 [12000/50000 (24%)]\tLoss: 4.422402, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 70 [13500/50000 (27%)]\tLoss: 4.381694, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 70 [15000/50000 (30%)]\tLoss: 4.407190, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 70 [16500/50000 (33%)]\tLoss: 4.455739, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 70 [18000/50000 (36%)]\tLoss: 4.470901, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 70 [19500/50000 (39%)]\tLoss: 4.302315, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 70 [21000/50000 (42%)]\tLoss: 4.481304, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 70 [22500/50000 (45%)]\tLoss: 4.487190, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 70 [24000/50000 (48%)]\tLoss: 4.379443, Accuracy: 23%, Learning rate: 0.010000\n",
            "Train Epoch: 70 [25500/50000 (51%)]\tLoss: 4.265382, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 70 [27000/50000 (54%)]\tLoss: 4.393661, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 70 [28500/50000 (57%)]\tLoss: 4.204232, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 70 [30000/50000 (60%)]\tLoss: 4.553934, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 70 [31500/50000 (63%)]\tLoss: 4.214942, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 70 [33000/50000 (66%)]\tLoss: 4.210161, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 70 [34500/50000 (69%)]\tLoss: 4.509468, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 70 [36000/50000 (72%)]\tLoss: 4.273781, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 70 [37500/50000 (75%)]\tLoss: 4.470123, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 70 [39000/50000 (78%)]\tLoss: 4.432532, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 70 [40500/50000 (81%)]\tLoss: 4.500683, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 70 [42000/50000 (84%)]\tLoss: 4.315722, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 70 [43500/50000 (87%)]\tLoss: 4.179725, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 70 [45000/50000 (90%)]\tLoss: 4.365757, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 70 [46500/50000 (93%)]\tLoss: 4.433697, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 70 [48000/50000 (96%)]\tLoss: 4.297259, Accuracy: 24%, Learning rate: 0.010000\n",
            "Train Epoch: 70 [49500/50000 (99%)]\tLoss: 4.341912, Accuracy: 24%, Learning rate: 0.010000\n",
            "\n",
            "Test set: Average loss: 1.5559, Accuracy: 7839/10000 (78%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 71 [1500/50000 (3%)]\tLoss: 4.516147, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 71 [3000/50000 (6%)]\tLoss: 4.218416, Accuracy: 26%, Learning rate: 0.001000\n",
            "Train Epoch: 71 [4500/50000 (9%)]\tLoss: 4.486444, Accuracy: 27%, Learning rate: 0.001000\n",
            "Train Epoch: 71 [6000/50000 (12%)]\tLoss: 4.413751, Accuracy: 26%, Learning rate: 0.001000\n",
            "Train Epoch: 71 [7500/50000 (15%)]\tLoss: 4.270951, Accuracy: 27%, Learning rate: 0.001000\n",
            "Train Epoch: 71 [9000/50000 (18%)]\tLoss: 4.203430, Accuracy: 26%, Learning rate: 0.001000\n",
            "Train Epoch: 71 [10500/50000 (21%)]\tLoss: 4.449382, Accuracy: 26%, Learning rate: 0.001000\n",
            "Train Epoch: 71 [12000/50000 (24%)]\tLoss: 4.457091, Accuracy: 26%, Learning rate: 0.001000\n",
            "Train Epoch: 71 [13500/50000 (27%)]\tLoss: 4.417969, Accuracy: 26%, Learning rate: 0.001000\n",
            "Train Epoch: 71 [15000/50000 (30%)]\tLoss: 4.201144, Accuracy: 26%, Learning rate: 0.001000\n",
            "Train Epoch: 71 [16500/50000 (33%)]\tLoss: 4.425209, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 71 [18000/50000 (36%)]\tLoss: 4.305998, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 71 [19500/50000 (39%)]\tLoss: 4.348188, Accuracy: 26%, Learning rate: 0.001000\n",
            "Train Epoch: 71 [21000/50000 (42%)]\tLoss: 4.385703, Accuracy: 26%, Learning rate: 0.001000\n",
            "Train Epoch: 71 [22500/50000 (45%)]\tLoss: 4.356786, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 71 [24000/50000 (48%)]\tLoss: 4.355284, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 71 [25500/50000 (51%)]\tLoss: 4.506707, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 71 [27000/50000 (54%)]\tLoss: 4.481228, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 71 [28500/50000 (57%)]\tLoss: 4.359716, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 71 [30000/50000 (60%)]\tLoss: 4.455646, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 71 [31500/50000 (63%)]\tLoss: 4.509868, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 71 [33000/50000 (66%)]\tLoss: 4.443043, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 71 [34500/50000 (69%)]\tLoss: 4.461865, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 71 [36000/50000 (72%)]\tLoss: 4.516041, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 71 [37500/50000 (75%)]\tLoss: 4.457428, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 71 [39000/50000 (78%)]\tLoss: 4.450239, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 71 [40500/50000 (81%)]\tLoss: 4.258403, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 71 [42000/50000 (84%)]\tLoss: 4.435383, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 71 [43500/50000 (87%)]\tLoss: 4.467052, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 71 [45000/50000 (90%)]\tLoss: 4.433176, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 71 [46500/50000 (93%)]\tLoss: 4.500652, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 71 [48000/50000 (96%)]\tLoss: 4.446658, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 71 [49500/50000 (99%)]\tLoss: 4.428210, Accuracy: 24%, Learning rate: 0.001000\n",
            "\n",
            "Test set: Average loss: 1.5588, Accuracy: 7862/10000 (79%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 72 [1500/50000 (3%)]\tLoss: 4.261353, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 72 [3000/50000 (6%)]\tLoss: 4.300767, Accuracy: 29%, Learning rate: 0.001000\n",
            "Train Epoch: 72 [4500/50000 (9%)]\tLoss: 4.444118, Accuracy: 27%, Learning rate: 0.001000\n",
            "Train Epoch: 72 [6000/50000 (12%)]\tLoss: 4.381011, Accuracy: 27%, Learning rate: 0.001000\n",
            "Train Epoch: 72 [7500/50000 (15%)]\tLoss: 4.197653, Accuracy: 27%, Learning rate: 0.001000\n",
            "Train Epoch: 72 [9000/50000 (18%)]\tLoss: 4.203186, Accuracy: 26%, Learning rate: 0.001000\n",
            "Train Epoch: 72 [10500/50000 (21%)]\tLoss: 4.511035, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 72 [12000/50000 (24%)]\tLoss: 4.450209, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 72 [13500/50000 (27%)]\tLoss: 4.504230, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 72 [15000/50000 (30%)]\tLoss: 4.277067, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 72 [16500/50000 (33%)]\tLoss: 4.484434, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 72 [18000/50000 (36%)]\tLoss: 4.294556, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 72 [19500/50000 (39%)]\tLoss: 4.244454, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 72 [21000/50000 (42%)]\tLoss: 4.360499, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 72 [22500/50000 (45%)]\tLoss: 4.422174, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 72 [24000/50000 (48%)]\tLoss: 4.403523, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 72 [25500/50000 (51%)]\tLoss: 4.362483, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 72 [27000/50000 (54%)]\tLoss: 4.441762, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 72 [28500/50000 (57%)]\tLoss: 4.452159, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 72 [30000/50000 (60%)]\tLoss: 4.432680, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 72 [31500/50000 (63%)]\tLoss: 4.450074, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 72 [33000/50000 (66%)]\tLoss: 4.517604, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 72 [34500/50000 (69%)]\tLoss: 4.352955, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 72 [36000/50000 (72%)]\tLoss: 4.502905, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 72 [37500/50000 (75%)]\tLoss: 4.416841, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 72 [39000/50000 (78%)]\tLoss: 4.504681, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 72 [40500/50000 (81%)]\tLoss: 4.355487, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 72 [42000/50000 (84%)]\tLoss: 4.252678, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 72 [43500/50000 (87%)]\tLoss: 4.331772, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 72 [45000/50000 (90%)]\tLoss: 4.136260, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 72 [46500/50000 (93%)]\tLoss: 4.434630, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 72 [48000/50000 (96%)]\tLoss: 4.484273, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 72 [49500/50000 (99%)]\tLoss: 4.436967, Accuracy: 24%, Learning rate: 0.001000\n",
            "\n",
            "Test set: Average loss: 1.5567, Accuracy: 7896/10000 (79%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 73 [1500/50000 (3%)]\tLoss: 4.513027, Accuracy: 19%, Learning rate: 0.001000\n",
            "Train Epoch: 73 [3000/50000 (6%)]\tLoss: 4.399961, Accuracy: 23%, Learning rate: 0.001000\n",
            "Train Epoch: 73 [4500/50000 (9%)]\tLoss: 4.402891, Accuracy: 23%, Learning rate: 0.001000\n",
            "Train Epoch: 73 [6000/50000 (12%)]\tLoss: 4.420974, Accuracy: 22%, Learning rate: 0.001000\n",
            "Train Epoch: 73 [7500/50000 (15%)]\tLoss: 4.526303, Accuracy: 22%, Learning rate: 0.001000\n",
            "Train Epoch: 73 [9000/50000 (18%)]\tLoss: 4.478084, Accuracy: 22%, Learning rate: 0.001000\n",
            "Train Epoch: 73 [10500/50000 (21%)]\tLoss: 4.404354, Accuracy: 23%, Learning rate: 0.001000\n",
            "Train Epoch: 73 [12000/50000 (24%)]\tLoss: 4.421411, Accuracy: 23%, Learning rate: 0.001000\n",
            "Train Epoch: 73 [13500/50000 (27%)]\tLoss: 4.362508, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 73 [15000/50000 (30%)]\tLoss: 4.402774, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 73 [16500/50000 (33%)]\tLoss: 4.272934, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 73 [18000/50000 (36%)]\tLoss: 4.303391, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 73 [19500/50000 (39%)]\tLoss: 4.281927, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 73 [21000/50000 (42%)]\tLoss: 4.446941, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 73 [22500/50000 (45%)]\tLoss: 4.386867, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 73 [24000/50000 (48%)]\tLoss: 4.293102, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 73 [25500/50000 (51%)]\tLoss: 4.392023, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 73 [27000/50000 (54%)]\tLoss: 4.487250, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 73 [28500/50000 (57%)]\tLoss: 4.388381, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 73 [30000/50000 (60%)]\tLoss: 4.375820, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 73 [31500/50000 (63%)]\tLoss: 4.439000, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 73 [33000/50000 (66%)]\tLoss: 4.386692, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 73 [34500/50000 (69%)]\tLoss: 4.201458, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 73 [36000/50000 (72%)]\tLoss: 4.218913, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 73 [37500/50000 (75%)]\tLoss: 4.473500, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 73 [39000/50000 (78%)]\tLoss: 4.502249, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 73 [40500/50000 (81%)]\tLoss: 4.308777, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 73 [42000/50000 (84%)]\tLoss: 4.211319, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 73 [43500/50000 (87%)]\tLoss: 4.246124, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 73 [45000/50000 (90%)]\tLoss: 4.466106, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 73 [46500/50000 (93%)]\tLoss: 4.165619, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 73 [48000/50000 (96%)]\tLoss: 4.367692, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 73 [49500/50000 (99%)]\tLoss: 4.264037, Accuracy: 25%, Learning rate: 0.001000\n",
            "\n",
            "Test set: Average loss: 1.5261, Accuracy: 7959/10000 (80%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 74 [1500/50000 (3%)]\tLoss: 4.390132, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 74 [3000/50000 (6%)]\tLoss: 4.504943, Accuracy: 23%, Learning rate: 0.001000\n",
            "Train Epoch: 74 [4500/50000 (9%)]\tLoss: 4.515606, Accuracy: 23%, Learning rate: 0.001000\n",
            "Train Epoch: 74 [6000/50000 (12%)]\tLoss: 4.369865, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 74 [7500/50000 (15%)]\tLoss: 4.495635, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 74 [9000/50000 (18%)]\tLoss: 4.468792, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 74 [10500/50000 (21%)]\tLoss: 4.418252, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 74 [12000/50000 (24%)]\tLoss: 4.342684, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 74 [13500/50000 (27%)]\tLoss: 4.487239, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 74 [15000/50000 (30%)]\tLoss: 4.242608, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 74 [16500/50000 (33%)]\tLoss: 4.153932, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 74 [18000/50000 (36%)]\tLoss: 4.451479, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 74 [19500/50000 (39%)]\tLoss: 4.252211, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 74 [21000/50000 (42%)]\tLoss: 4.505712, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 74 [22500/50000 (45%)]\tLoss: 4.474692, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 74 [24000/50000 (48%)]\tLoss: 4.452995, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 74 [25500/50000 (51%)]\tLoss: 4.212243, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 74 [27000/50000 (54%)]\tLoss: 4.498702, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 74 [28500/50000 (57%)]\tLoss: 4.522868, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 74 [30000/50000 (60%)]\tLoss: 4.324253, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 74 [31500/50000 (63%)]\tLoss: 4.164528, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 74 [33000/50000 (66%)]\tLoss: 4.474892, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 74 [34500/50000 (69%)]\tLoss: 4.239382, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 74 [36000/50000 (72%)]\tLoss: 4.414752, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 74 [37500/50000 (75%)]\tLoss: 4.476757, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 74 [39000/50000 (78%)]\tLoss: 4.505207, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 74 [40500/50000 (81%)]\tLoss: 4.278546, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 74 [42000/50000 (84%)]\tLoss: 4.455469, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 74 [43500/50000 (87%)]\tLoss: 4.413893, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 74 [45000/50000 (90%)]\tLoss: 4.093915, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 74 [46500/50000 (93%)]\tLoss: 4.395550, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 74 [48000/50000 (96%)]\tLoss: 4.226759, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 74 [49500/50000 (99%)]\tLoss: 4.437305, Accuracy: 25%, Learning rate: 0.001000\n",
            "\n",
            "Test set: Average loss: 1.5470, Accuracy: 7864/10000 (79%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 75 [1500/50000 (3%)]\tLoss: 4.522349, Accuracy: 27%, Learning rate: 0.001000\n",
            "Train Epoch: 75 [3000/50000 (6%)]\tLoss: 4.507894, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 75 [4500/50000 (9%)]\tLoss: 4.438419, Accuracy: 23%, Learning rate: 0.001000\n",
            "Train Epoch: 75 [6000/50000 (12%)]\tLoss: 4.331304, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 75 [7500/50000 (15%)]\tLoss: 4.462946, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 75 [9000/50000 (18%)]\tLoss: 4.417656, Accuracy: 23%, Learning rate: 0.001000\n",
            "Train Epoch: 75 [10500/50000 (21%)]\tLoss: 4.444933, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 75 [12000/50000 (24%)]\tLoss: 4.481592, Accuracy: 23%, Learning rate: 0.001000\n",
            "Train Epoch: 75 [13500/50000 (27%)]\tLoss: 4.319775, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 75 [15000/50000 (30%)]\tLoss: 4.371364, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 75 [16500/50000 (33%)]\tLoss: 4.393524, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 75 [18000/50000 (36%)]\tLoss: 4.390087, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 75 [19500/50000 (39%)]\tLoss: 4.207132, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 75 [21000/50000 (42%)]\tLoss: 4.440782, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 75 [22500/50000 (45%)]\tLoss: 4.301006, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 75 [24000/50000 (48%)]\tLoss: 4.466299, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 75 [25500/50000 (51%)]\tLoss: 4.305432, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 75 [27000/50000 (54%)]\tLoss: 4.519253, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 75 [28500/50000 (57%)]\tLoss: 4.177186, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 75 [30000/50000 (60%)]\tLoss: 4.338656, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 75 [31500/50000 (63%)]\tLoss: 4.466543, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 75 [33000/50000 (66%)]\tLoss: 4.492280, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 75 [34500/50000 (69%)]\tLoss: 4.479785, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 75 [36000/50000 (72%)]\tLoss: 4.448215, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 75 [37500/50000 (75%)]\tLoss: 4.456054, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 75 [39000/50000 (78%)]\tLoss: 4.410857, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 75 [40500/50000 (81%)]\tLoss: 4.370433, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 75 [42000/50000 (84%)]\tLoss: 4.435103, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 75 [43500/50000 (87%)]\tLoss: 4.521888, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 75 [45000/50000 (90%)]\tLoss: 4.493129, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 75 [46500/50000 (93%)]\tLoss: 4.433979, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 75 [48000/50000 (96%)]\tLoss: 4.453557, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 75 [49500/50000 (99%)]\tLoss: 4.473386, Accuracy: 25%, Learning rate: 0.001000\n",
            "\n",
            "Test set: Average loss: 1.5433, Accuracy: 7868/10000 (79%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 76 [1500/50000 (3%)]\tLoss: 4.287202, Accuracy: 22%, Learning rate: 0.001000\n",
            "Train Epoch: 76 [3000/50000 (6%)]\tLoss: 4.492899, Accuracy: 23%, Learning rate: 0.001000\n",
            "Train Epoch: 76 [4500/50000 (9%)]\tLoss: 4.342073, Accuracy: 23%, Learning rate: 0.001000\n",
            "Train Epoch: 76 [6000/50000 (12%)]\tLoss: 4.407900, Accuracy: 23%, Learning rate: 0.001000\n",
            "Train Epoch: 76 [7500/50000 (15%)]\tLoss: 4.257710, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 76 [9000/50000 (18%)]\tLoss: 4.252758, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 76 [10500/50000 (21%)]\tLoss: 4.468440, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 76 [12000/50000 (24%)]\tLoss: 4.379297, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 76 [13500/50000 (27%)]\tLoss: 4.339423, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 76 [15000/50000 (30%)]\tLoss: 4.461616, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 76 [16500/50000 (33%)]\tLoss: 4.498603, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 76 [18000/50000 (36%)]\tLoss: 4.426758, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 76 [19500/50000 (39%)]\tLoss: 4.472153, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 76 [21000/50000 (42%)]\tLoss: 4.173759, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 76 [22500/50000 (45%)]\tLoss: 4.148885, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 76 [24000/50000 (48%)]\tLoss: 4.484948, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 76 [25500/50000 (51%)]\tLoss: 4.411243, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 76 [27000/50000 (54%)]\tLoss: 4.300838, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 76 [28500/50000 (57%)]\tLoss: 4.465137, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 76 [30000/50000 (60%)]\tLoss: 4.438050, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 76 [31500/50000 (63%)]\tLoss: 4.408526, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 76 [33000/50000 (66%)]\tLoss: 4.390957, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 76 [34500/50000 (69%)]\tLoss: 4.169580, Accuracy: 26%, Learning rate: 0.001000\n",
            "Train Epoch: 76 [36000/50000 (72%)]\tLoss: 4.124049, Accuracy: 26%, Learning rate: 0.001000\n",
            "Train Epoch: 76 [37500/50000 (75%)]\tLoss: 4.335040, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 76 [39000/50000 (78%)]\tLoss: 4.465217, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 76 [40500/50000 (81%)]\tLoss: 4.285458, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 76 [42000/50000 (84%)]\tLoss: 4.301102, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 76 [43500/50000 (87%)]\tLoss: 4.413172, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 76 [45000/50000 (90%)]\tLoss: 4.524798, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 76 [46500/50000 (93%)]\tLoss: 4.229452, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 76 [48000/50000 (96%)]\tLoss: 4.461150, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 76 [49500/50000 (99%)]\tLoss: 4.277524, Accuracy: 25%, Learning rate: 0.001000\n",
            "\n",
            "Test set: Average loss: 1.5502, Accuracy: 7859/10000 (79%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 77 [1500/50000 (3%)]\tLoss: 4.306956, Accuracy: 27%, Learning rate: 0.001000\n",
            "Train Epoch: 77 [3000/50000 (6%)]\tLoss: 4.230755, Accuracy: 23%, Learning rate: 0.001000\n",
            "Train Epoch: 77 [4500/50000 (9%)]\tLoss: 4.494361, Accuracy: 23%, Learning rate: 0.001000\n",
            "Train Epoch: 77 [6000/50000 (12%)]\tLoss: 4.430089, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 77 [7500/50000 (15%)]\tLoss: 4.480273, Accuracy: 23%, Learning rate: 0.001000\n",
            "Train Epoch: 77 [9000/50000 (18%)]\tLoss: 4.335689, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 77 [10500/50000 (21%)]\tLoss: 4.507371, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 77 [12000/50000 (24%)]\tLoss: 4.264696, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 77 [13500/50000 (27%)]\tLoss: 4.170137, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 77 [15000/50000 (30%)]\tLoss: 4.477416, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 77 [16500/50000 (33%)]\tLoss: 4.395060, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 77 [18000/50000 (36%)]\tLoss: 4.293331, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 77 [19500/50000 (39%)]\tLoss: 4.401946, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 77 [21000/50000 (42%)]\tLoss: 4.374639, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 77 [22500/50000 (45%)]\tLoss: 4.396888, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 77 [24000/50000 (48%)]\tLoss: 4.200770, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 77 [25500/50000 (51%)]\tLoss: 4.360991, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 77 [27000/50000 (54%)]\tLoss: 4.413620, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 77 [28500/50000 (57%)]\tLoss: 4.501019, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 77 [30000/50000 (60%)]\tLoss: 4.495759, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 77 [31500/50000 (63%)]\tLoss: 4.256717, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 77 [33000/50000 (66%)]\tLoss: 4.366399, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 77 [34500/50000 (69%)]\tLoss: 4.312638, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 77 [36000/50000 (72%)]\tLoss: 4.377820, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 77 [37500/50000 (75%)]\tLoss: 4.313780, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 77 [39000/50000 (78%)]\tLoss: 4.188318, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 77 [40500/50000 (81%)]\tLoss: 4.475858, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 77 [42000/50000 (84%)]\tLoss: 4.353629, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 77 [43500/50000 (87%)]\tLoss: 4.350091, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 77 [45000/50000 (90%)]\tLoss: 4.463255, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 77 [46500/50000 (93%)]\tLoss: 4.393941, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 77 [48000/50000 (96%)]\tLoss: 4.349777, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 77 [49500/50000 (99%)]\tLoss: 4.370239, Accuracy: 25%, Learning rate: 0.001000\n",
            "\n",
            "Test set: Average loss: 1.5298, Accuracy: 7834/10000 (78%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 78 [1500/50000 (3%)]\tLoss: 4.189110, Accuracy: 29%, Learning rate: 0.001000\n",
            "Train Epoch: 78 [3000/50000 (6%)]\tLoss: 4.492022, Accuracy: 30%, Learning rate: 0.001000\n",
            "Train Epoch: 78 [4500/50000 (9%)]\tLoss: 4.404368, Accuracy: 30%, Learning rate: 0.001000\n",
            "Train Epoch: 78 [6000/50000 (12%)]\tLoss: 4.442919, Accuracy: 28%, Learning rate: 0.001000\n",
            "Train Epoch: 78 [7500/50000 (15%)]\tLoss: 4.456964, Accuracy: 27%, Learning rate: 0.001000\n",
            "Train Epoch: 78 [9000/50000 (18%)]\tLoss: 4.507397, Accuracy: 26%, Learning rate: 0.001000\n",
            "Train Epoch: 78 [10500/50000 (21%)]\tLoss: 4.458519, Accuracy: 26%, Learning rate: 0.001000\n",
            "Train Epoch: 78 [12000/50000 (24%)]\tLoss: 4.471158, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 78 [13500/50000 (27%)]\tLoss: 4.450878, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 78 [15000/50000 (30%)]\tLoss: 4.180101, Accuracy: 26%, Learning rate: 0.001000\n",
            "Train Epoch: 78 [16500/50000 (33%)]\tLoss: 4.517838, Accuracy: 26%, Learning rate: 0.001000\n",
            "Train Epoch: 78 [18000/50000 (36%)]\tLoss: 4.371006, Accuracy: 26%, Learning rate: 0.001000\n",
            "Train Epoch: 78 [19500/50000 (39%)]\tLoss: 4.230863, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 78 [21000/50000 (42%)]\tLoss: 4.477113, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 78 [22500/50000 (45%)]\tLoss: 4.474346, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 78 [24000/50000 (48%)]\tLoss: 4.444262, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 78 [25500/50000 (51%)]\tLoss: 4.415358, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 78 [27000/50000 (54%)]\tLoss: 4.303854, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 78 [28500/50000 (57%)]\tLoss: 4.422218, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 78 [30000/50000 (60%)]\tLoss: 4.244803, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 78 [31500/50000 (63%)]\tLoss: 4.434819, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 78 [33000/50000 (66%)]\tLoss: 4.275595, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 78 [34500/50000 (69%)]\tLoss: 4.477223, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 78 [36000/50000 (72%)]\tLoss: 4.472052, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 78 [37500/50000 (75%)]\tLoss: 4.393356, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 78 [39000/50000 (78%)]\tLoss: 4.455933, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 78 [40500/50000 (81%)]\tLoss: 4.436290, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 78 [42000/50000 (84%)]\tLoss: 4.470133, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 78 [43500/50000 (87%)]\tLoss: 4.543807, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 78 [45000/50000 (90%)]\tLoss: 4.215932, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 78 [46500/50000 (93%)]\tLoss: 4.480064, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 78 [48000/50000 (96%)]\tLoss: 4.322094, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 78 [49500/50000 (99%)]\tLoss: 4.380381, Accuracy: 25%, Learning rate: 0.001000\n",
            "\n",
            "Test set: Average loss: 1.5453, Accuracy: 7842/10000 (78%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 79 [1500/50000 (3%)]\tLoss: 4.449290, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 79 [3000/50000 (6%)]\tLoss: 4.482489, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 79 [4500/50000 (9%)]\tLoss: 4.202180, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 79 [6000/50000 (12%)]\tLoss: 4.455090, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 79 [7500/50000 (15%)]\tLoss: 4.289527, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 79 [9000/50000 (18%)]\tLoss: 4.440209, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 79 [10500/50000 (21%)]\tLoss: 4.217000, Accuracy: 26%, Learning rate: 0.001000\n",
            "Train Epoch: 79 [12000/50000 (24%)]\tLoss: 4.476082, Accuracy: 26%, Learning rate: 0.001000\n",
            "Train Epoch: 79 [13500/50000 (27%)]\tLoss: 4.218274, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 79 [15000/50000 (30%)]\tLoss: 4.438342, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 79 [16500/50000 (33%)]\tLoss: 4.471601, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 79 [18000/50000 (36%)]\tLoss: 4.477610, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 79 [19500/50000 (39%)]\tLoss: 4.440181, Accuracy: 26%, Learning rate: 0.001000\n",
            "Train Epoch: 79 [21000/50000 (42%)]\tLoss: 4.361583, Accuracy: 26%, Learning rate: 0.001000\n",
            "Train Epoch: 79 [22500/50000 (45%)]\tLoss: 4.488139, Accuracy: 26%, Learning rate: 0.001000\n",
            "Train Epoch: 79 [24000/50000 (48%)]\tLoss: 4.469441, Accuracy: 26%, Learning rate: 0.001000\n",
            "Train Epoch: 79 [25500/50000 (51%)]\tLoss: 4.352593, Accuracy: 26%, Learning rate: 0.001000\n",
            "Train Epoch: 79 [27000/50000 (54%)]\tLoss: 4.144652, Accuracy: 26%, Learning rate: 0.001000\n",
            "Train Epoch: 79 [28500/50000 (57%)]\tLoss: 4.463803, Accuracy: 26%, Learning rate: 0.001000\n",
            "Train Epoch: 79 [30000/50000 (60%)]\tLoss: 4.399046, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 79 [31500/50000 (63%)]\tLoss: 4.443363, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 79 [33000/50000 (66%)]\tLoss: 4.475145, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 79 [34500/50000 (69%)]\tLoss: 4.459447, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 79 [36000/50000 (72%)]\tLoss: 4.285930, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 79 [37500/50000 (75%)]\tLoss: 4.466739, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 79 [39000/50000 (78%)]\tLoss: 4.442753, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 79 [40500/50000 (81%)]\tLoss: 4.441860, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 79 [42000/50000 (84%)]\tLoss: 4.459516, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 79 [43500/50000 (87%)]\tLoss: 4.256355, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 79 [45000/50000 (90%)]\tLoss: 4.472049, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 79 [46500/50000 (93%)]\tLoss: 4.384583, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 79 [48000/50000 (96%)]\tLoss: 4.139518, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 79 [49500/50000 (99%)]\tLoss: 4.510951, Accuracy: 25%, Learning rate: 0.001000\n",
            "\n",
            "Test set: Average loss: 1.5535, Accuracy: 7802/10000 (78%)\n",
            "\n",
            "Training with 0.6 noise ratio of uniform random label noise\n",
            "Train Epoch: 80 [1500/50000 (3%)]\tLoss: 4.485074, Accuracy: 29%, Learning rate: 0.001000\n",
            "Train Epoch: 80 [3000/50000 (6%)]\tLoss: 4.448559, Accuracy: 26%, Learning rate: 0.001000\n",
            "Train Epoch: 80 [4500/50000 (9%)]\tLoss: 4.296852, Accuracy: 27%, Learning rate: 0.001000\n",
            "Train Epoch: 80 [6000/50000 (12%)]\tLoss: 4.303083, Accuracy: 27%, Learning rate: 0.001000\n",
            "Train Epoch: 80 [7500/50000 (15%)]\tLoss: 4.410759, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 80 [9000/50000 (18%)]\tLoss: 4.374697, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 80 [10500/50000 (21%)]\tLoss: 4.444472, Accuracy: 26%, Learning rate: 0.001000\n",
            "Train Epoch: 80 [12000/50000 (24%)]\tLoss: 4.473217, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 80 [13500/50000 (27%)]\tLoss: 4.370658, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 80 [15000/50000 (30%)]\tLoss: 4.262436, Accuracy: 24%, Learning rate: 0.001000\n",
            "Train Epoch: 80 [16500/50000 (33%)]\tLoss: 4.454752, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 80 [18000/50000 (36%)]\tLoss: 4.276856, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 80 [19500/50000 (39%)]\tLoss: 4.309530, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 80 [21000/50000 (42%)]\tLoss: 4.221385, Accuracy: 26%, Learning rate: 0.001000\n",
            "Train Epoch: 80 [22500/50000 (45%)]\tLoss: 4.480516, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 80 [24000/50000 (48%)]\tLoss: 4.515434, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 80 [25500/50000 (51%)]\tLoss: 4.493343, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 80 [27000/50000 (54%)]\tLoss: 4.331289, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 80 [28500/50000 (57%)]\tLoss: 4.478786, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 80 [30000/50000 (60%)]\tLoss: 4.206484, Accuracy: 26%, Learning rate: 0.001000\n",
            "Train Epoch: 80 [31500/50000 (63%)]\tLoss: 4.062673, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 80 [33000/50000 (66%)]\tLoss: 4.523992, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 80 [34500/50000 (69%)]\tLoss: 4.361421, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 80 [36000/50000 (72%)]\tLoss: 4.164142, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 80 [37500/50000 (75%)]\tLoss: 4.164436, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 80 [39000/50000 (78%)]\tLoss: 4.468103, Accuracy: 25%, Learning rate: 0.001000\n",
            "Train Epoch: 80 [40500/50000 (81%)]\tLoss: 4.453789, Accuracy: 26%, Learning rate: 0.001000\n",
            "Train Epoch: 80 [42000/50000 (84%)]\tLoss: 4.291609, Accuracy: 26%, Learning rate: 0.001000\n",
            "Train Epoch: 80 [43500/50000 (87%)]\tLoss: 4.180781, Accuracy: 26%, Learning rate: 0.001000\n",
            "Train Epoch: 80 [45000/50000 (90%)]\tLoss: 4.442916, Accuracy: 26%, Learning rate: 0.001000\n",
            "Train Epoch: 80 [46500/50000 (93%)]\tLoss: 4.335317, Accuracy: 26%, Learning rate: 0.001000\n",
            "Train Epoch: 80 [48000/50000 (96%)]\tLoss: 4.223925, Accuracy: 26%, Learning rate: 0.001000\n",
            "Train Epoch: 80 [49500/50000 (99%)]\tLoss: 4.508994, Accuracy: 26%, Learning rate: 0.001000\n",
            "\n",
            "Test set: Average loss: 1.5340, Accuracy: 7821/10000 (78%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3pJ5NwzlvQS"
      },
      "source": [
        "# Accuracy and loss curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6mNcKE8lbS0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 881
        },
        "outputId": "d94a3e38-a61b-4bae-da24-65aa705bc764"
      },
      "source": [
        "##Accuracy\n",
        "acc_train_mixBoot = np.load(res_path + '/' + 'accuracy_per_epoch_train_mixBoot.npy')\n",
        "acc_test_mixBoot = np.load(res_path + '/' + 'accuracy_per_epoch_val_mixBoot.npy')\n",
        "\n",
        "\n",
        "#Loss per epoch\n",
        "loss_train_mixBoot = np.load(res_path + '/' + 'LOSS_epoch_train_mixBoot.npy')\n",
        "loss_test_mixBoot = np.load(res_path + '/' + 'LOSS_epoch_val_mixBoot.npy')\n",
        "\n",
        "all_loss_train_epoch_mixBoot = np.load(res_path + '/' + 'losses_per_sample_train_mixBoot.npy')\n",
        "clean_idx = np.load(res_path + '/' + 'clean_idx.npy')\n",
        "noisy_idx = np.load(res_path + '/' + 'noisy_idx.npy')\n",
        "\n",
        "numEpochs = len(acc_test_mixBoot)\n",
        "epochs = range(numEpochs)\n",
        "\n",
        "plt.figure(4)\n",
        "plt.plot(epochs, acc_test_mixBoot, label='Test, max acc: ' + str(np.max(acc_test_mixBoot)))\n",
        "plt.plot(epochs, acc_train_mixBoot, label='Train, max acc: ' + str(np.max(acc_train_mixBoot)))\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "plt.figure(6)\n",
        "plt.plot(epochs, np.mean(all_loss_train_epoch_mixBoot[:, np.sort(clean_idx)], 1), label='Clean samples loss')\n",
        "plt.plot(epochs, np.mean(all_loss_train_epoch_mixBoot[:, np.sort(noisy_idx)], 1), label='Noisy samples loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0rDjvMIIMIN"
      },
      "source": [
        "**QUESTION FOR STUDENTS**\n",
        "\n",
        "Explain the loss behaviour. For noisy samples, why the behaviour is different compared to clean samples?\n",
        "\n",
        "Answer:  \n",
        "The utilization of bootstrapping loss correction and mixup data augmentation is aimed at avoiding memorization, which leads to distinct behavior for clean and noisy samples. To minimize the loss, the relabeling of the noisy samples is conducted."
      ]
    }
  ]
}